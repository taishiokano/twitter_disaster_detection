{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"44b334d74d2c4e48a9984c0ebacf5a65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cef152bc900e43b5ab1a895f76fc34f5","IPY_MODEL_4648ae0f17994018bfd49f3f0a7a707a","IPY_MODEL_752ad46cf6684b62aba58640ce2faeb4"],"layout":"IPY_MODEL_de9d8d85cc5e48cfa8e9a12f4701499f"}},"cef152bc900e43b5ab1a895f76fc34f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9da4a61c9f354abda43050299fdf20a5","placeholder":"​","style":"IPY_MODEL_07ebd7a294344e32a0167046078b6d3e","value":"Downloading (…)lve/main/config.json: 100%"}},"4648ae0f17994018bfd49f3f0a7a707a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5336389ef0848fb820d241a245dda59","max":1154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07839dbc24884dd39c66a1b035fb3989","value":1154}},"752ad46cf6684b62aba58640ce2faeb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcbf385f30614eb9978d1c5bb66ccfa3","placeholder":"​","style":"IPY_MODEL_41319da8f15f4bc59d860515231c2369","value":" 1.15k/1.15k [00:00&lt;00:00, 59.2kB/s]"}},"de9d8d85cc5e48cfa8e9a12f4701499f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9da4a61c9f354abda43050299fdf20a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07ebd7a294344e32a0167046078b6d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5336389ef0848fb820d241a245dda59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07839dbc24884dd39c66a1b035fb3989":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcbf385f30614eb9978d1c5bb66ccfa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41319da8f15f4bc59d860515231c2369":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea6a6bbb52514db29955f1f4e36791e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_574cdc4894fe4163b827871d6587afc6","IPY_MODEL_143ce6d5aa8a4bffa684298240b9b768","IPY_MODEL_4dd782b5dba24cde94f63752f2588069"],"layout":"IPY_MODEL_896eec03d5a04ffb9d1a987b2d00245f"}},"574cdc4894fe4163b827871d6587afc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_161f8c2277f6468ba9d3fc05dc9a814b","placeholder":"​","style":"IPY_MODEL_7bf52c34233e4d4690cbb39accd2a93f","value":"Downloading pytorch_model.bin: 100%"}},"143ce6d5aa8a4bffa684298240b9b768":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1777fe6a4ab4e41bbab377558412abc","max":1629486723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4198586f4a440cd8a214247bf53c618","value":1629486723}},"4dd782b5dba24cde94f63752f2588069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f80ef3d3721e4719b460ab0182978dba","placeholder":"​","style":"IPY_MODEL_dd3d62449b4841b48e894a325214c127","value":" 1.63G/1.63G [00:10&lt;00:00, 135MB/s]"}},"896eec03d5a04ffb9d1a987b2d00245f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"161f8c2277f6468ba9d3fc05dc9a814b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf52c34233e4d4690cbb39accd2a93f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1777fe6a4ab4e41bbab377558412abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4198586f4a440cd8a214247bf53c618":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f80ef3d3721e4719b460ab0182978dba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd3d62449b4841b48e894a325214c127":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9697256d12a4196b2715824d62c722a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5484e3f516a141bdbd3e99c5433d2fe1","IPY_MODEL_86ec42db3f414b4cac52807fd772988e","IPY_MODEL_9c236fc4badc4edaad36476c0c455644"],"layout":"IPY_MODEL_94c8fd8847a049769329b24c449a5858"}},"5484e3f516a141bdbd3e99c5433d2fe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6bcbe503cbb4628b6735848980264da","placeholder":"​","style":"IPY_MODEL_ab3d8c94fd6c48a5a854d315bfacb55f","value":"Downloading (…)okenizer_config.json: 100%"}},"86ec42db3f414b4cac52807fd772988e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_530ac8a910ab43698e54576ea43756a9","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b41ebc3030f411eac4afce86213d069","value":26}},"9c236fc4badc4edaad36476c0c455644":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ff53751a5d5476a88d31187ca1f6074","placeholder":"​","style":"IPY_MODEL_6dd3e13fe4424849b6fc0f97ac24f8a3","value":" 26.0/26.0 [00:00&lt;00:00, 530B/s]"}},"94c8fd8847a049769329b24c449a5858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6bcbe503cbb4628b6735848980264da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3d8c94fd6c48a5a854d315bfacb55f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"530ac8a910ab43698e54576ea43756a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b41ebc3030f411eac4afce86213d069":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ff53751a5d5476a88d31187ca1f6074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd3e13fe4424849b6fc0f97ac24f8a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7003086a01c04da18001924c7be33022":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d4ba8117a334c1f82327481a1f53f62","IPY_MODEL_5cac8a1cbf9547e68398f8df55c6a126","IPY_MODEL_0419851280af4c45949b65af79ed8472"],"layout":"IPY_MODEL_75f9f1a64f04432dac3ecad858084b7d"}},"2d4ba8117a334c1f82327481a1f53f62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c39840aa92ad432187a20c6f2a97004c","placeholder":"​","style":"IPY_MODEL_04d0e0b3f03c4e299ae23ea0f4573191","value":"Downloading (…)olve/main/vocab.json: 100%"}},"5cac8a1cbf9547e68398f8df55c6a126":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13d29538c2b14f1798ba3634a3909b25","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5021de8be2e4b36b32170b25dada11f","value":898822}},"0419851280af4c45949b65af79ed8472":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34e0aa8c7b4349a68785eeedd2e99306","placeholder":"​","style":"IPY_MODEL_d26655555ec3417bba194c3e8477ac6d","value":" 899k/899k [00:00&lt;00:00, 13.4MB/s]"}},"75f9f1a64f04432dac3ecad858084b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c39840aa92ad432187a20c6f2a97004c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d0e0b3f03c4e299ae23ea0f4573191":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13d29538c2b14f1798ba3634a3909b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5021de8be2e4b36b32170b25dada11f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34e0aa8c7b4349a68785eeedd2e99306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d26655555ec3417bba194c3e8477ac6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02ff29ddc93d4339a9139f30d6a64d00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f07fe05bb723424b82db938c5b2f3c52","IPY_MODEL_e4aa6a7c6a1340208f434c722bd17375","IPY_MODEL_f10a938da3bd4350968198aea6e2d3e5"],"layout":"IPY_MODEL_2663666e3f0f48f4b3c6533e55e88bd4"}},"f07fe05bb723424b82db938c5b2f3c52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59e1b378ba634854aed2cc3e13b51fa7","placeholder":"​","style":"IPY_MODEL_e3f9b4c1061044d8855c09827aea1c65","value":"Downloading (…)olve/main/merges.txt: 100%"}},"e4aa6a7c6a1340208f434c722bd17375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d51cd1c6ea79437fa3e912914f338718","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1cc5987c892433f9f980dddbb2a4508","value":456318}},"f10a938da3bd4350968198aea6e2d3e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16ba9f692c15478fb74e272779f7a0c9","placeholder":"​","style":"IPY_MODEL_4b0bfe4a93434d849b92c410959d4422","value":" 456k/456k [00:00&lt;00:00, 9.14MB/s]"}},"2663666e3f0f48f4b3c6533e55e88bd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e1b378ba634854aed2cc3e13b51fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3f9b4c1061044d8855c09827aea1c65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d51cd1c6ea79437fa3e912914f338718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1cc5987c892433f9f980dddbb2a4508":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16ba9f692c15478fb74e272779f7a0c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b0bfe4a93434d849b92c410959d4422":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4655f9da79ae46af8eba01896eee86c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ebc4b4b77b54dacba44ad72bc644070","IPY_MODEL_53f767597f224a629466c330739e8561","IPY_MODEL_65c4a3018d9b4f6f8578aafeb194f434"],"layout":"IPY_MODEL_9537f67619564ed3ba037fe687755264"}},"6ebc4b4b77b54dacba44ad72bc644070":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d86e036baa547ddbe1458d56e49afd7","placeholder":"​","style":"IPY_MODEL_f0f565e0bc90467d8897902984f731cd","value":"Downloading (…)/main/tokenizer.json: 100%"}},"53f767597f224a629466c330739e8561":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5eb22b1935194193ac6884bfb93ed50f","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc062b8f86174c9aa7067cd5f99bc02f","value":1355863}},"65c4a3018d9b4f6f8578aafeb194f434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cb15ee59d534b9f925f319d5f1efbea","placeholder":"​","style":"IPY_MODEL_b82b8374cb534494bde4cc4e9f6b8040","value":" 1.36M/1.36M [00:00&lt;00:00, 6.12MB/s]"}},"9537f67619564ed3ba037fe687755264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d86e036baa547ddbe1458d56e49afd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0f565e0bc90467d8897902984f731cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eb22b1935194193ac6884bfb93ed50f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc062b8f86174c9aa7067cd5f99bc02f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cb15ee59d534b9f925f319d5f1efbea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b82b8374cb534494bde4cc4e9f6b8040":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05ef74d1e1a54ab49cc6f678edeb1154":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f6e60e5fff043d082739ed556ebf044","IPY_MODEL_8ab1093d700149cba4adc69c77749a97","IPY_MODEL_2d626ac7cc374a7d9b60e771c3a486d7"],"layout":"IPY_MODEL_b10dc8b5149141f79d7f1a4fef8607c4"}},"0f6e60e5fff043d082739ed556ebf044":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92f4b27041924242bf1af53b71e0da7d","placeholder":"​","style":"IPY_MODEL_996a0ad2a27744bbb92abe8de2d58005","value":"Downloading (…)lve/main/config.json: 100%"}},"8ab1093d700149cba4adc69c77749a97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10b1dcdbd4d442478cfb33d1fab31576","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2460d53532234992ba6e4a7b4c57e114","value":483}},"2d626ac7cc374a7d9b60e771c3a486d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beaa5399c0d54cb2bb8c271ffba28d4f","placeholder":"​","style":"IPY_MODEL_14eed485e5c24686b24cc741eaeb002e","value":" 483/483 [00:00&lt;00:00, 32.9kB/s]"}},"b10dc8b5149141f79d7f1a4fef8607c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92f4b27041924242bf1af53b71e0da7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"996a0ad2a27744bbb92abe8de2d58005":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10b1dcdbd4d442478cfb33d1fab31576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2460d53532234992ba6e4a7b4c57e114":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"beaa5399c0d54cb2bb8c271ffba28d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14eed485e5c24686b24cc741eaeb002e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b931b9dd883403d9b1ef37b17b881d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_738671733b9b4d2eb4d8ad6cb810256d","IPY_MODEL_d784315b617946b89e444055494de1d6","IPY_MODEL_a7a66c2610e7450d9bcdd53cbf30cec8"],"layout":"IPY_MODEL_676136a65927411eb68d6cbe38c3aae4"}},"738671733b9b4d2eb4d8ad6cb810256d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced61f02a6774341881609d34458b71b","placeholder":"​","style":"IPY_MODEL_7829436c8f45465eb3b55d1d765d1165","value":"Downloading pytorch_model.bin: 100%"}},"d784315b617946b89e444055494de1d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e289a021b2b946b48db64f461c398e85","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_900a1a0d8eb44c52a5678485407f393c","value":267967963}},"a7a66c2610e7450d9bcdd53cbf30cec8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68c7be8a967e43538f8cd7909317faaa","placeholder":"​","style":"IPY_MODEL_a321875ca5f54381973efa18fd3f62cb","value":" 268M/268M [00:02&lt;00:00, 95.5MB/s]"}},"676136a65927411eb68d6cbe38c3aae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ced61f02a6774341881609d34458b71b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7829436c8f45465eb3b55d1d765d1165":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e289a021b2b946b48db64f461c398e85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900a1a0d8eb44c52a5678485407f393c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68c7be8a967e43538f8cd7909317faaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a321875ca5f54381973efa18fd3f62cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc02cc403522413ba1bdbea8e877c48a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91273b5ac793497b816c0f2b9f2b0ad1","IPY_MODEL_20206aa5b3f3425f8ccdc27e7381f8e9","IPY_MODEL_e73fca752bc94121bc99bcc6dd4c2b15"],"layout":"IPY_MODEL_6615e61dfed34a4990c1de16daf289d6"}},"91273b5ac793497b816c0f2b9f2b0ad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4208dca6401c48139d8a74169b7978c9","placeholder":"​","style":"IPY_MODEL_769fbd8c81194e639fb08d8ddf8208db","value":"Downloading (…)okenizer_config.json: 100%"}},"20206aa5b3f3425f8ccdc27e7381f8e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b3ac426757e44b98f87be1ec767eeac","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f96db9a22b224f93bd4acd36797756b8","value":28}},"e73fca752bc94121bc99bcc6dd4c2b15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53823ee214b74d5594fda2b26e738cf3","placeholder":"​","style":"IPY_MODEL_efacf4050e2f4457a714b4a45807d3a5","value":" 28.0/28.0 [00:00&lt;00:00, 1.30kB/s]"}},"6615e61dfed34a4990c1de16daf289d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4208dca6401c48139d8a74169b7978c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"769fbd8c81194e639fb08d8ddf8208db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b3ac426757e44b98f87be1ec767eeac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f96db9a22b224f93bd4acd36797756b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53823ee214b74d5594fda2b26e738cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efacf4050e2f4457a714b4a45807d3a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9aaa873f53724f989fbc1859d760ed63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bb5d96cd3844a87b359765af77ec695","IPY_MODEL_850cb826e12347afa6344ac5535a71b3","IPY_MODEL_6c31bccbed4e48308f231698f874c14c"],"layout":"IPY_MODEL_6573e7b66ca24338aeb13ba30d6d5e2a"}},"1bb5d96cd3844a87b359765af77ec695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96677ea8c20c4390ba6e8e6fb48c5a4d","placeholder":"​","style":"IPY_MODEL_6608aaa7466d4fbf90ec6186d1cbfbe4","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"850cb826e12347afa6344ac5535a71b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_045b7e19e7d54757bf9e7a74207a5d0a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c01c4dd103a54506ae881476b571366b","value":231508}},"6c31bccbed4e48308f231698f874c14c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93a107d3092a497796f30fa75b4d67b6","placeholder":"​","style":"IPY_MODEL_3e50beb22cd84dbd8ca7c64aab173fc3","value":" 232k/232k [00:00&lt;00:00, 4.20MB/s]"}},"6573e7b66ca24338aeb13ba30d6d5e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96677ea8c20c4390ba6e8e6fb48c5a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6608aaa7466d4fbf90ec6186d1cbfbe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"045b7e19e7d54757bf9e7a74207a5d0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c01c4dd103a54506ae881476b571366b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93a107d3092a497796f30fa75b4d67b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e50beb22cd84dbd8ca7c64aab173fc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c74acd3ae9745dca21a5912769d48f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8bf05b262b44865b4119a2c310ba808","IPY_MODEL_e86f35f4fc5a42169a5c6913108cf905","IPY_MODEL_145a958cc7cc4ea6a444ad0ca7ae98c4"],"layout":"IPY_MODEL_b7957ab7653749c78caf142db9ecc47c"}},"f8bf05b262b44865b4119a2c310ba808":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ff6a6c0817d430fad3eba3fb6dcefde","placeholder":"​","style":"IPY_MODEL_1f04ebc1e44543b19149c639a9c75480","value":"Downloading (…)/main/tokenizer.json: 100%"}},"e86f35f4fc5a42169a5c6913108cf905":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4669592ceb11465cb252a70126ceaba9","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87314329550e4e9c900037ced40488d8","value":466062}},"145a958cc7cc4ea6a444ad0ca7ae98c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bd1a6098a20479db71e6b1332cf716c","placeholder":"​","style":"IPY_MODEL_a8122bcc575e40deb579191f5f084692","value":" 466k/466k [00:00&lt;00:00, 26.9MB/s]"}},"b7957ab7653749c78caf142db9ecc47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ff6a6c0817d430fad3eba3fb6dcefde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f04ebc1e44543b19149c639a9c75480":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4669592ceb11465cb252a70126ceaba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87314329550e4e9c900037ced40488d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bd1a6098a20479db71e6b1332cf716c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8122bcc575e40deb579191f5f084692":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"bsDvRbQXtElF"}},{"cell_type":"code","source":["use_colab = True\n","if use_colab:\n","    !pip install transformers[sentencepiece]\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path = \"/content/drive/MyDrive/CAPP30255_Project/twitter_disaster_detection\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":822},"id":"eVgrRprMSh3z","executionInfo":{"status":"ok","timestamp":1684810069472,"user_tz":300,"elapsed":141239,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"2abe8d2c-bfc1-4f09-9cdb-1e077ac6c9bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[sentencepiece]\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers[sentencepiece])\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece])\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.65.0)\n","Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece])\n","  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n","Installing collected packages: tokenizers, sentencepiece, protobuf, huggingface-hub, transformers\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.14.1 protobuf-3.20.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import copy\n","import pandas as pd\n","import numpy as np\n","# from tqdm.autonotebook import tqdm\n","from tqdm import tqdm\n","import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.model_selection import train_test_split, KFold\n","\n","# importing HuggingFace transformers library\n","import transformers\n","from transformers import pipeline, get_linear_schedule_with_warmup\n","\n","print(\"Transformer version:\", transformers.__version__)\n","print(\"torch.device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-15T02:35:13.559996Z","iopub.execute_input":"2023-05-15T02:35:13.560366Z","iopub.status.idle":"2023-05-15T02:35:13.566423Z","shell.execute_reply.started":"2023-05-15T02:35:13.560333Z","shell.execute_reply":"2023-05-15T02:35:13.565503Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"XqhHFJ4BSWNI","executionInfo":{"status":"ok","timestamp":1684810088992,"user_tz":300,"elapsed":16414,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"6b2f06cc-7169-4923-d9c4-c4abbea87c26"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Transformer version: 4.29.2\n","torch.device: cuda\n"]}]},{"cell_type":"code","source":["data = pd.read_csv(path+'/data/cleaned-train-tweets.csv', sep=\"|\")\n","display(data.sample(5))\n"],"metadata":{"id":"VIfVqHZTUGR1","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1684810090345,"user_tz":300,"elapsed":1355,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"207e740e-0f9e-485a-f438-c4635bb2979c"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["          id               keyword                     location  \\\n","13246  13246              flooding  Jakarta/Kuala Lumpur/S'pore   \n","16688  16688  structural%20failure                          NaN   \n","3745    3745                  fire                          NaN   \n","14069  14069               injured                      Nigeria   \n","3301    3301              evacuate                          NaN   \n","\n","                                                    text  target  \\\n","13246  Heavy Rainfall and Flooding in Northern #VietN...       1   \n","16688  Investigators say a fatal Virgin Galactic spac...       1   \n","3745      My asshole is on fire  https://t.co/Y3FO0gHg8t       0   \n","14069  Ogun smugglers engage Customs in shootoutåÊ: S...       1   \n","3301   Condemnation clearly replacing the latest resp...       1   \n","\n","                                              clean_text  \n","13246  heavy rainfall flooding northern vietnam situa...  \n","16688  investigator say fatal virgin galactic spacesh...  \n","3745                                   asshole fire http  \n","14069  ogun smuggler engage custom shootoutåê several...  \n","3301   condemnation clearly replacing latest response...  "],"text/html":["\n","  <div id=\"df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13246</th>\n","      <td>13246</td>\n","      <td>flooding</td>\n","      <td>Jakarta/Kuala Lumpur/S'pore</td>\n","      <td>Heavy Rainfall and Flooding in Northern #VietN...</td>\n","      <td>1</td>\n","      <td>heavy rainfall flooding northern vietnam situa...</td>\n","    </tr>\n","    <tr>\n","      <th>16688</th>\n","      <td>16688</td>\n","      <td>structural%20failure</td>\n","      <td>NaN</td>\n","      <td>Investigators say a fatal Virgin Galactic spac...</td>\n","      <td>1</td>\n","      <td>investigator say fatal virgin galactic spacesh...</td>\n","    </tr>\n","    <tr>\n","      <th>3745</th>\n","      <td>3745</td>\n","      <td>fire</td>\n","      <td>NaN</td>\n","      <td>My asshole is on fire  https://t.co/Y3FO0gHg8t</td>\n","      <td>0</td>\n","      <td>asshole fire http</td>\n","    </tr>\n","    <tr>\n","      <th>14069</th>\n","      <td>14069</td>\n","      <td>injured</td>\n","      <td>Nigeria</td>\n","      <td>Ogun smugglers engage Customs in shootoutåÊ: S...</td>\n","      <td>1</td>\n","      <td>ogun smuggler engage custom shootoutåê several...</td>\n","    </tr>\n","    <tr>\n","      <th>3301</th>\n","      <td>3301</td>\n","      <td>evacuate</td>\n","      <td>NaN</td>\n","      <td>Condemnation clearly replacing the latest resp...</td>\n","      <td>1</td>\n","      <td>condemnation clearly replacing latest response...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["# BERT without fine-tuning"],"metadata":{"id":"HHT244szslHW"}},{"cell_type":"code","source":["simple_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"],"metadata":{"id":"5ykpDc3HskZV","executionInfo":{"status":"ok","timestamp":1684799595070,"user_tz":300,"elapsed":25583,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["44b334d74d2c4e48a9984c0ebacf5a65","cef152bc900e43b5ab1a895f76fc34f5","4648ae0f17994018bfd49f3f0a7a707a","752ad46cf6684b62aba58640ce2faeb4","de9d8d85cc5e48cfa8e9a12f4701499f","9da4a61c9f354abda43050299fdf20a5","07ebd7a294344e32a0167046078b6d3e","e5336389ef0848fb820d241a245dda59","07839dbc24884dd39c66a1b035fb3989","bcbf385f30614eb9978d1c5bb66ccfa3","41319da8f15f4bc59d860515231c2369","ea6a6bbb52514db29955f1f4e36791e9","574cdc4894fe4163b827871d6587afc6","143ce6d5aa8a4bffa684298240b9b768","4dd782b5dba24cde94f63752f2588069","896eec03d5a04ffb9d1a987b2d00245f","161f8c2277f6468ba9d3fc05dc9a814b","7bf52c34233e4d4690cbb39accd2a93f","c1777fe6a4ab4e41bbab377558412abc","d4198586f4a440cd8a214247bf53c618","f80ef3d3721e4719b460ab0182978dba","dd3d62449b4841b48e894a325214c127","e9697256d12a4196b2715824d62c722a","5484e3f516a141bdbd3e99c5433d2fe1","86ec42db3f414b4cac52807fd772988e","9c236fc4badc4edaad36476c0c455644","94c8fd8847a049769329b24c449a5858","e6bcbe503cbb4628b6735848980264da","ab3d8c94fd6c48a5a854d315bfacb55f","530ac8a910ab43698e54576ea43756a9","3b41ebc3030f411eac4afce86213d069","2ff53751a5d5476a88d31187ca1f6074","6dd3e13fe4424849b6fc0f97ac24f8a3","7003086a01c04da18001924c7be33022","2d4ba8117a334c1f82327481a1f53f62","5cac8a1cbf9547e68398f8df55c6a126","0419851280af4c45949b65af79ed8472","75f9f1a64f04432dac3ecad858084b7d","c39840aa92ad432187a20c6f2a97004c","04d0e0b3f03c4e299ae23ea0f4573191","13d29538c2b14f1798ba3634a3909b25","b5021de8be2e4b36b32170b25dada11f","34e0aa8c7b4349a68785eeedd2e99306","d26655555ec3417bba194c3e8477ac6d","02ff29ddc93d4339a9139f30d6a64d00","f07fe05bb723424b82db938c5b2f3c52","e4aa6a7c6a1340208f434c722bd17375","f10a938da3bd4350968198aea6e2d3e5","2663666e3f0f48f4b3c6533e55e88bd4","59e1b378ba634854aed2cc3e13b51fa7","e3f9b4c1061044d8855c09827aea1c65","d51cd1c6ea79437fa3e912914f338718","d1cc5987c892433f9f980dddbb2a4508","16ba9f692c15478fb74e272779f7a0c9","4b0bfe4a93434d849b92c410959d4422","4655f9da79ae46af8eba01896eee86c5","6ebc4b4b77b54dacba44ad72bc644070","53f767597f224a629466c330739e8561","65c4a3018d9b4f6f8578aafeb194f434","9537f67619564ed3ba037fe687755264","6d86e036baa547ddbe1458d56e49afd7","f0f565e0bc90467d8897902984f731cd","5eb22b1935194193ac6884bfb93ed50f","cc062b8f86174c9aa7067cd5f99bc02f","1cb15ee59d534b9f925f319d5f1efbea","b82b8374cb534494bde4cc4e9f6b8040"]},"outputId":"5565f87a-acc5-4221-f7f4-b1511a60ba89"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b334d74d2c4e48a9984c0ebacf5a65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea6a6bbb52514db29955f1f4e36791e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9697256d12a4196b2715824d62c722a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7003086a01c04da18001924c7be33022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ff29ddc93d4339a9139f30d6a64d00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4655f9da79ae46af8eba01896eee86c5"}},"metadata":{}}]},{"cell_type":"code","source":["labels = [\"not disaster\", \"disaster\"]\n","\n","def model_simple_test(i):\n","    responce= simple_model(\n","        data[\"text\"][i],\n","        candidate_labels=labels\n","    )\n","    print(responce)\n","\n","    true_label = labels[1] if data[\"target\"][i] else labels[0]\n","    print(\"True Label:\", true_label)\n","    print(\"Prediction:\", responce[\"labels\"][np.argmax(responce[\"scores\"])])\n","\n","def calculate_accuracy_zscppl(data, target_ids):\n","    accurate_num = 0\n","    for i in target_ids:\n","        response = simple_model(\n","            data[\"text\"][i],\n","            candidate_labels=labels\n","        )\n","        true_label = labels[1] if data[\"target\"][i] else labels[0]\n","        if true_label == response[\"labels\"][np.argmax(response[\"scores\"])]:\n","            accurate_num += 1\n","    return accurate_num / len(target_ids)\n"],"metadata":{"id":"Hdvn6CNUusF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_sample = data.sample(5)\n","data_sample_ids = data_sample[\"id\"].tolist()\n","display(data_sample)\n","\n","for id in data_sample_ids:\n","    model_simple_test(id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"Bpho3btjy3CO","executionInfo":{"status":"ok","timestamp":1684799606232,"user_tz":300,"elapsed":11177,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"92101c91-14ae-4176-acd7-7e4d71f86282"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["          id       keyword                     location  \\\n","3782    3782  fire%20truck  District 12 - Orange County   \n","9491    9491       burning                          NaN   \n","8573    8573         blaze                        Delhi   \n","9514    9514       burning          TÌÁchira, Venezuela   \n","14290  14290     landslide                          NaN   \n","\n","                                                    text  target  \\\n","3782   SIGALERT UPDATE #3***N-133 CLOSED AT 5 FWY UFN...       1   \n","9491   @aubilenon @MarkKriegsman if you think you'd l...       0   \n","8573   #socialmedia news - New Facebook Page Features...       0   \n","9514                     the Burning Legion has returned       0   \n","14290  5 need to-dos seeing as how technical writing ...       0   \n","\n","                                              clean_text  \n","3782     sigalert update closed fwy ufn trash truck fire  \n","9491   aubilenon markkriegsman think like burning man...  \n","8573   socialmedia news new facebook page feature see...  \n","9514                             burning legion returned  \n","14290  need seeing technical writing administer apps ...  "],"text/html":["\n","  <div id=\"df-e1921da3-68d7-4b62-8011-2fe14a0cdd41\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3782</th>\n","      <td>3782</td>\n","      <td>fire%20truck</td>\n","      <td>District 12 - Orange County</td>\n","      <td>SIGALERT UPDATE #3***N-133 CLOSED AT 5 FWY UFN...</td>\n","      <td>1</td>\n","      <td>sigalert update closed fwy ufn trash truck fire</td>\n","    </tr>\n","    <tr>\n","      <th>9491</th>\n","      <td>9491</td>\n","      <td>burning</td>\n","      <td>NaN</td>\n","      <td>@aubilenon @MarkKriegsman if you think you'd l...</td>\n","      <td>0</td>\n","      <td>aubilenon markkriegsman think like burning man...</td>\n","    </tr>\n","    <tr>\n","      <th>8573</th>\n","      <td>8573</td>\n","      <td>blaze</td>\n","      <td>Delhi</td>\n","      <td>#socialmedia news - New Facebook Page Features...</td>\n","      <td>0</td>\n","      <td>socialmedia news new facebook page feature see...</td>\n","    </tr>\n","    <tr>\n","      <th>9514</th>\n","      <td>9514</td>\n","      <td>burning</td>\n","      <td>TÌÁchira, Venezuela</td>\n","      <td>the Burning Legion has returned</td>\n","      <td>0</td>\n","      <td>burning legion returned</td>\n","    </tr>\n","    <tr>\n","      <th>14290</th>\n","      <td>14290</td>\n","      <td>landslide</td>\n","      <td>NaN</td>\n","      <td>5 need to-dos seeing as how technical writing ...</td>\n","      <td>0</td>\n","      <td>need seeing technical writing administer apps ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1921da3-68d7-4b62-8011-2fe14a0cdd41')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1921da3-68d7-4b62-8011-2fe14a0cdd41 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1921da3-68d7-4b62-8011-2fe14a0cdd41');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'sequence': 'SIGALERT UPDATE #3***N-133 CLOSED AT 5 FWY UFN***- TRASH TRUCK FIRE', 'labels': ['disaster', 'not disaster'], 'scores': [0.9129602909088135, 0.08703970164060593]}\n","True Label: disaster\n","Prediction: disaster\n","{'sequence': \"@aubilenon @MarkKriegsman if you think you'd like burning man you should try it because it's the only way to know!\", 'labels': ['disaster', 'not disaster'], 'scores': [0.7511258721351624, 0.24887412786483765]}\n","True Label: not disaster\n","Prediction: disaster\n","{'sequence': '#socialmedia news - New Facebook Page Features Seek to Help Personalize the Customer Experience http://t.co/nbizaTlsmV', 'labels': ['not disaster', 'disaster'], 'scores': [0.9289625883102417, 0.07103737443685532]}\n","True Label: not disaster\n","Prediction: not disaster\n","{'sequence': 'the Burning Legion has returned', 'labels': ['disaster', 'not disaster'], 'scores': [0.9670848250389099, 0.0329151451587677]}\n","True Label: not disaster\n","Prediction: disaster\n","{'sequence': '5 need to-dos seeing as how technical writing administer apps that landslide: QCt', 'labels': ['disaster', 'not disaster'], 'scores': [0.9608525633811951, 0.03914748877286911]}\n","True Label: not disaster\n","Prediction: disaster\n"]}]},{"cell_type":"code","source":["num_target = 50\n","target_ids = [random.randint(0, len(data)) for _ in range(num_target)]\n","accuracy_rate = calculate_accuracy_zscppl(data, target_ids)\n","print(f\"Accuracy Rate using Pretrained BERT Zero-Shot-Classification: {accuracy_rate}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4DGs3zuQYDV","executionInfo":{"status":"ok","timestamp":1684799676970,"user_tz":300,"elapsed":70751,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"7e6b0ced-c4cd-4e24-8906-8adb061dab7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Rate using Pretrained BERT Zero-Shot-Classification: 0.6\n"]}]},{"cell_type":"markdown","source":["# DistilBERT model with fine-tuning"],"metadata":{"id":"Xlra61nRSWNH"}},{"cell_type":"markdown","source":["## Preparation"],"metadata":{"id":"lR4EcMBspGGz"}},{"cell_type":"markdown","source":["### Building A PyTorch Dataset\n","\n","The following code uses the idea from this tutorial [Fine-tuning with custom datasets](https://huggingface.co/transformers/v3.2.0/custom_datasets.html) on building a custom dataset:\n"],"metadata":{"id":"to5qz7VUSWNJ"}},{"cell_type":"code","source":["class TweetDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataframe, tokenizer, mode=\"train\", max_length=None):\n","        self.dataframe = dataframe\n","        if mode != \"test\":\n","            self.targets = dataframe['target'].values\n","        texts = list(dataframe['text'].values)\n","        self.encodings = tokenizer(texts, \n","                                   padding=True, \n","                                   truncation=True, \n","                                   max_length=max_length)\n","        self.mode = mode\n","\n","\n","    def __getitem__(self, idx):\n","        # putting each tensor in front of the corresponding key from the tokenizer\n","        # HuggingFace tokenizers give you whatever you need to feed to the corresponding model\n","        item = {key: torch.tensor(values[idx]) for key, values in self.encodings.items()}\n","        # when testing, there are no targets so we won't do the following\n","        if self.mode != \"test\":\n","            item['labels'] = torch.tensor(self.targets[idx])\n","        return item\n","\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:35:50.271667Z","iopub.execute_input":"2023-05-15T02:35:50.272029Z","iopub.status.idle":"2023-05-15T02:35:50.280718Z","shell.execute_reply.started":"2023-05-15T02:35:50.271998Z","shell.execute_reply":"2023-05-15T02:35:50.279451Z"},"trusted":true,"id":"MXAsAhBSSWNJ","executionInfo":{"status":"ok","timestamp":1684810090346,"user_tz":300,"elapsed":4,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Just a wrapper to easier build the Dataset and DataLoader"],"metadata":{"id":"yj_9H_-BSWNK"}},{"cell_type":"code","source":["def make_loaders(dataframe, tokenizer, mode=\"train\", max_length=None):\n","    dataset = TweetDataset(dataframe, tokenizer, mode, max_length=max_length)\n","    dataloader = torch.utils.data.DataLoader(dataset, \n","                                             batch_size=options.batch_size, \n","                                             shuffle=True if mode == \"train\" else False,\n","                                             num_workers=options.num_workers)\n","    return dataloader"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:35:51.411496Z","iopub.execute_input":"2023-05-15T02:35:51.411851Z","iopub.status.idle":"2023-05-15T02:35:51.418299Z","shell.execute_reply.started":"2023-05-15T02:35:51.411817Z","shell.execute_reply":"2023-05-15T02:35:51.417359Z"},"trusted":true,"id":"PIZplw1hSWNK","executionInfo":{"status":"ok","timestamp":1684810092047,"user_tz":300,"elapsed":359,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Custom Classification Model based on DistilBERT\n","\n","* DistilBERT is a Language Model which needs to be fine-tuned on a final task of interest. So, we need to build that custom head here. In the [BERT paper](https://arxiv.org/abs/1810.04805)), they introduce some special tokens named [CLS] and [SEP] which they add to the sequence which is being fed to the model. [CLS] is used at the beginning of the sequence and [SEP] tokens are used to notify the end of each part in a sequence (a sequence which is going to be fed to BERT model can be made up of two parts; e.x question and corresponding text). \n"," \n","* In the paper they explain that they use [CLS] hidden state representation to do classification tasks for the sequence. So, in our case, we are going to the same. DistilBERT model will produce a vector of size 768 as a hidden representation for this [CLS] token and we will give it to some nn.Linear layers to do our own specific task. "],"metadata":{"id":"2Sy9YmZISWNK"}},{"cell_type":"code","source":["class CustomModel(nn.Module):\n","    def __init__(self,\n","                 bert_model,\n","                 num_labels, \n","                 bert_hidden_dim=768, \n","                 classifier_hidden_dim=768, \n","                 dropout=None):\n","\n","        super().__init__()\n","        self.bert_model = bert_model\n","        self.head = nn.Sequential(nn.Linear(bert_hidden_dim, classifier_hidden_dim), # Do nothing if the dropout is set to None\n","                                  nn.ReLU(),\n","                                  nn.Dropout(dropout) if dropout is not None else nn.Identity(),\n","                                  nn.Linear(classifier_hidden_dim, num_labels))\n","\n","    def forward(self, batch):\n","        # feeding the input_ids and masks to the model. These are provided by our tokenizer\n","        output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n","        # obtaining the last layer hidden states of the Transformer\n","        last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n","        # CLS token is in the beginning of the sequence. So, we grab its representation by indexing the tensor containing the hidden representations\n","        CLS_token_state = last_hidden_state[:, 0, :]\n","        # passing this representation through our custom head\n","        logits = self.head(CLS_token_state)\n","        return logits\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:06.249683Z","iopub.execute_input":"2023-05-15T02:37:06.250030Z","iopub.status.idle":"2023-05-15T02:37:06.258344Z","shell.execute_reply.started":"2023-05-15T02:37:06.249998Z","shell.execute_reply":"2023-05-15T02:37:06.257103Z"},"trusted":true,"id":"PEMceatFSWNK","executionInfo":{"status":"ok","timestamp":1684810094451,"user_tz":300,"elapsed":108,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Training and Evaluation"],"metadata":{"id":"xzwgKxINSWNL"}},{"cell_type":"code","source":["class AvgMeter:\n","    def __init__(self, name=\"Metric\"):\n","        self.name = name\n","        self.reset()\n","    \n","    def reset(self):\n","        self.avg, self.sum, self.count = [0]*3\n","    \n","    def update(self, val, count=1):\n","        self.count += count\n","        self.sum += val * count\n","        self.avg = self.sum / self.count\n","    \n","    def __repr__(self):\n","        text = f\"{self.name}: {self.avg:.4f}\"\n","        return text\n","\n","def one_epoch(model, criterion, loader, device, optimizer=None, lr_scheduler=None, mode=\"train\", step=\"batch\"):\n","    loss_meter = AvgMeter()\n","    acc_meter = AvgMeter()\n","    \n","    tqdm_object = tqdm(loader, total=len(loader))\n","    for batch in tqdm_object:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        preds = model(batch)\n","        loss = criterion(preds, batch['labels'])\n","        if mode == \"train\":\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if step == \"batch\":\n","                lr_scheduler.step()\n","                \n","        count = batch['input_ids'].size(0)\n","        loss_meter.update(loss.item(), count)\n","        \n","        accuracy = get_accuracy(preds.detach(), batch['labels'])\n","        acc_meter.update(accuracy.item(), count)\n","        if mode == \"train\":\n","            tqdm_object.set_postfix(loss=loss_meter.avg, accuracy=acc_meter.avg, lr=get_lr(optimizer))\n","        else:\n","            tqdm_object.set_postfix(loss=loss_meter.avg, accuracy=acc_meter.avg)\n","    \n","    return loss_meter, acc_meter\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group[\"lr\"]\n","\n","def get_accuracy(preds, targets):\n","    \"\"\"\n","    preds shape: (batch_size, num_labels)\n","    targets shape: (batch_size)\n","    \"\"\"\n","    preds = preds.argmax(dim=1)\n","    acc = (preds == targets).float().mean()\n","    return acc\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:09.732149Z","iopub.execute_input":"2023-05-15T02:37:09.732539Z","iopub.status.idle":"2023-05-15T02:37:09.746732Z","shell.execute_reply.started":"2023-05-15T02:37:09.732503Z","shell.execute_reply":"2023-05-15T02:37:09.745558Z"},"trusted":true,"id":"mkTjvwGKSWNL","executionInfo":{"status":"ok","timestamp":1684810096600,"user_tz":300,"elapsed":89,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train_eval(epochs, model, train_loader, valid_loader, \n","               criterion, optimizer, device, options, loss_accuracy, lr_scheduler=None):\n","    \n","    best_loss = float('inf')\n","    best_model_weights = copy.deepcopy(model.state_dict())\n","    \n","    for epoch in range(epochs):\n","        print(\"~\" * 30)\n","        print(f\"Epoch {epoch + 1}\")\n","        current_lr = get_lr(optimizer)\n","        \n","        model.train()\n","        train_loss, train_acc = one_epoch(model, \n","                                          criterion, \n","                                          train_loader, \n","                                          device,\n","                                          optimizer=optimizer,\n","                                          lr_scheduler=lr_scheduler,\n","                                          mode=\"train\",\n","                                          step=options.step)                     \n","        model.eval()\n","        with torch.no_grad():\n","            valid_loss, valid_acc = one_epoch(model, \n","                                              criterion, \n","                                              valid_loader, \n","                                              device,\n","                                              optimizer=None,\n","                                              lr_scheduler=None,\n","                                              mode=\"valid\")\n","        \n","        if valid_loss.avg < best_loss:\n","            best_loss = valid_loss.avg\n","            best_model_weights = copy.deepcopy(model.state_dict())\n","            torch.save(model.state_dict(), f'{options.model_path}/{options.model_save_name}')\n","            print(\"Saved best model!\")\n","        \n","        # or you could do: if step == \"epoch\":\n","        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n","            lr_scheduler.step(valid_loss.avg)\n","            # if the learning rate changes by ReduceLROnPlateau, we are going to\n","            # reload our previous best model weights and start from there with a lower LR\n","            if current_lr != get_lr(optimizer):\n","                print(\"Loading best model weights!\")\n","                model.load_state_dict(torch.load(f'{options.model_path}/{options.model_save_name}', \n","                                                 map_location=device))\n","        \n","\n","        print(f\"Train Loss: {train_loss.avg:.5f}\")\n","        print(f\"Train Accuracy: {train_acc.avg:.5f}\")\n","        \n","        print(f\"Valid Loss: {valid_loss.avg:.5f}\")\n","        print(f\"Valid Accuracy: {valid_acc.avg:.5f}\")\n","        print(\"*\" * 30)\n","\n","        loss_accuracy[\"Train Loss\"] += [train_loss.avg]\n","        loss_accuracy[\"Train Accuracy\"] += [train_acc.avg]\n","        loss_accuracy[\"Valid Loss\"] += [valid_loss.avg]\n","        loss_accuracy[\"Valid Accuracy\"] += [valid_acc.avg]\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:14.338616Z","iopub.execute_input":"2023-05-15T02:37:14.338954Z","iopub.status.idle":"2023-05-15T02:37:14.349969Z","shell.execute_reply.started":"2023-05-15T02:37:14.338924Z","shell.execute_reply":"2023-05-15T02:37:14.348719Z"},"trusted":true,"id":"EOerwOCGSWNL","executionInfo":{"status":"ok","timestamp":1684810098739,"user_tz":300,"elapsed":124,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### K-Fold Cross Validation"],"metadata":{"id":"s_AZ3wc-SWNM"}},{"cell_type":"code","source":["def make_folds(dataframe, n_splits=5):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    for i, (_, valid_idx) in enumerate(kf.split(X=dataframe['id'])):\n","        dataframe.loc[valid_idx, 'fold'] = i\n","    return dataframe"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:23.993766Z","iopub.execute_input":"2023-05-15T02:37:23.994118Z","iopub.status.idle":"2023-05-15T02:37:23.999710Z","shell.execute_reply.started":"2023-05-15T02:37:23.994084Z","shell.execute_reply":"2023-05-15T02:37:23.998736Z"},"trusted":true,"id":"zcbxzg-uSWNM","executionInfo":{"status":"ok","timestamp":1684810100968,"user_tz":300,"elapsed":2,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def one_fold(fold, options):  \n","    print(f\"Training Fold: {fold}\")\n","    loss_accuracy = {\"Train Loss\": [], \"Train Accuracy\": [], \"Valid Loss\": [], \"Valid Accuracy\": []}\n","    \n","    # Here, we load the pre-trained DistilBERT model from transformers library\n","    bert_model = transformers.DistilBertModel.from_pretrained(options.model_name)\n","    # Loading the corresponding tokenizer from HuggingFace by using AutoTokenizer class.\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(options.model_name, use_fast=True)\n","    \n","    dataframe = pd.read_csv(path+'/data/cleaned-train-tweets.csv', sep=\"|\")\n","    dataframe = make_folds(dataframe, n_splits=options.n_folds)\n","    train_dataframe = dataframe[dataframe['fold'] != fold].reset_index(drop=True)\n","    valid_dataframe = dataframe[dataframe['fold'] == fold].reset_index(drop=True)\n","\n","    train_loader = make_loaders(train_dataframe, tokenizer, \"train\", options.max_length)\n","    valid_loader = make_loaders(valid_dataframe, tokenizer, \"valid\", options.max_length)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = CustomModel(bert_model, options.num_labels, dropout=options.dropout).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=options.learning_rate)\n","    if options.scheduler == \"ReduceLROnPlateau\":\n","        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n","                                                                  mode=\"min\", \n","                                                                  factor=0.5, \n","                                                                  patience=options.patience)\n","\n","        # when to step the scheduler: after an epoch or after a batch\n","        options.step = \"epoch\"\n","        \n","    elif options.scheduler == \"LinearWarmup\":\n","        num_train_steps = len(train_loader) * options.epochs\n","        lr_scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                       num_warmup_steps=0, \n","                                                       num_training_steps=num_train_steps)\n","        \n","        # when to step the scheduler: after an epoch or after a batch\n","        options.step = \"batch\"\n","    \n","    criterion = nn.CrossEntropyLoss()\n","    options.model_save_name = f\"model_fold_{fold}.pt\"\n","    train_eval(options.epochs, model, train_loader, valid_loader,\n","               criterion, optimizer, device, options, loss_accuracy, lr_scheduler=lr_scheduler)\n","\n","    # tf = open(f\"{path}/models/loss_accuracy_{fold}.json\", \"x\")\n","    # json.dump(loss_accuracy, tf)\n","    # tf.close()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:25.103721Z","iopub.execute_input":"2023-05-15T02:37:25.104074Z","iopub.status.idle":"2023-05-15T02:37:25.115414Z","shell.execute_reply.started":"2023-05-15T02:37:25.104042Z","shell.execute_reply":"2023-05-15T02:37:25.114344Z"},"trusted":true,"id":"S3cM655NSWNM","executionInfo":{"status":"ok","timestamp":1684810101385,"user_tz":300,"elapsed":2,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_folds(options):\n","    n_folds = options.n_folds\n","    for i in range(n_folds):\n","        one_fold(fold=i, options=options)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:25.972069Z","iopub.execute_input":"2023-05-15T02:37:25.972455Z","iopub.status.idle":"2023-05-15T02:37:25.977449Z","shell.execute_reply.started":"2023-05-15T02:37:25.972422Z","shell.execute_reply":"2023-05-15T02:37:25.976345Z"},"trusted":true,"id":"InHEqq1rSWNM","executionInfo":{"status":"ok","timestamp":1684810103191,"user_tz":300,"elapsed":2,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Tuning"],"metadata":{"id":"CRtAQoJIhLq-"}},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 32\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XZI0mrZvbhM","executionInfo":{"status":"ok","timestamp":1684802010127,"user_tz":300,"elapsed":948860,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"ed2dec67-ccdb-4ac5-906e-0511c9a83813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.39it/s, accuracy=0.835, loss=0.396, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.20it/s, accuracy=0.861, loss=0.369]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39624\n","Train Accuracy: 0.83484\n","Valid Loss: 0.36893\n","Valid Accuracy: 0.86148\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.40it/s, accuracy=0.901, loss=0.266, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.46it/s, accuracy=0.884, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26632\n","Train Accuracy: 0.90085\n","Valid Loss: 0.29943\n","Valid Accuracy: 0.88373\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.41it/s, accuracy=0.941, loss=0.163, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.46it/s, accuracy=0.9, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16299\n","Train Accuracy: 0.94113\n","Valid Loss: 0.29887\n","Valid Accuracy: 0.89964\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.82, loss=0.414, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.45it/s, accuracy=0.87, loss=0.335]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41373\n","Train Accuracy: 0.82038\n","Valid Loss: 0.33518\n","Valid Accuracy: 0.86976\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.896, loss=0.273, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.42it/s, accuracy=0.878, loss=0.313]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27293\n","Train Accuracy: 0.89557\n","Valid Loss: 0.31261\n","Valid Accuracy: 0.87804\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.41it/s, accuracy=0.944, loss=0.165, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.23it/s, accuracy=0.893, loss=0.311]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16510\n","Train Accuracy: 0.94365\n","Valid Loss: 0.31143\n","Valid Accuracy: 0.89282\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.41it/s, accuracy=0.828, loss=0.4, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.09it/s, accuracy=0.86, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39955\n","Train Accuracy: 0.82770\n","Valid Loss: 0.33870\n","Valid Accuracy: 0.86016\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.902, loss=0.261, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.18it/s, accuracy=0.897, loss=0.278]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26119\n","Train Accuracy: 0.90159\n","Valid Loss: 0.27786\n","Valid Accuracy: 0.89654\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.943, loss=0.154, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.18it/s, accuracy=0.888, loss=0.311]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.15444\n","Train Accuracy: 0.94251\n","Valid Loss: 0.31078\n","Valid Accuracy: 0.88793\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93uwwAE_vbCG","executionInfo":{"status":"ok","timestamp":1684802883780,"user_tz":300,"elapsed":873669,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"157b35d5-bb7a-4abe-e92a-89d43bf67f76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.825, loss=0.408, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.80it/s, accuracy=0.859, loss=0.347]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40761\n","Train Accuracy: 0.82485\n","Valid Loss: 0.34736\n","Valid Accuracy: 0.85905\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.282, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.872, loss=0.318]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28239\n","Train Accuracy: 0.89346\n","Valid Loss: 0.31829\n","Valid Accuracy: 0.87187\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.93, loss=0.191, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.888, loss=0.313]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19137\n","Train Accuracy: 0.93017\n","Valid Loss: 0.31318\n","Valid Accuracy: 0.88828\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.817, loss=0.418, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.86, loss=0.346]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41810\n","Train Accuracy: 0.81697\n","Valid Loss: 0.34594\n","Valid Accuracy: 0.85986\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.283, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.885, loss=0.305]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28280\n","Train Accuracy: 0.89306\n","Valid Loss: 0.30509\n","Valid Accuracy: 0.88503\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.935, loss=0.188, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.892, loss=0.315]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.18823\n","Train Accuracy: 0.93479\n","Valid Loss: 0.31475\n","Valid Accuracy: 0.89185\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.821, loss=0.414, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.66it/s, accuracy=0.859, loss=0.35]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41384\n","Train Accuracy: 0.82113\n","Valid Loss: 0.35003\n","Valid Accuracy: 0.85870\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.891, loss=0.287, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.61it/s, accuracy=0.885, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28655\n","Train Accuracy: 0.89112\n","Valid Loss: 0.30893\n","Valid Accuracy: 0.88485\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.193, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.899, loss=0.279]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19258\n","Train Accuracy: 0.93245\n","Valid Loss: 0.27942\n","Valid Accuracy: 0.89881\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 128\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GIGRP_CvhI0","executionInfo":{"status":"ok","timestamp":1684803748399,"user_tz":300,"elapsed":864651,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"3ac808f5-b0a2-4546-ee89-2519f6bc11fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.807, loss=0.439, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.31it/s, accuracy=0.857, loss=0.359]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43871\n","Train Accuracy: 0.80666\n","Valid Loss: 0.35905\n","Valid Accuracy: 0.85661\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.883, loss=0.307, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.27it/s, accuracy=0.87, loss=0.329]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.30734\n","Train Accuracy: 0.88331\n","Valid Loss: 0.32878\n","Valid Accuracy: 0.87009\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.921, loss=0.223, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.30it/s, accuracy=0.891, loss=0.307]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.22275\n","Train Accuracy: 0.92140\n","Valid Loss: 0.30688\n","Valid Accuracy: 0.89071\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.812, loss=0.432, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.28it/s, accuracy=0.854, loss=0.363]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43164\n","Train Accuracy: 0.81202\n","Valid Loss: 0.36299\n","Valid Accuracy: 0.85450\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:19<00:00,  1.23it/s, accuracy=0.878, loss=0.307, lr=3e-5]\n","100%|██████████| 49/49 [00:15<00:00,  3.26it/s, accuracy=0.872, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.30695\n","Train Accuracy: 0.87795\n","Valid Loss: 0.33933\n","Valid Accuracy: 0.87204\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.92, loss=0.224, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.28it/s, accuracy=0.883, loss=0.333]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.22383\n","Train Accuracy: 0.92018\n","Valid Loss: 0.33326\n","Valid Accuracy: 0.88308\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.806, loss=0.441, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.35it/s, accuracy=0.857, loss=0.351]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44064\n","Train Accuracy: 0.80627\n","Valid Loss: 0.35106\n","Valid Accuracy: 0.85724\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.882, loss=0.311, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.38it/s, accuracy=0.876, loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31060\n","Train Accuracy: 0.88154\n","Valid Loss: 0.31368\n","Valid Accuracy: 0.87559\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.917, loss=0.234, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.38it/s, accuracy=0.888, loss=0.297]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.23450\n","Train Accuracy: 0.91702\n","Valid Loss: 0.29747\n","Valid Accuracy: 0.88761\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRSerzeH2vT_","executionInfo":{"status":"ok","timestamp":1684804619388,"user_tz":300,"elapsed":871005,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"78085474-30a2-4e59-fff9-ec48da629685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.826, loss=0.409, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.73it/s, accuracy=0.851, loss=0.357]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40899\n","Train Accuracy: 0.82639\n","Valid Loss: 0.35676\n","Valid Accuracy: 0.85060\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.891, loss=0.285, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.867, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28516\n","Train Accuracy: 0.89143\n","Valid Loss: 0.33968\n","Valid Accuracy: 0.86716\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.189, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.887, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18873\n","Train Accuracy: 0.93179\n","Valid Loss: 0.30920\n","Valid Accuracy: 0.88714\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.819, loss=0.416, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.70it/s, accuracy=0.868, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41588\n","Train Accuracy: 0.81900\n","Valid Loss: 0.34047\n","Valid Accuracy: 0.86765\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.895, loss=0.278, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.887, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27804\n","Train Accuracy: 0.89476\n","Valid Loss: 0.30867\n","Valid Accuracy: 0.88665\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.934, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.904, loss=0.285]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18642\n","Train Accuracy: 0.93366\n","Valid Loss: 0.28461\n","Valid Accuracy: 0.90419\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.819, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.67it/s, accuracy=0.863, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41302\n","Train Accuracy: 0.81926\n","Valid Loss: 0.33852\n","Valid Accuracy: 0.86292\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.281, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.63it/s, accuracy=0.887, loss=0.307]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28063\n","Train Accuracy: 0.89290\n","Valid Loss: 0.30682\n","Valid Accuracy: 0.88696\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.935, loss=0.183, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.67it/s, accuracy=0.901, loss=0.279]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18279\n","Train Accuracy: 0.93513\n","Valid Loss: 0.27861\n","Valid Accuracy: 0.90141\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 4\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBGlFVf824LX","executionInfo":{"status":"ok","timestamp":1684805496067,"user_tz":300,"elapsed":876152,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"603597c5-6416-4aba-c6ab-f703324679cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.817, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.848, loss=0.373]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41296\n","Train Accuracy: 0.81746\n","Valid Loss: 0.37315\n","Valid Accuracy: 0.84784\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.896, loss=0.28, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.73it/s, accuracy=0.873, loss=0.312]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27979\n","Train Accuracy: 0.89557\n","Valid Loss: 0.31200\n","Valid Accuracy: 0.87301\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.933, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.897, loss=0.296]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18627\n","Train Accuracy: 0.93350\n","Valid Loss: 0.29639\n","Valid Accuracy: 0.89704\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.823, loss=0.407, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.867, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40715\n","Train Accuracy: 0.82306\n","Valid Loss: 0.33856\n","Valid Accuracy: 0.86749\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.282, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.89, loss=0.293]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28229\n","Train Accuracy: 0.89306\n","Valid Loss: 0.29268\n","Valid Accuracy: 0.88990\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.935, loss=0.189, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.74it/s, accuracy=0.898, loss=0.276]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18892\n","Train Accuracy: 0.93471\n","Valid Loss: 0.27601\n","Valid Accuracy: 0.89818\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.822, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.62it/s, accuracy=0.861, loss=0.349]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41310\n","Train Accuracy: 0.82243\n","Valid Loss: 0.34871\n","Valid Accuracy: 0.86097\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.892, loss=0.286, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.68it/s, accuracy=0.879, loss=0.312]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28591\n","Train Accuracy: 0.89217\n","Valid Loss: 0.31213\n","Valid Accuracy: 0.87900\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.193, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.65it/s, accuracy=0.902, loss=0.268]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19294\n","Train Accuracy: 0.93204\n","Valid Loss: 0.26834\n","Valid Accuracy: 0.90239\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 164\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 8\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVANY9xo26LY","executionInfo":{"status":"ok","timestamp":1684806328598,"user_tz":300,"elapsed":832542,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"ce31b4fe-3f70-4bbd-a3e3-55e4d9c73190"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.813, loss=0.436, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.67it/s, accuracy=0.851, loss=0.366]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43580\n","Train Accuracy: 0.81267\n","Valid Loss: 0.36562\n","Valid Accuracy: 0.85125\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.881, loss=0.314, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.65it/s, accuracy=0.865, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31400\n","Train Accuracy: 0.88112\n","Valid Loss: 0.33951\n","Valid Accuracy: 0.86505\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.915, loss=0.238, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.66it/s, accuracy=0.882, loss=0.319]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.23828\n","Train Accuracy: 0.91539\n","Valid Loss: 0.31860\n","Valid Accuracy: 0.88178\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.806, loss=0.443, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.64it/s, accuracy=0.861, loss=0.351]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44344\n","Train Accuracy: 0.80641\n","Valid Loss: 0.35062\n","Valid Accuracy: 0.86148\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.876, loss=0.319, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.64it/s, accuracy=0.879, loss=0.324]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31884\n","Train Accuracy: 0.87568\n","Valid Loss: 0.32432\n","Valid Accuracy: 0.87934\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.909, loss=0.244, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.66it/s, accuracy=0.877, loss=0.328]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.24363\n","Train Accuracy: 0.90905\n","Valid Loss: 0.32769\n","Valid Accuracy: 0.87675\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.811, loss=0.438, lr=3e-5]\n","100%|██████████| 38/38 [00:13<00:00,  2.83it/s, accuracy=0.859, loss=0.352]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43805\n","Train Accuracy: 0.81098\n","Valid Loss: 0.35230\n","Valid Accuracy: 0.85886\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.879, loss=0.316, lr=3e-5]\n","100%|██████████| 38/38 [00:13<00:00,  2.82it/s, accuracy=0.879, loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31595\n","Train Accuracy: 0.87886\n","Valid Loss: 0.31393\n","Valid Accuracy: 0.87884\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.913, loss=0.242, lr=3e-5]\n","100%|██████████| 38/38 [00:13<00:00,  2.79it/s, accuracy=0.89, loss=0.3]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.24200\n","Train Accuracy: 0.91288\n","Valid Loss: 0.30004\n","Valid Accuracy: 0.89037\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-4\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zfnHC7CvuSs","executionInfo":{"status":"ok","timestamp":1684807192842,"user_tz":300,"elapsed":864262,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"b4106a01-d28a-42a2-ab3e-a3d8181d9ae8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.821, loss=0.428, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.841, loss=0.377]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42777\n","Train Accuracy: 0.82063\n","Valid Loss: 0.37685\n","Valid Accuracy: 0.84053\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.899, loss=0.278, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.866, loss=0.384]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.27810\n","Train Accuracy: 0.89866\n","Valid Loss: 0.38411\n","Valid Accuracy: 0.86635\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.857, loss=0.311, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.89it/s, accuracy=0.568, loss=0.685]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.31086\n","Train Accuracy: 0.85708\n","Valid Loss: 0.68475\n","Valid Accuracy: 0.56804\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.808, loss=0.448, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.842, loss=0.387]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44846\n","Train Accuracy: 0.80828\n","Valid Loss: 0.38718\n","Valid Accuracy: 0.84167\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.892, loss=0.304, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.868, loss=0.369]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.30358\n","Train Accuracy: 0.89151\n","Valid Loss: 0.36917\n","Valid Accuracy: 0.86798\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.899, loss=0.289, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.85it/s, accuracy=0.86, loss=0.371]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.28907\n","Train Accuracy: 0.89923\n","Valid Loss: 0.37125\n","Valid Accuracy: 0.85969\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.81, loss=0.443, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.86, loss=0.35]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44255\n","Train Accuracy: 0.81049\n","Valid Loss: 0.35021\n","Valid Accuracy: 0.85983\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:19<00:00,  2.42it/s, accuracy=0.904, loss=0.265, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.883, loss=0.351]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.26450\n","Train Accuracy: 0.90435\n","Valid Loss: 0.35081\n","Valid Accuracy: 0.88306\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:19<00:00,  2.41it/s, accuracy=0.942, loss=0.183, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.86it/s, accuracy=0.797, loss=0.539]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.18266\n","Train Accuracy: 0.94186\n","Valid Loss: 0.53891\n","Valid Accuracy: 0.79682\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSbf7y5Xh4Da","executionInfo":{"status":"ok","timestamp":1684808066622,"user_tz":300,"elapsed":873806,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"7f9c034b-a235-486b-8be9-9478716b5ba8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.828, loss=0.407, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.74it/s, accuracy=0.855, loss=0.354]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40745\n","Train Accuracy: 0.82818\n","Valid Loss: 0.35389\n","Valid Accuracy: 0.85515\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.894, loss=0.281, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.87, loss=0.33]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28069\n","Train Accuracy: 0.89411\n","Valid Loss: 0.32966\n","Valid Accuracy: 0.87025\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.934, loss=0.184, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.891, loss=0.311]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18392\n","Train Accuracy: 0.93374\n","Valid Loss: 0.31124\n","Valid Accuracy: 0.89136\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.814, loss=0.418, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.72it/s, accuracy=0.869, loss=0.336]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41840\n","Train Accuracy: 0.81445\n","Valid Loss: 0.33602\n","Valid Accuracy: 0.86928\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.893, loss=0.283, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.89, loss=0.302]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28258\n","Train Accuracy: 0.89265\n","Valid Loss: 0.30174\n","Valid Accuracy: 0.89006\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.937, loss=0.184, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.9, loss=0.274]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18427\n","Train Accuracy: 0.93723\n","Valid Loss: 0.27359\n","Valid Accuracy: 0.90045\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.825, loss=0.411, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.61it/s, accuracy=0.862, loss=0.342]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41074\n","Train Accuracy: 0.82462\n","Valid Loss: 0.34211\n","Valid Accuracy: 0.86195\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.897, loss=0.279, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.68it/s, accuracy=0.887, loss=0.296]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27871\n","Train Accuracy: 0.89713\n","Valid Loss: 0.29615\n","Valid Accuracy: 0.88728\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.19, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.897, loss=0.293]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18972\n","Train Accuracy: 0.93220\n","Valid Loss: 0.29288\n","Valid Accuracy: 0.89703\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-6\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yR7Mjom3v6qo","executionInfo":{"status":"ok","timestamp":1684808939068,"user_tz":300,"elapsed":872472,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"598c612f-798c-4660-b058-7833294e0a5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.709, loss=0.561, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.71it/s, accuracy=0.816, loss=0.429]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.56141\n","Train Accuracy: 0.70905\n","Valid Loss: 0.42886\n","Valid Accuracy: 0.81634\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.836, loss=0.393, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.839, loss=0.392]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39309\n","Train Accuracy: 0.83573\n","Valid Loss: 0.39205\n","Valid Accuracy: 0.83875\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.856, loss=0.359, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.845, loss=0.378]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.35943\n","Train Accuracy: 0.85595\n","Valid Loss: 0.37782\n","Valid Accuracy: 0.84492\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.714, loss=0.571, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.74it/s, accuracy=0.815, loss=0.425]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.57116\n","Train Accuracy: 0.71368\n","Valid Loss: 0.42452\n","Valid Accuracy: 0.81487\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.828, loss=0.406, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.837, loss=0.384]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40560\n","Train Accuracy: 0.82810\n","Valid Loss: 0.38365\n","Valid Accuracy: 0.83696\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.851, loss=0.365, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.856, loss=0.358]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.36466\n","Train Accuracy: 0.85132\n","Valid Loss: 0.35792\n","Valid Accuracy: 0.85612\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.759, loss=0.535, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.62it/s, accuracy=0.829, loss=0.407]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.53493\n","Train Accuracy: 0.75893\n","Valid Loss: 0.40660\n","Valid Accuracy: 0.82930\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.836, loss=0.397, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.847, loss=0.374]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39690\n","Train Accuracy: 0.83647\n","Valid Loss: 0.37408\n","Valid Accuracy: 0.84733\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.854, loss=0.361, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.854, loss=0.359]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.36112\n","Train Accuracy: 0.85442\n","Valid Loss: 0.35892\n","Valid Accuracy: 0.85399\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.3\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-RvtjDCwImw","outputId":"376501ee-a7b1-4b53-992f-0418167132d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.829, loss=0.407, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.73it/s, accuracy=0.859, loss=0.35]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40665\n","Train Accuracy: 0.82875\n","Valid Loss: 0.35020\n","Valid Accuracy: 0.85856\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.896, loss=0.28, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.80it/s, accuracy=0.878, loss=0.322]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27963\n","Train Accuracy: 0.89631\n","Valid Loss: 0.32183\n","Valid Accuracy: 0.87788\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.932, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.888, loss=0.307]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19230\n","Train Accuracy: 0.93220\n","Valid Loss: 0.30682\n","Valid Accuracy: 0.88795\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.82, loss=0.414, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.70it/s, accuracy=0.869, loss=0.335]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41370\n","Train Accuracy: 0.82006\n","Valid Loss: 0.33459\n","Valid Accuracy: 0.86928\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.895, loss=0.277, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.66it/s, accuracy=0.883, loss=0.317]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27708\n","Train Accuracy: 0.89484\n","Valid Loss: 0.31736\n","Valid Accuracy: 0.88259\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.936, loss=0.179, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.886, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.17940\n","Train Accuracy: 0.93593\n","Valid Loss: 0.34012\n","Valid Accuracy: 0.88600\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.824, loss=0.406, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.63it/s, accuracy=0.867, loss=0.336]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40642\n","Train Accuracy: 0.82421\n","Valid Loss: 0.33584\n","Valid Accuracy: 0.86731\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.895, loss=0.279, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.70it/s, accuracy=0.889, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27859\n","Train Accuracy: 0.89510\n","Valid Loss: 0.29923\n","Valid Accuracy: 0.88939\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 111/193 [00:46<00:35,  2.34it/s, accuracy=0.932, loss=0.191, lr=3e-5]"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"id":"_XOAQZF_wIa9","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["05ef74d1e1a54ab49cc6f678edeb1154","0f6e60e5fff043d082739ed556ebf044","8ab1093d700149cba4adc69c77749a97","2d626ac7cc374a7d9b60e771c3a486d7","b10dc8b5149141f79d7f1a4fef8607c4","92f4b27041924242bf1af53b71e0da7d","996a0ad2a27744bbb92abe8de2d58005","10b1dcdbd4d442478cfb33d1fab31576","2460d53532234992ba6e4a7b4c57e114","beaa5399c0d54cb2bb8c271ffba28d4f","14eed485e5c24686b24cc741eaeb002e","0b931b9dd883403d9b1ef37b17b881d2","738671733b9b4d2eb4d8ad6cb810256d","d784315b617946b89e444055494de1d6","a7a66c2610e7450d9bcdd53cbf30cec8","676136a65927411eb68d6cbe38c3aae4","ced61f02a6774341881609d34458b71b","7829436c8f45465eb3b55d1d765d1165","e289a021b2b946b48db64f461c398e85","900a1a0d8eb44c52a5678485407f393c","68c7be8a967e43538f8cd7909317faaa","a321875ca5f54381973efa18fd3f62cb","cc02cc403522413ba1bdbea8e877c48a","91273b5ac793497b816c0f2b9f2b0ad1","20206aa5b3f3425f8ccdc27e7381f8e9","e73fca752bc94121bc99bcc6dd4c2b15","6615e61dfed34a4990c1de16daf289d6","4208dca6401c48139d8a74169b7978c9","769fbd8c81194e639fb08d8ddf8208db","7b3ac426757e44b98f87be1ec767eeac","f96db9a22b224f93bd4acd36797756b8","53823ee214b74d5594fda2b26e738cf3","efacf4050e2f4457a714b4a45807d3a5","9aaa873f53724f989fbc1859d760ed63","1bb5d96cd3844a87b359765af77ec695","850cb826e12347afa6344ac5535a71b3","6c31bccbed4e48308f231698f874c14c","6573e7b66ca24338aeb13ba30d6d5e2a","96677ea8c20c4390ba6e8e6fb48c5a4d","6608aaa7466d4fbf90ec6186d1cbfbe4","045b7e19e7d54757bf9e7a74207a5d0a","c01c4dd103a54506ae881476b571366b","93a107d3092a497796f30fa75b4d67b6","3e50beb22cd84dbd8ca7c64aab173fc3","8c74acd3ae9745dca21a5912769d48f2","f8bf05b262b44865b4119a2c310ba808","e86f35f4fc5a42169a5c6913108cf905","145a958cc7cc4ea6a444ad0ca7ae98c4","b7957ab7653749c78caf142db9ecc47c","7ff6a6c0817d430fad3eba3fb6dcefde","1f04ebc1e44543b19149c639a9c75480","4669592ceb11465cb252a70126ceaba9","87314329550e4e9c900037ced40488d8","9bd1a6098a20479db71e6b1332cf716c","a8122bcc575e40deb579191f5f084692"]},"executionInfo":{"status":"ok","timestamp":1684811050826,"user_tz":300,"elapsed":918798,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"1660fd2b-7290-4676-dc88-7301d9999c69"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ef74d1e1a54ab49cc6f678edeb1154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b931b9dd883403d9b1ef37b17b881d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc02cc403522413ba1bdbea8e877c48a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aaa873f53724f989fbc1859d760ed63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c74acd3ae9745dca21a5912769d48f2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.829, loss=0.404, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.28it/s, accuracy=0.859, loss=0.349]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40448\n","Train Accuracy: 0.82907\n","Valid Loss: 0.34852\n","Valid Accuracy: 0.85872\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.897, loss=0.275, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.56it/s, accuracy=0.882, loss=0.32]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27475\n","Train Accuracy: 0.89712\n","Valid Loss: 0.32010\n","Valid Accuracy: 0.88178\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.932, loss=0.185, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.53it/s, accuracy=0.893, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18475\n","Train Accuracy: 0.93228\n","Valid Loss: 0.30369\n","Valid Accuracy: 0.89282\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.824, loss=0.416, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.57it/s, accuracy=0.864, loss=0.341]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41584\n","Train Accuracy: 0.82420\n","Valid Loss: 0.34128\n","Valid Accuracy: 0.86408\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.889, loss=0.285, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.58it/s, accuracy=0.89, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28511\n","Train Accuracy: 0.88948\n","Valid Loss: 0.29872\n","Valid Accuracy: 0.89022\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.934, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.52it/s, accuracy=0.897, loss=0.298]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18641\n","Train Accuracy: 0.93447\n","Valid Loss: 0.29832\n","Valid Accuracy: 0.89721\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.822, loss=0.415, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.42it/s, accuracy=0.862, loss=0.342]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41490\n","Train Accuracy: 0.82194\n","Valid Loss: 0.34152\n","Valid Accuracy: 0.86211\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.89, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.44it/s, accuracy=0.884, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28883\n","Train Accuracy: 0.88982\n","Valid Loss: 0.30353\n","Valid Accuracy: 0.88420\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.931, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.43it/s, accuracy=0.897, loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19210\n","Train Accuracy: 0.93090\n","Valid Loss: 0.28713\n","Valid Accuracy: 0.89687\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.7\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"id":"q7aR3nDuwIMx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684811944941,"user_tz":300,"elapsed":894119,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"b6462802-32b2-4ace-e62c-5200a677741a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.82, loss=0.424, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.49it/s, accuracy=0.855, loss=0.36]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42373\n","Train Accuracy: 0.81989\n","Valid Loss: 0.35962\n","Valid Accuracy: 0.85466\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.893, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.57it/s, accuracy=0.874, loss=0.326]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28902\n","Train Accuracy: 0.89265\n","Valid Loss: 0.32593\n","Valid Accuracy: 0.87399\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.925, loss=0.204, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.52it/s, accuracy=0.886, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.20383\n","Train Accuracy: 0.92481\n","Valid Loss: 0.30859\n","Valid Accuracy: 0.88600\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.816, loss=0.42, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.51it/s, accuracy=0.863, loss=0.338]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42016\n","Train Accuracy: 0.81640\n","Valid Loss: 0.33790\n","Valid Accuracy: 0.86310\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.889, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.56it/s, accuracy=0.886, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28857\n","Train Accuracy: 0.88867\n","Valid Loss: 0.30922\n","Valid Accuracy: 0.88600\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.929, loss=0.198, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.48it/s, accuracy=0.893, loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.19808\n","Train Accuracy: 0.92895\n","Valid Loss: 0.31361\n","Valid Accuracy: 0.89282\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.822, loss=0.42, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.42it/s, accuracy=0.867, loss=0.342]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42011\n","Train Accuracy: 0.82243\n","Valid Loss: 0.34216\n","Valid Accuracy: 0.86682\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.891, loss=0.287, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.36it/s, accuracy=0.882, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28724\n","Train Accuracy: 0.89063\n","Valid Loss: 0.30376\n","Valid Accuracy: 0.88176\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.932, loss=0.195, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.42it/s, accuracy=0.895, loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19470\n","Train Accuracy: 0.93196\n","Valid Loss: 0.28740\n","Valid Accuracy: 0.89524\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"id":"B2JMQIhVyfTZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684812837627,"user_tz":300,"elapsed":892692,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"874b052d-36cc-49f3-8b68-4390304c4af6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.819, loss=0.416, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.59it/s, accuracy=0.855, loss=0.349]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41570\n","Train Accuracy: 0.81876\n","Valid Loss: 0.34924\n","Valid Accuracy: 0.85466\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.892, loss=0.286, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.55it/s, accuracy=0.876, loss=0.316]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28595\n","Train Accuracy: 0.89249\n","Valid Loss: 0.31641\n","Valid Accuracy: 0.87577\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.932, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.56it/s, accuracy=0.897, loss=0.306]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19208\n","Train Accuracy: 0.93220\n","Valid Loss: 0.30561\n","Valid Accuracy: 0.89737\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.819, loss=0.418, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.60it/s, accuracy=0.863, loss=0.347]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41766\n","Train Accuracy: 0.81908\n","Valid Loss: 0.34712\n","Valid Accuracy: 0.86262\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.889, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.50it/s, accuracy=0.887, loss=0.308]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28851\n","Train Accuracy: 0.88883\n","Valid Loss: 0.30789\n","Valid Accuracy: 0.88698\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.93, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.58it/s, accuracy=0.885, loss=0.338]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.19165\n","Train Accuracy: 0.93025\n","Valid Loss: 0.33782\n","Valid Accuracy: 0.88454\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.821, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.45it/s, accuracy=0.868, loss=0.344]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41259\n","Train Accuracy: 0.82137\n","Valid Loss: 0.34394\n","Valid Accuracy: 0.86844\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.892, loss=0.282, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.39it/s, accuracy=0.889, loss=0.296]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28152\n","Train Accuracy: 0.89169\n","Valid Loss: 0.29590\n","Valid Accuracy: 0.88939\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.935, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.44it/s, accuracy=0.901, loss=0.303]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.18581\n","Train Accuracy: 0.93456\n","Valid Loss: 0.30261\n","Valid Accuracy: 0.90109\n","******************************\n"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 5\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"id":"uZaMpvL_ylZ_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a6d991c-cf30-4439-dd67-bfc71b7f1325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.826, loss=0.403, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.48it/s, accuracy=0.868, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40256\n","Train Accuracy: 0.82589\n","Valid Loss: 0.33863\n","Valid Accuracy: 0.86766\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":[" 66%|██████▌   | 153/231 [01:05<00:33,  2.36it/s, accuracy=0.897, loss=0.275, lr=3e-5]"]}]},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 7\n","\n","options = Options()\n","train_folds(options)\n"],"metadata":{"id":"ZYQAyiu8ymXd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run with the best setting"],"metadata":{"id":"VdZonxywX33B"}},{"cell_type":"code","source":["class Options:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 5\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 5\n","\n","options = Options()\n","train_folds(options)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:21.624974Z","iopub.execute_input":"2023-05-15T02:37:21.625331Z","iopub.status.idle":"2023-05-15T02:37:21.633119Z","shell.execute_reply.started":"2023-05-15T02:37:21.625294Z","shell.execute_reply":"2023-05-15T02:37:21.632176Z"},"trusted":true,"id":"2Cr9kRKlSWNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies = [0.8657645459910691, 0.8960757774493691, 0.9096075771464708, 0.9098782130765334, 0.9234100128058974, 0.9142083890221923, 0.9174560208927149, 0.9139377529953426, 0.9209742888546119, 0.9179972929141518, 0.9220568328006987, 0.9198917448762628, 0.9169147489358027, 0.9182679289087391, 0.9161028409520409, 0.9155615689628663, 0.9179972929141518, 0.9188092008979136, 0.9147496609791045, 0.9150202969736917]\n","import matplotlib.pyplot as plt\n","epochs = 20\n","plt.plot(range(1, epochs + 1), accuracies)"],"metadata":{"id":"oVDHc4s3hwwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"JlktsGzItmiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_one_model(options):  \n","    test_dataframe = pd.read_csv(path+'/data/tweet_samples_100.csv', sep=\",\")\n","\n","    bert_model = transformers.DistilBertModel.from_pretrained(options.model_name)\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(options.model_name, use_fast=True)\n","    \n","    test_loader = make_loaders(test_dataframe, tokenizer, mode=\"test\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = CustomModel(bert_model,\n","                        options.num_labels,\n","                        dropout=options.dropout).to(device)\n","    model.load_state_dict(torch.load(f\"{options.model_path}/{options.model_save_name}\", \n","                                     map_location=device))\n","    model.eval()\n","    \n","    all_preds = None\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader):\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            preds = model(batch)\n","            if all_preds is None:\n","                all_preds = preds\n","            else:\n","                all_preds = torch.cat([all_preds, preds], dim=0)\n","\n","    return all_preds"],"metadata":{"trusted":true,"id":"2wPQkR2oSWNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_all_models(options):\n","    n_folds = options.n_folds\n","    all_model_preds = []\n","    for fold in range(n_folds):\n","        options.model_save_name = f\"model_fold_{fold}.pt\"\n","        all_preds = test_one_model(options)\n","        all_model_preds.append(all_preds)\n","    \n","    all_model_preds = torch.stack(all_model_preds, dim=0)\n","    print(all_model_preds.shape)\n","    # I will return the mean of the final predictions of all the models\n","    # You could do other things like 'voting' between the five models\n","    return all_model_preds.mean(0)"],"metadata":{"trusted":true,"id":"ExIew2paSWNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataframe = pd.read_csv(path+'/data/tweet_samples_100.csv', sep=\",\")\n","all_preds = test_all_models(options)\n","predictions = all_preds.argmax(dim=1).cpu().numpy()\n","true_labels = np.array(test_dataframe[\"target\"].tolist())"],"metadata":{"trusted":true,"id":"u0ldye1tSWNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.sum(predictions == true_labels)"],"metadata":{"id":"yOovrTfP0sHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mismatched_indices = []\n","for i in range(len(predictions)):\n","    if predictions[i] != true_labels[i]:\n","        mismatched_indices.append(i)\n","mismatched_indices"],"metadata":{"id":"sRLIv1SK0yEh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pa7D1IJB-lLS"},"execution_count":null,"outputs":[]}]}