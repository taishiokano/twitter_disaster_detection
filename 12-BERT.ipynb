{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"44b334d74d2c4e48a9984c0ebacf5a65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cef152bc900e43b5ab1a895f76fc34f5","IPY_MODEL_4648ae0f17994018bfd49f3f0a7a707a","IPY_MODEL_752ad46cf6684b62aba58640ce2faeb4"],"layout":"IPY_MODEL_de9d8d85cc5e48cfa8e9a12f4701499f"}},"cef152bc900e43b5ab1a895f76fc34f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9da4a61c9f354abda43050299fdf20a5","placeholder":"​","style":"IPY_MODEL_07ebd7a294344e32a0167046078b6d3e","value":"Downloading (…)lve/main/config.json: 100%"}},"4648ae0f17994018bfd49f3f0a7a707a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5336389ef0848fb820d241a245dda59","max":1154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07839dbc24884dd39c66a1b035fb3989","value":1154}},"752ad46cf6684b62aba58640ce2faeb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcbf385f30614eb9978d1c5bb66ccfa3","placeholder":"​","style":"IPY_MODEL_41319da8f15f4bc59d860515231c2369","value":" 1.15k/1.15k [00:00&lt;00:00, 59.2kB/s]"}},"de9d8d85cc5e48cfa8e9a12f4701499f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9da4a61c9f354abda43050299fdf20a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07ebd7a294344e32a0167046078b6d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5336389ef0848fb820d241a245dda59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07839dbc24884dd39c66a1b035fb3989":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcbf385f30614eb9978d1c5bb66ccfa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41319da8f15f4bc59d860515231c2369":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea6a6bbb52514db29955f1f4e36791e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_574cdc4894fe4163b827871d6587afc6","IPY_MODEL_143ce6d5aa8a4bffa684298240b9b768","IPY_MODEL_4dd782b5dba24cde94f63752f2588069"],"layout":"IPY_MODEL_896eec03d5a04ffb9d1a987b2d00245f"}},"574cdc4894fe4163b827871d6587afc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_161f8c2277f6468ba9d3fc05dc9a814b","placeholder":"​","style":"IPY_MODEL_7bf52c34233e4d4690cbb39accd2a93f","value":"Downloading pytorch_model.bin: 100%"}},"143ce6d5aa8a4bffa684298240b9b768":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1777fe6a4ab4e41bbab377558412abc","max":1629486723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4198586f4a440cd8a214247bf53c618","value":1629486723}},"4dd782b5dba24cde94f63752f2588069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f80ef3d3721e4719b460ab0182978dba","placeholder":"​","style":"IPY_MODEL_dd3d62449b4841b48e894a325214c127","value":" 1.63G/1.63G [00:10&lt;00:00, 135MB/s]"}},"896eec03d5a04ffb9d1a987b2d00245f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"161f8c2277f6468ba9d3fc05dc9a814b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf52c34233e4d4690cbb39accd2a93f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1777fe6a4ab4e41bbab377558412abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4198586f4a440cd8a214247bf53c618":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f80ef3d3721e4719b460ab0182978dba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd3d62449b4841b48e894a325214c127":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9697256d12a4196b2715824d62c722a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5484e3f516a141bdbd3e99c5433d2fe1","IPY_MODEL_86ec42db3f414b4cac52807fd772988e","IPY_MODEL_9c236fc4badc4edaad36476c0c455644"],"layout":"IPY_MODEL_94c8fd8847a049769329b24c449a5858"}},"5484e3f516a141bdbd3e99c5433d2fe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6bcbe503cbb4628b6735848980264da","placeholder":"​","style":"IPY_MODEL_ab3d8c94fd6c48a5a854d315bfacb55f","value":"Downloading (…)okenizer_config.json: 100%"}},"86ec42db3f414b4cac52807fd772988e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_530ac8a910ab43698e54576ea43756a9","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b41ebc3030f411eac4afce86213d069","value":26}},"9c236fc4badc4edaad36476c0c455644":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ff53751a5d5476a88d31187ca1f6074","placeholder":"​","style":"IPY_MODEL_6dd3e13fe4424849b6fc0f97ac24f8a3","value":" 26.0/26.0 [00:00&lt;00:00, 530B/s]"}},"94c8fd8847a049769329b24c449a5858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6bcbe503cbb4628b6735848980264da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3d8c94fd6c48a5a854d315bfacb55f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"530ac8a910ab43698e54576ea43756a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b41ebc3030f411eac4afce86213d069":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ff53751a5d5476a88d31187ca1f6074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd3e13fe4424849b6fc0f97ac24f8a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7003086a01c04da18001924c7be33022":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d4ba8117a334c1f82327481a1f53f62","IPY_MODEL_5cac8a1cbf9547e68398f8df55c6a126","IPY_MODEL_0419851280af4c45949b65af79ed8472"],"layout":"IPY_MODEL_75f9f1a64f04432dac3ecad858084b7d"}},"2d4ba8117a334c1f82327481a1f53f62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c39840aa92ad432187a20c6f2a97004c","placeholder":"​","style":"IPY_MODEL_04d0e0b3f03c4e299ae23ea0f4573191","value":"Downloading (…)olve/main/vocab.json: 100%"}},"5cac8a1cbf9547e68398f8df55c6a126":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13d29538c2b14f1798ba3634a3909b25","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5021de8be2e4b36b32170b25dada11f","value":898822}},"0419851280af4c45949b65af79ed8472":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34e0aa8c7b4349a68785eeedd2e99306","placeholder":"​","style":"IPY_MODEL_d26655555ec3417bba194c3e8477ac6d","value":" 899k/899k [00:00&lt;00:00, 13.4MB/s]"}},"75f9f1a64f04432dac3ecad858084b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c39840aa92ad432187a20c6f2a97004c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d0e0b3f03c4e299ae23ea0f4573191":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13d29538c2b14f1798ba3634a3909b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5021de8be2e4b36b32170b25dada11f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34e0aa8c7b4349a68785eeedd2e99306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d26655555ec3417bba194c3e8477ac6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02ff29ddc93d4339a9139f30d6a64d00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f07fe05bb723424b82db938c5b2f3c52","IPY_MODEL_e4aa6a7c6a1340208f434c722bd17375","IPY_MODEL_f10a938da3bd4350968198aea6e2d3e5"],"layout":"IPY_MODEL_2663666e3f0f48f4b3c6533e55e88bd4"}},"f07fe05bb723424b82db938c5b2f3c52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59e1b378ba634854aed2cc3e13b51fa7","placeholder":"​","style":"IPY_MODEL_e3f9b4c1061044d8855c09827aea1c65","value":"Downloading (…)olve/main/merges.txt: 100%"}},"e4aa6a7c6a1340208f434c722bd17375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d51cd1c6ea79437fa3e912914f338718","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1cc5987c892433f9f980dddbb2a4508","value":456318}},"f10a938da3bd4350968198aea6e2d3e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16ba9f692c15478fb74e272779f7a0c9","placeholder":"​","style":"IPY_MODEL_4b0bfe4a93434d849b92c410959d4422","value":" 456k/456k [00:00&lt;00:00, 9.14MB/s]"}},"2663666e3f0f48f4b3c6533e55e88bd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e1b378ba634854aed2cc3e13b51fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3f9b4c1061044d8855c09827aea1c65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d51cd1c6ea79437fa3e912914f338718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1cc5987c892433f9f980dddbb2a4508":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16ba9f692c15478fb74e272779f7a0c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b0bfe4a93434d849b92c410959d4422":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4655f9da79ae46af8eba01896eee86c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ebc4b4b77b54dacba44ad72bc644070","IPY_MODEL_53f767597f224a629466c330739e8561","IPY_MODEL_65c4a3018d9b4f6f8578aafeb194f434"],"layout":"IPY_MODEL_9537f67619564ed3ba037fe687755264"}},"6ebc4b4b77b54dacba44ad72bc644070":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d86e036baa547ddbe1458d56e49afd7","placeholder":"​","style":"IPY_MODEL_f0f565e0bc90467d8897902984f731cd","value":"Downloading (…)/main/tokenizer.json: 100%"}},"53f767597f224a629466c330739e8561":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5eb22b1935194193ac6884bfb93ed50f","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc062b8f86174c9aa7067cd5f99bc02f","value":1355863}},"65c4a3018d9b4f6f8578aafeb194f434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cb15ee59d534b9f925f319d5f1efbea","placeholder":"​","style":"IPY_MODEL_b82b8374cb534494bde4cc4e9f6b8040","value":" 1.36M/1.36M [00:00&lt;00:00, 6.12MB/s]"}},"9537f67619564ed3ba037fe687755264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d86e036baa547ddbe1458d56e49afd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0f565e0bc90467d8897902984f731cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eb22b1935194193ac6884bfb93ed50f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc062b8f86174c9aa7067cd5f99bc02f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cb15ee59d534b9f925f319d5f1efbea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b82b8374cb534494bde4cc4e9f6b8040":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05ef74d1e1a54ab49cc6f678edeb1154":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f6e60e5fff043d082739ed556ebf044","IPY_MODEL_8ab1093d700149cba4adc69c77749a97","IPY_MODEL_2d626ac7cc374a7d9b60e771c3a486d7"],"layout":"IPY_MODEL_b10dc8b5149141f79d7f1a4fef8607c4"}},"0f6e60e5fff043d082739ed556ebf044":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92f4b27041924242bf1af53b71e0da7d","placeholder":"​","style":"IPY_MODEL_996a0ad2a27744bbb92abe8de2d58005","value":"Downloading (…)lve/main/config.json: 100%"}},"8ab1093d700149cba4adc69c77749a97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10b1dcdbd4d442478cfb33d1fab31576","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2460d53532234992ba6e4a7b4c57e114","value":483}},"2d626ac7cc374a7d9b60e771c3a486d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beaa5399c0d54cb2bb8c271ffba28d4f","placeholder":"​","style":"IPY_MODEL_14eed485e5c24686b24cc741eaeb002e","value":" 483/483 [00:00&lt;00:00, 32.9kB/s]"}},"b10dc8b5149141f79d7f1a4fef8607c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92f4b27041924242bf1af53b71e0da7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"996a0ad2a27744bbb92abe8de2d58005":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10b1dcdbd4d442478cfb33d1fab31576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2460d53532234992ba6e4a7b4c57e114":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"beaa5399c0d54cb2bb8c271ffba28d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14eed485e5c24686b24cc741eaeb002e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b931b9dd883403d9b1ef37b17b881d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_738671733b9b4d2eb4d8ad6cb810256d","IPY_MODEL_d784315b617946b89e444055494de1d6","IPY_MODEL_a7a66c2610e7450d9bcdd53cbf30cec8"],"layout":"IPY_MODEL_676136a65927411eb68d6cbe38c3aae4"}},"738671733b9b4d2eb4d8ad6cb810256d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced61f02a6774341881609d34458b71b","placeholder":"​","style":"IPY_MODEL_7829436c8f45465eb3b55d1d765d1165","value":"Downloading pytorch_model.bin: 100%"}},"d784315b617946b89e444055494de1d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e289a021b2b946b48db64f461c398e85","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_900a1a0d8eb44c52a5678485407f393c","value":267967963}},"a7a66c2610e7450d9bcdd53cbf30cec8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68c7be8a967e43538f8cd7909317faaa","placeholder":"​","style":"IPY_MODEL_a321875ca5f54381973efa18fd3f62cb","value":" 268M/268M [00:02&lt;00:00, 95.5MB/s]"}},"676136a65927411eb68d6cbe38c3aae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ced61f02a6774341881609d34458b71b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7829436c8f45465eb3b55d1d765d1165":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e289a021b2b946b48db64f461c398e85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900a1a0d8eb44c52a5678485407f393c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68c7be8a967e43538f8cd7909317faaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a321875ca5f54381973efa18fd3f62cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc02cc403522413ba1bdbea8e877c48a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91273b5ac793497b816c0f2b9f2b0ad1","IPY_MODEL_20206aa5b3f3425f8ccdc27e7381f8e9","IPY_MODEL_e73fca752bc94121bc99bcc6dd4c2b15"],"layout":"IPY_MODEL_6615e61dfed34a4990c1de16daf289d6"}},"91273b5ac793497b816c0f2b9f2b0ad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4208dca6401c48139d8a74169b7978c9","placeholder":"​","style":"IPY_MODEL_769fbd8c81194e639fb08d8ddf8208db","value":"Downloading (…)okenizer_config.json: 100%"}},"20206aa5b3f3425f8ccdc27e7381f8e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b3ac426757e44b98f87be1ec767eeac","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f96db9a22b224f93bd4acd36797756b8","value":28}},"e73fca752bc94121bc99bcc6dd4c2b15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53823ee214b74d5594fda2b26e738cf3","placeholder":"​","style":"IPY_MODEL_efacf4050e2f4457a714b4a45807d3a5","value":" 28.0/28.0 [00:00&lt;00:00, 1.30kB/s]"}},"6615e61dfed34a4990c1de16daf289d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4208dca6401c48139d8a74169b7978c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"769fbd8c81194e639fb08d8ddf8208db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b3ac426757e44b98f87be1ec767eeac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f96db9a22b224f93bd4acd36797756b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53823ee214b74d5594fda2b26e738cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efacf4050e2f4457a714b4a45807d3a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9aaa873f53724f989fbc1859d760ed63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bb5d96cd3844a87b359765af77ec695","IPY_MODEL_850cb826e12347afa6344ac5535a71b3","IPY_MODEL_6c31bccbed4e48308f231698f874c14c"],"layout":"IPY_MODEL_6573e7b66ca24338aeb13ba30d6d5e2a"}},"1bb5d96cd3844a87b359765af77ec695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96677ea8c20c4390ba6e8e6fb48c5a4d","placeholder":"​","style":"IPY_MODEL_6608aaa7466d4fbf90ec6186d1cbfbe4","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"850cb826e12347afa6344ac5535a71b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_045b7e19e7d54757bf9e7a74207a5d0a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c01c4dd103a54506ae881476b571366b","value":231508}},"6c31bccbed4e48308f231698f874c14c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93a107d3092a497796f30fa75b4d67b6","placeholder":"​","style":"IPY_MODEL_3e50beb22cd84dbd8ca7c64aab173fc3","value":" 232k/232k [00:00&lt;00:00, 4.20MB/s]"}},"6573e7b66ca24338aeb13ba30d6d5e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96677ea8c20c4390ba6e8e6fb48c5a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6608aaa7466d4fbf90ec6186d1cbfbe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"045b7e19e7d54757bf9e7a74207a5d0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c01c4dd103a54506ae881476b571366b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93a107d3092a497796f30fa75b4d67b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e50beb22cd84dbd8ca7c64aab173fc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c74acd3ae9745dca21a5912769d48f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8bf05b262b44865b4119a2c310ba808","IPY_MODEL_e86f35f4fc5a42169a5c6913108cf905","IPY_MODEL_145a958cc7cc4ea6a444ad0ca7ae98c4"],"layout":"IPY_MODEL_b7957ab7653749c78caf142db9ecc47c"}},"f8bf05b262b44865b4119a2c310ba808":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ff6a6c0817d430fad3eba3fb6dcefde","placeholder":"​","style":"IPY_MODEL_1f04ebc1e44543b19149c639a9c75480","value":"Downloading (…)/main/tokenizer.json: 100%"}},"e86f35f4fc5a42169a5c6913108cf905":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4669592ceb11465cb252a70126ceaba9","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87314329550e4e9c900037ced40488d8","value":466062}},"145a958cc7cc4ea6a444ad0ca7ae98c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bd1a6098a20479db71e6b1332cf716c","placeholder":"​","style":"IPY_MODEL_a8122bcc575e40deb579191f5f084692","value":" 466k/466k [00:00&lt;00:00, 26.9MB/s]"}},"b7957ab7653749c78caf142db9ecc47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ff6a6c0817d430fad3eba3fb6dcefde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f04ebc1e44543b19149c639a9c75480":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4669592ceb11465cb252a70126ceaba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87314329550e4e9c900037ced40488d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bd1a6098a20479db71e6b1332cf716c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8122bcc575e40deb579191f5f084692":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"bsDvRbQXtElF"}},{"cell_type":"code","source":["use_colab = True\n","if use_colab:\n","    !pip install transformers[sentencepiece]\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path = \"/content/drive/MyDrive/CAPP30255_Project/twitter_disaster_detection\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":822},"id":"eVgrRprMSh3z","executionInfo":{"status":"ok","timestamp":1684810069472,"user_tz":300,"elapsed":141239,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"2abe8d2c-bfc1-4f09-9cdb-1e077ac6c9bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[sentencepiece]\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers[sentencepiece])\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece])\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.65.0)\n","Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece])\n","  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n","Installing collected packages: tokenizers, sentencepiece, protobuf, huggingface-hub, transformers\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.14.1 protobuf-3.20.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import copy\n","import pandas as pd\n","import numpy as np\n","# from tqdm.autonotebook import tqdm\n","from tqdm import tqdm\n","import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.model_selection import train_test_split, KFold\n","\n","# importing HuggingFace transformers library\n","import transformers\n","from transformers import pipeline, get_linear_schedule_with_warmup\n","\n","print(\"Transformer version:\", transformers.__version__)\n","print(\"torch.device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-15T02:35:13.559996Z","iopub.execute_input":"2023-05-15T02:35:13.560366Z","iopub.status.idle":"2023-05-15T02:35:13.566423Z","shell.execute_reply.started":"2023-05-15T02:35:13.560333Z","shell.execute_reply":"2023-05-15T02:35:13.565503Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"XqhHFJ4BSWNI","executionInfo":{"status":"ok","timestamp":1684810088992,"user_tz":300,"elapsed":16414,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"6b2f06cc-7169-4923-d9c4-c4abbea87c26"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Transformer version: 4.29.2\n","torch.device: cuda\n"]}]},{"cell_type":"code","source":["data = pd.read_csv(path+'/data/cleaned-train-tweets.csv', sep=\"|\")\n","display(data.sample(5))\n"],"metadata":{"id":"VIfVqHZTUGR1","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1684810090345,"user_tz":300,"elapsed":1355,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"207e740e-0f9e-485a-f438-c4635bb2979c"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["          id               keyword                     location  \\\n","13246  13246              flooding  Jakarta/Kuala Lumpur/S'pore   \n","16688  16688  structural%20failure                          NaN   \n","3745    3745                  fire                          NaN   \n","14069  14069               injured                      Nigeria   \n","3301    3301              evacuate                          NaN   \n","\n","                                                    text  target  \\\n","13246  Heavy Rainfall and Flooding in Northern #VietN...       1   \n","16688  Investigators say a fatal Virgin Galactic spac...       1   \n","3745      My asshole is on fire  https://t.co/Y3FO0gHg8t       0   \n","14069  Ogun smugglers engage Customs in shootoutåÊ: S...       1   \n","3301   Condemnation clearly replacing the latest resp...       1   \n","\n","                                              clean_text  \n","13246  heavy rainfall flooding northern vietnam situa...  \n","16688  investigator say fatal virgin galactic spacesh...  \n","3745                                   asshole fire http  \n","14069  ogun smuggler engage custom shootoutåê several...  \n","3301   condemnation clearly replacing latest response...  "],"text/html":["\n","  <div id=\"df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13246</th>\n","      <td>13246</td>\n","      <td>flooding</td>\n","      <td>Jakarta/Kuala Lumpur/S'pore</td>\n","      <td>Heavy Rainfall and Flooding in Northern #VietN...</td>\n","      <td>1</td>\n","      <td>heavy rainfall flooding northern vietnam situa...</td>\n","    </tr>\n","    <tr>\n","      <th>16688</th>\n","      <td>16688</td>\n","      <td>structural%20failure</td>\n","      <td>NaN</td>\n","      <td>Investigators say a fatal Virgin Galactic spac...</td>\n","      <td>1</td>\n","      <td>investigator say fatal virgin galactic spacesh...</td>\n","    </tr>\n","    <tr>\n","      <th>3745</th>\n","      <td>3745</td>\n","      <td>fire</td>\n","      <td>NaN</td>\n","      <td>My asshole is on fire  https://t.co/Y3FO0gHg8t</td>\n","      <td>0</td>\n","      <td>asshole fire http</td>\n","    </tr>\n","    <tr>\n","      <th>14069</th>\n","      <td>14069</td>\n","      <td>injured</td>\n","      <td>Nigeria</td>\n","      <td>Ogun smugglers engage Customs in shootoutåÊ: S...</td>\n","      <td>1</td>\n","      <td>ogun smuggler engage custom shootoutåê several...</td>\n","    </tr>\n","    <tr>\n","      <th>3301</th>\n","      <td>3301</td>\n","      <td>evacuate</td>\n","      <td>NaN</td>\n","      <td>Condemnation clearly replacing the latest resp...</td>\n","      <td>1</td>\n","      <td>condemnation clearly replacing latest response...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-acaf5a57-3dad-45ec-85cc-63cf8903b2d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["# BERT without fine-tuning"],"metadata":{"id":"HHT244szslHW"}},{"cell_type":"code","source":["simple_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"],"metadata":{"id":"5ykpDc3HskZV","executionInfo":{"status":"ok","timestamp":1684799595070,"user_tz":300,"elapsed":25583,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["44b334d74d2c4e48a9984c0ebacf5a65","cef152bc900e43b5ab1a895f76fc34f5","4648ae0f17994018bfd49f3f0a7a707a","752ad46cf6684b62aba58640ce2faeb4","de9d8d85cc5e48cfa8e9a12f4701499f","9da4a61c9f354abda43050299fdf20a5","07ebd7a294344e32a0167046078b6d3e","e5336389ef0848fb820d241a245dda59","07839dbc24884dd39c66a1b035fb3989","bcbf385f30614eb9978d1c5bb66ccfa3","41319da8f15f4bc59d860515231c2369","ea6a6bbb52514db29955f1f4e36791e9","574cdc4894fe4163b827871d6587afc6","143ce6d5aa8a4bffa684298240b9b768","4dd782b5dba24cde94f63752f2588069","896eec03d5a04ffb9d1a987b2d00245f","161f8c2277f6468ba9d3fc05dc9a814b","7bf52c34233e4d4690cbb39accd2a93f","c1777fe6a4ab4e41bbab377558412abc","d4198586f4a440cd8a214247bf53c618","f80ef3d3721e4719b460ab0182978dba","dd3d62449b4841b48e894a325214c127","e9697256d12a4196b2715824d62c722a","5484e3f516a141bdbd3e99c5433d2fe1","86ec42db3f414b4cac52807fd772988e","9c236fc4badc4edaad36476c0c455644","94c8fd8847a049769329b24c449a5858","e6bcbe503cbb4628b6735848980264da","ab3d8c94fd6c48a5a854d315bfacb55f","530ac8a910ab43698e54576ea43756a9","3b41ebc3030f411eac4afce86213d069","2ff53751a5d5476a88d31187ca1f6074","6dd3e13fe4424849b6fc0f97ac24f8a3","7003086a01c04da18001924c7be33022","2d4ba8117a334c1f82327481a1f53f62","5cac8a1cbf9547e68398f8df55c6a126","0419851280af4c45949b65af79ed8472","75f9f1a64f04432dac3ecad858084b7d","c39840aa92ad432187a20c6f2a97004c","04d0e0b3f03c4e299ae23ea0f4573191","13d29538c2b14f1798ba3634a3909b25","b5021de8be2e4b36b32170b25dada11f","34e0aa8c7b4349a68785eeedd2e99306","d26655555ec3417bba194c3e8477ac6d","02ff29ddc93d4339a9139f30d6a64d00","f07fe05bb723424b82db938c5b2f3c52","e4aa6a7c6a1340208f434c722bd17375","f10a938da3bd4350968198aea6e2d3e5","2663666e3f0f48f4b3c6533e55e88bd4","59e1b378ba634854aed2cc3e13b51fa7","e3f9b4c1061044d8855c09827aea1c65","d51cd1c6ea79437fa3e912914f338718","d1cc5987c892433f9f980dddbb2a4508","16ba9f692c15478fb74e272779f7a0c9","4b0bfe4a93434d849b92c410959d4422","4655f9da79ae46af8eba01896eee86c5","6ebc4b4b77b54dacba44ad72bc644070","53f767597f224a629466c330739e8561","65c4a3018d9b4f6f8578aafeb194f434","9537f67619564ed3ba037fe687755264","6d86e036baa547ddbe1458d56e49afd7","f0f565e0bc90467d8897902984f731cd","5eb22b1935194193ac6884bfb93ed50f","cc062b8f86174c9aa7067cd5f99bc02f","1cb15ee59d534b9f925f319d5f1efbea","b82b8374cb534494bde4cc4e9f6b8040"]},"outputId":"5565f87a-acc5-4221-f7f4-b1511a60ba89"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b334d74d2c4e48a9984c0ebacf5a65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea6a6bbb52514db29955f1f4e36791e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9697256d12a4196b2715824d62c722a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7003086a01c04da18001924c7be33022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ff29ddc93d4339a9139f30d6a64d00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4655f9da79ae46af8eba01896eee86c5"}},"metadata":{}}]},{"cell_type":"code","source":["labels = [\"not disaster\", \"disaster\"]\n","\n","def model_simple_test(i):\n","    \"\"\"\n","    Performs a simple test of the simple_model by predicting the label for a specific index of the input data.\n","\n","    Args:\n","        i (int): The index of the data to test.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    responce= simple_model(\n","        data[\"text\"][i],\n","        candidate_labels=labels\n","    )\n","    print(responce)\n","\n","    true_label = labels[1] if data[\"target\"][i] else labels[0]\n","    print(\"True Label:\", true_label)\n","    print(\"Prediction:\", responce[\"labels\"][np.argmax(responce[\"scores\"])])\n","\n","def calculate_accuracy_zscppl(data, target_ids):\n","    \"\"\"\n","    Calculates the accuracy of the simple_model on a subset of data specified by target_ids.\n","\n","    Args:\n","        data (dict): The input data.\n","        target_ids (list): A list of indices indicating the subset of data to calculate accuracy on.\n","\n","    Returns:\n","        accuracy (float): The accuracy of the model on the specified subset of data.\n","    \"\"\"\n","    accurate_num = 0\n","    for i in target_ids:\n","        response = simple_model(\n","            data[\"text\"][i],\n","            candidate_labels=labels\n","        )\n","        true_label = labels[1] if data[\"target\"][i] else labels[0]\n","        if true_label == response[\"labels\"][np.argmax(response[\"scores\"])]:\n","            accurate_num += 1\n","    return accurate_num / len(target_ids)\n"],"metadata":{"id":"Hdvn6CNUusF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_sample = data.sample(5)\n","data_sample_ids = data_sample[\"id\"].tolist()\n","display(data_sample)\n","\n","for id in data_sample_ids:\n","    model_simple_test(id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"Bpho3btjy3CO","executionInfo":{"status":"ok","timestamp":1684799606232,"user_tz":300,"elapsed":11177,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"92101c91-14ae-4176-acd7-7e4d71f86282"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["          id       keyword                     location  \\\n","3782    3782  fire%20truck  District 12 - Orange County   \n","9491    9491       burning                          NaN   \n","8573    8573         blaze                        Delhi   \n","9514    9514       burning          TÌÁchira, Venezuela   \n","14290  14290     landslide                          NaN   \n","\n","                                                    text  target  \\\n","3782   SIGALERT UPDATE #3***N-133 CLOSED AT 5 FWY UFN...       1   \n","9491   @aubilenon @MarkKriegsman if you think you'd l...       0   \n","8573   #socialmedia news - New Facebook Page Features...       0   \n","9514                     the Burning Legion has returned       0   \n","14290  5 need to-dos seeing as how technical writing ...       0   \n","\n","                                              clean_text  \n","3782     sigalert update closed fwy ufn trash truck fire  \n","9491   aubilenon markkriegsman think like burning man...  \n","8573   socialmedia news new facebook page feature see...  \n","9514                             burning legion returned  \n","14290  need seeing technical writing administer apps ...  "],"text/html":["\n","  <div id=\"df-e1921da3-68d7-4b62-8011-2fe14a0cdd41\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3782</th>\n","      <td>3782</td>\n","      <td>fire%20truck</td>\n","      <td>District 12 - Orange County</td>\n","      <td>SIGALERT UPDATE #3***N-133 CLOSED AT 5 FWY UFN...</td>\n","      <td>1</td>\n","      <td>sigalert update closed fwy ufn trash truck fire</td>\n","    </tr>\n","    <tr>\n","      <th>9491</th>\n","      <td>9491</td>\n","      <td>burning</td>\n","      <td>NaN</td>\n","      <td>@aubilenon @MarkKriegsman if you think you'd l...</td>\n","      <td>0</td>\n","      <td>aubilenon markkriegsman think like burning man...</td>\n","    </tr>\n","    <tr>\n","      <th>8573</th>\n","      <td>8573</td>\n","      <td>blaze</td>\n","      <td>Delhi</td>\n","      <td>#socialmedia news - New Facebook Page Features...</td>\n","      <td>0</td>\n","      <td>socialmedia news new facebook page feature see...</td>\n","    </tr>\n","    <tr>\n","      <th>9514</th>\n","      <td>9514</td>\n","      <td>burning</td>\n","      <td>TÌÁchira, Venezuela</td>\n","      <td>the Burning Legion has returned</td>\n","      <td>0</td>\n","      <td>burning legion returned</td>\n","    </tr>\n","    <tr>\n","      <th>14290</th>\n","      <td>14290</td>\n","      <td>landslide</td>\n","      <td>NaN</td>\n","      <td>5 need to-dos seeing as how technical writing ...</td>\n","      <td>0</td>\n","      <td>need seeing technical writing administer apps ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1921da3-68d7-4b62-8011-2fe14a0cdd41')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1921da3-68d7-4b62-8011-2fe14a0cdd41 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1921da3-68d7-4b62-8011-2fe14a0cdd41');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'sequence': 'SIGALERT UPDATE #3***N-133 CLOSED AT 5 FWY UFN***- TRASH TRUCK FIRE', 'labels': ['disaster', 'not disaster'], 'scores': [0.9129602909088135, 0.08703970164060593]}\n","True Label: disaster\n","Prediction: disaster\n","{'sequence': \"@aubilenon @MarkKriegsman if you think you'd like burning man you should try it because it's the only way to know!\", 'labels': ['disaster', 'not disaster'], 'scores': [0.7511258721351624, 0.24887412786483765]}\n","True Label: not disaster\n","Prediction: disaster\n","{'sequence': '#socialmedia news - New Facebook Page Features Seek to Help Personalize the Customer Experience http://t.co/nbizaTlsmV', 'labels': ['not disaster', 'disaster'], 'scores': [0.9289625883102417, 0.07103737443685532]}\n","True Label: not disaster\n","Prediction: not disaster\n","{'sequence': 'the Burning Legion has returned', 'labels': ['disaster', 'not disaster'], 'scores': [0.9670848250389099, 0.0329151451587677]}\n","True Label: not disaster\n","Prediction: disaster\n","{'sequence': '5 need to-dos seeing as how technical writing administer apps that landslide: QCt', 'labels': ['disaster', 'not disaster'], 'scores': [0.9608525633811951, 0.03914748877286911]}\n","True Label: not disaster\n","Prediction: disaster\n"]}]},{"cell_type":"code","source":["num_target = 50\n","target_ids = [random.randint(0, len(data)) for _ in range(num_target)]\n","accuracy_rate = calculate_accuracy_zscppl(data, target_ids)\n","print(f\"Accuracy Rate using Pretrained BERT Zero-Shot-Classification: {accuracy_rate}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4DGs3zuQYDV","executionInfo":{"status":"ok","timestamp":1684799676970,"user_tz":300,"elapsed":70751,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"7e6b0ced-c4cd-4e24-8906-8adb061dab7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Rate using Pretrained BERT Zero-Shot-Classification: 0.6\n"]}]},{"cell_type":"markdown","source":["# DistilBERT model with fine-tuning"],"metadata":{"id":"Xlra61nRSWNH"}},{"cell_type":"markdown","source":["## Preparation"],"metadata":{"id":"lR4EcMBspGGz"}},{"cell_type":"markdown","source":["### Building A PyTorch Dataset\n","\n","The following code uses the idea from this tutorial [Fine-tuning with custom datasets](https://huggingface.co/transformers/v3.2.0/custom_datasets.html) on building a custom dataset:\n"],"metadata":{"id":"to5qz7VUSWNJ"}},{"cell_type":"code","source":["class TweetDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataframe, tokenizer, mode=\"train\", max_length=None):\n","        \"\"\"\n","        A custom PyTorch dataset for handling tweet data.\n","\n","        Args:\n","            dataframe: The input dataframe containing tweet data.\n","            tokenizer: The tokenizer object used to tokenize the tweets.\n","            mode (str): The mode of the dataset (default is \"train\").\n","            max_length (int): The maximum length of the tokenized sequences (default is None).\n","        \"\"\"\n","        self.dataframe = dataframe\n","        self.mode = mode\n","        if mode != \"test\":\n","            self.targets = dataframe['target'].values\n","        texts = list(dataframe['text'].values)\n","        self.encodings = tokenizer(texts, \n","                                   padding=True, \n","                                   truncation=True, \n","                                   max_length=max_length)\n","\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Retrieves the item at the given index from the dataset.\n","\n","        Args:\n","            idx (int): The index of the item to retrieve.\n","\n","        Returns:\n","            item (dict): A dictionary containing the input IDs, attention masks, and labels (if available) of the item.\n","        \"\"\"\n","        item = {}\n","        for key, values in self.encodings.items():\n","            item[key] = torch.tensor(values[idx])\n","\n","        if self.mode != \"test\":\n","            item['labels'] = torch.tensor(self.targets[idx])\n","        return item\n","\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the length of the dataset.\n","\n","        Returns:\n","            length (int): The length of the dataset.\n","        \"\"\"\n","        return len(self.dataframe)\n","\n","\n","def make_loaders(dataframe, tokenizer, mode=\"train\", max_length=None):\n","    \"\"\"\n","    Creates data loaders for the tweet dataset.\n","\n","    Args:\n","        dataframe: The input dataframe containing tweet data.\n","        tokenizer: The tokenizer object used to tokenize the tweets.\n","        mode (str): The mode of the dataset (default is \"train\").\n","        max_length (int): The maximum length of the tokenized sequences (default is None).\n","\n","    Returns:\n","        dataloader (torch.utils.data.DataLoader): The data loader for the tweet dataset.\n","    \"\"\"\n","    dataset = TweetDataset(dataframe, tokenizer, mode, max_length=max_length)\n","    dataloader = torch.utils.data.DataLoader(dataset, \n","                                             batch_size=parameters.batch_size, \n","                                             shuffle=True if mode == \"train\" else False,\n","                                             num_workers=parameters.num_workers)\n","    return dataloader\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:35:50.271667Z","iopub.execute_input":"2023-05-15T02:35:50.272029Z","iopub.status.idle":"2023-05-15T02:35:50.280718Z","shell.execute_reply.started":"2023-05-15T02:35:50.271998Z","shell.execute_reply":"2023-05-15T02:35:50.279451Z"},"trusted":true,"id":"MXAsAhBSSWNJ","executionInfo":{"status":"ok","timestamp":1684810090346,"user_tz":300,"elapsed":4,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Construction of DistilBERT"],"metadata":{"id":"2Sy9YmZISWNK"}},{"cell_type":"code","source":["class CustomModel(nn.Module):\n","    def __init__(self,\n","                 bert_model,\n","                 num_labels, \n","                 bert_hidden_dim=768, \n","                 classifier_hidden_dim=768, \n","                 dropout=None):\n","        \"\"\"\n","        Initializes an instance of the CustomModel class. It takes the following arguments:\n","        Args: \n","          bert_model: \n","            The pre-trained BERT model to be used as the base model.\n","          num_labels:\n","            The number of output labels for classification.\n","          bert_hidden_dim:\n","            The dimensionality of the hidden states in the BERT model \n","            (default is 768).\n","          classifier_hidden_dim:\n","            The dimensionality of the hidden states in the classifier layers \n","            (default is 768).\n","          dropout: \n","            The dropout probability to be applied in the classifier layers \n","            (default is None). If it is None, dropout is not applied.\n","        \"\"\"\n","\n","        super().__init__()\n","        self.bert_model = bert_model\n","        if not dropout:\n","            self.head = nn.Sequential(nn.Linear(bert_hidden_dim, classifier_hidden_dim),\n","                                      nn.ReLU(),\n","                                      nn.Dropout(dropout),\n","                                      nn.Linear(classifier_hidden_dim, num_labels))\n","        else:\n","            self.head = nn.Sequential(nn.Linear(bert_hidden_dim, classifier_hidden_dim),\n","                                      nn.ReLU(),\n","                                      nn.Identity(),\n","                                      nn.Linear(classifier_hidden_dim, num_labels))\n","\n","    def forward(self, batch):\n","        output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n","        CLS_token_state = output.last_hidden_state[:, 0, :]\n","        return self.head(CLS_token_state)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:06.249683Z","iopub.execute_input":"2023-05-15T02:37:06.250030Z","iopub.status.idle":"2023-05-15T02:37:06.258344Z","shell.execute_reply.started":"2023-05-15T02:37:06.249998Z","shell.execute_reply":"2023-05-15T02:37:06.257103Z"},"trusted":true,"id":"PEMceatFSWNK","executionInfo":{"status":"ok","timestamp":1684810094451,"user_tz":300,"elapsed":108,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Training and Evaluation"],"metadata":{"id":"xzwgKxINSWNL"}},{"cell_type":"code","source":["class AverageCalculator:\n","    def __init__(self, name=\"Metric\"):\n","        self.name = name\n","        self.reset()\n","\n","    def reset(self):\n","        \"\"\"\n","        Reset the calculator by setting the average, sum, and count values to zero.\n","        \"\"\"\n","        self.avg, self.sum, self.count = [0]*3\n","\n","    def update(self, val, count=1):\n","        \"\"\"\n","        Update the calculator with a new value.\n","\n","        Parameters:\n","            val (float): The new value to be added.\n","            count (int, optional): The number of instances the value represents (default is 1).\n","        \"\"\"\n","        self.count += count\n","        self.sum += val * count\n","        self.avg = self.sum / self.count\n","\n","    def __repr__(self):\n","        \"\"\"\n","        Return a string representation of the calculator object.\n","\n","        Returns:\n","            str: A string displaying the name of the metric and its average value rounded to four decimal places.\n","        \"\"\"\n","        text = f\"{self.name}: {self.avg:.4f}\"\n","        return text\n","\n","\n","def one_epoch(model, criterion, loader, device, optimizer=None,\n","              lr_scheduler=None, mode=\"train\", step=\"batch\"):\n","    \"\"\"\n","    Executes one epoch of training or evaluation for a given model.\n","\n","    Args:\n","        model (nn.Module): The model to be trained or evaluated.\n","        criterion: The loss function used for training or evaluation.\n","        loader: The data loader containing the input data.\n","        device: The device (CPU or GPU) to be used for computation.\n","        optimizer: The optimizer used for training. Default is None.\n","        lr_scheduler: The learning rate scheduler. Default is None.\n","        mode (str): The mode of operation. Can be \"train\" or \"eval\". Default is \"train\".\n","        step (str): The step size for the learning rate scheduler. Can be \"batch\" or \"epoch\". Default is \"batch\".\n","\n","    Returns:\n","        Tuple: A tuple containing the average loss and accuracy calculated during the epoch.\n","    \"\"\"\n","    loss_calculator = AverageCalculator()\n","    accuracy_calculator = AverageCalculator()\n","    \n","    tqdm_object = tqdm(loader, total=len(loader))\n","    for batch in tqdm_object:\n","        batch = {}\n","        for k, v in batch.items():\n","            batch[k] = v.to(device)\n","        preds = model(batch)\n","        loss = criterion(preds, batch['labels'])\n","        if mode == \"train\":\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if step == \"batch\":\n","                lr_scheduler.step()\n","                \n","        count = batch['input_ids'].size(0)\n","        loss_calculator.update(loss.item(), count)\n","\n","        accuracy = get_accuracy(preds.detach(), batch['labels'])\n","        accuracy_calculator.update(accuracy.item(), count)\n","        if mode == \"train\":\n","            tqdm_object.set_postfix(loss=loss_calculator.avg,\n","                                    accuracy=accuracy_calculator.avg,\n","                                    lr=get_lr(optimizer))\n","        else:\n","            tqdm_object.set_postfix(loss=loss_calculator.avg,\n","                                    accuracy=accuracy_calculator.avg)\n","    \n","    return loss_calculator, accuracy_calculator\n","\n","def get_lr(optimizer):\n","    \"\"\"\n","    Returns the current learning rate of the optimizer.\n","\n","    Args:\n","        optimizer: The optimizer.\n","\n","    Returns:\n","        float: The current learning rate.\n","    \"\"\"\n","    for param_group in optimizer.param_groups:\n","        return param_group[\"lr\"]\n","\n","def get_accuracy(preds, targets):\n","    \"\"\"\n","    Calculates the accuracy given the predicted and target labels.\n","\n","    Args:\n","        preds (torch.Tensor): The predicted labels. Shape: (batch_size, num_labels)\n","        targets (torch.Tensor): The target labels. Shape: (batch_size)\n","\n","    Returns:\n","        torch.Tensor: The accuracy value.\n","    \"\"\"\n","    preds = preds.argmax(dim=1)\n","    acc = (preds == targets).float().mean()\n","    return acc\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:09.732149Z","iopub.execute_input":"2023-05-15T02:37:09.732539Z","iopub.status.idle":"2023-05-15T02:37:09.746732Z","shell.execute_reply.started":"2023-05-15T02:37:09.732503Z","shell.execute_reply":"2023-05-15T02:37:09.745558Z"},"trusted":true,"id":"mkTjvwGKSWNL","executionInfo":{"status":"ok","timestamp":1684810096600,"user_tz":300,"elapsed":89,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train_eval(num_epochs, model, train_loader, valid_loader,\n","               criterion, optimizer, device, parameters, loss_accuracy, lr_scheduler=None):\n","    \"\"\"\n","    Train and evaluate the model for a specified number of epochs.\n","\n","    Args:\n","        num_epochs (int): The number of epochs to train.\n","        model (nn.Module): The model to train and evaluate.\n","        train_loader (DataLoader): The data loader for training data.\n","        valid_loader (DataLoader): The data loader for validation data.\n","        criterion: The loss function.\n","        optimizer: The optimizer for updating model parameters.\n","        device: The device to run the model on.\n","        parameters: Additional parameters for training and evaluation.\n","        loss_accuracy (dict): A dictionary to store the loss and accuracy values.\n","        lr_scheduler: The learning rate scheduler (default: None).\n","\n","    Returns:\n","        None\n","    \"\"\"\n","\n","    best_loss = float('inf')\n","    best_model_weights = copy.deepcopy(model.state_dict())\n","\n","    # Loop over the specified number of epochs\n","    for epoch in range(num_epochs):\n","        print(\"~\" * 30)\n","        print(f\"Epoch {epoch + 1}\")\n","        current_lr = get_lr(optimizer)\n","\n","        # Set the model in training mode\n","        model.train()\n","        # Perform one epoch of training\n","        train_loss, train_acc = one_epoch(model,\n","                                          criterion,\n","                                          train_loader,\n","                                          device,\n","                                          optimizer=optimizer,\n","                                          lr_scheduler=lr_scheduler,\n","                                          mode=\"train\",\n","                                          step=parameters.step)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            valid_loss, valid_acc = one_epoch(model,\n","                                              criterion,\n","                                              valid_loader,\n","                                              device,\n","                                              optimizer=None,\n","                                              lr_scheduler=None,\n","                                              mode=\"valid\")\n","\n","        # Check if the current validation loss is better than the best loss so far\n","        if valid_loss.avg < best_loss:\n","            best_loss = valid_loss.avg\n","            best_model_weights = copy.deepcopy(model.state_dict())\n","            print(\"Saving the best model!\")\n","            torch.save(model.state_dict(),\n","                       f'{parameters.model_path}/{parameters.model_save_name}')\n","\n","        # Update learning rate if lr_scheduler is ReduceLROnPlateau\n","        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n","            lr_scheduler.step(valid_loss.avg)\n","\n","            # If the learning rate has changed, reload the previous best model weights\n","            if current_lr != get_lr(optimizer):\n","                print(\"Loading the best model weights!\")\n","                model.load_state_dict(torch.load(f'{parameters.model_path}/{parameters.model_save_name}',\n","                                                 map_location=device))\n","\n","        print(f\"Train Loss: {train_loss.avg:.5f}\")\n","        print(f\"Train Accuracy: {train_acc.avg:.5f}\")\n","\n","        print(f\"Valid Loss: {valid_loss.avg:.5f}\")\n","        print(f\"Valid Accuracy: {valid_acc.avg:.5f}\")\n","        print(\"*\" * 30)\n","\n","        # Store loss and accuracy values in the provided dictionary\n","        loss_accuracy[\"Train Loss\"].append(train_loss.avg)\n","        loss_accuracy[\"Train Accuracy\"].append(train_acc.avg)\n","        loss_accuracy[\"Valid Loss\"].append(valid_loss.avg)\n","        loss_accuracy[\"Valid Accuracy\"].append(valid_acc.avg)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:14.338616Z","iopub.execute_input":"2023-05-15T02:37:14.338954Z","iopub.status.idle":"2023-05-15T02:37:14.349969Z","shell.execute_reply.started":"2023-05-15T02:37:14.338924Z","shell.execute_reply":"2023-05-15T02:37:14.348719Z"},"trusted":true,"id":"EOerwOCGSWNL","executionInfo":{"status":"ok","timestamp":1684810098739,"user_tz":300,"elapsed":124,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### K-Fold Cross Validation"],"metadata":{"id":"s_AZ3wc-SWNM"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import pandas as pd\n","\n","def create_folds(data, num_folds=5):\n","    \"\"\"\n","    Create fold column in the dataframe for cross-validation.\n","\n","    Args:\n","        data (pandas.DataFrame): The dataframe.\n","        num_folds (int, optional): Number of folds to create (default is 5).\n","\n","    Returns:\n","        pandas.DataFrame: The dataframe with the fold column added.\n","    \"\"\"\n","    # Create an instance of KFold class and split the data\n","    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n","    for fold_index, (_, valid_index) in enumerate(kfold.split(X=data['id'])):\n","        # Update the fold column in the dataframe using the valid indices\n","        data.loc[valid_index, 'fold'] = fold_index\n","    return data\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:23.993766Z","iopub.execute_input":"2023-05-15T02:37:23.994118Z","iopub.status.idle":"2023-05-15T02:37:23.999710Z","shell.execute_reply.started":"2023-05-15T02:37:23.994084Z","shell.execute_reply":"2023-05-15T02:37:23.998736Z"},"trusted":true,"id":"zcbxzg-uSWNM","executionInfo":{"status":"ok","timestamp":1684810100968,"user_tz":300,"elapsed":2,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def one_fold(fold, parameters):  \n","    \"\"\"\n","    Perform training for a single fold of the dataset.\n","\n","    Args:\n","        fold (int): The fold number.\n","        parameters: An object containing various parameters and configurations.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    print(f\"Training Fold: {fold}\")\n","    loss_accuracy = {\"Train Loss\": [], \"Train Accuracy\": [], \"Valid Loss\": [], \"Valid Accuracy\": []}\n","\n","    # Load pre-trained BERT model\n","    bert_model = transformers.DistilBertModel.from_pretrained(parameters.model_name)\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(parameters.model_name, use_fast=True)\n","    \n","    # Read the cleaned training tweets data\n","    dataframe = pd.read_csv(path+'/data/cleaned-train-tweets.csv', sep=\"|\")\n","    # Create folds in the dataframe for cross-validation\n","    dataframe = create_folds(dataframe, n_splits=parameters.n_folds)\n","    train_dataframe = dataframe[dataframe['fold'] != fold].reset_index(drop=True)\n","    valid_dataframe = dataframe[dataframe['fold'] == fold].reset_index(drop=True)\n","\n","    # Create data loaders for training and validation datasets\n","    train_loader = make_loaders(train_dataframe, \n","                                tokenizer, \n","                                \"train\", \n","                                parameters.max_length)\n","    valid_loader = make_loaders(valid_dataframe, \n","                                tokenizer, \n","                                \"valid\", \n","                                parameters.max_length)\n","\n","    # Set device (GPU if available, otherwise CPU)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # Create custom model using the BERT model\n","    model = CustomModel(bert_model, parameters.num_labels, dropout=parameters.dropout).to(device)\n","    # Define the optimizer for model parameters\n","    optimizer = torch.optim.Adam(model.parameters(), lr=parameters.learning_rate)\n","    \n","    # Set the learning rate scheduler based on the specified parameters\n","    if parameters.scheduler == \"ReduceLROnPlateau\":\n","        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n","                                                                  mode=\"min\", \n","                                                                  factor=0.5, \n","                                                                  patience=parameters.patience)\n","\n","        parameters.step = \"epoch\"\n","        \n","    elif parameters.scheduler == \"LinearWarmup\":\n","        num_train_steps = len(train_loader) * parameters.epochs\n","        lr_scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                       num_warmup_steps=0, \n","                                                       num_training_steps=num_train_steps)\n","        \n","        # Specify when to step the scheduler: after an epoch or after a batch\n","        parameters.step = \"batch\"\n","    \n","    # Define the loss criterion\n","    criterion = nn.CrossEntropyLoss()\n","    parameters.model_save_name = f\"model_fold_{fold}.pt\"\n","    # Perform the training and evaluation\n","    train_eval(parameters.epochs, model, train_loader, valid_loader,\n","               criterion, optimizer, device, parameters, loss_accuracy, lr_scheduler=lr_scheduler)\n","\n","    # Uncomment the code below if you want to save the loss and accuracy as a JSON file\n","    # tf = open(f\"{path}/models/loss_accuracy_{fold}.json\", \"x\")\n","    # json.dump(loss_accuracy, tf)\n","    # tf.close()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:25.103721Z","iopub.execute_input":"2023-05-15T02:37:25.104074Z","iopub.status.idle":"2023-05-15T02:37:25.115414Z","shell.execute_reply.started":"2023-05-15T02:37:25.104042Z","shell.execute_reply":"2023-05-15T02:37:25.114344Z"},"trusted":true,"id":"S3cM655NSWNM","executionInfo":{"status":"ok","timestamp":1684810101385,"user_tz":300,"elapsed":2,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_folds(parameters):\n","    \"\"\"\n","    Perform training for all folds of the dataset.\n","\n","    Args:\n","        parameters: An object containing various parameters and configurations.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    n_folds = parameters.n_folds\n","    for i in range(n_folds):\n","        # Train and evaluate for each fold\n","        one_fold(fold=i, parameters=parameters)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:25.972069Z","iopub.execute_input":"2023-05-15T02:37:25.972455Z","iopub.status.idle":"2023-05-15T02:37:25.977449Z","shell.execute_reply.started":"2023-05-15T02:37:25.972422Z","shell.execute_reply":"2023-05-15T02:37:25.976345Z"},"trusted":true,"id":"InHEqq1rSWNM","executionInfo":{"status":"ok","timestamp":1684810103191,"user_tz":300,"elapsed":2,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Tuning"],"metadata":{"id":"CRtAQoJIhLq-"}},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 32\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XZI0mrZvbhM","executionInfo":{"status":"ok","timestamp":1684802010127,"user_tz":300,"elapsed":948860,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"ed2dec67-ccdb-4ac5-906e-0511c9a83813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.39it/s, accuracy=0.835, loss=0.396, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.20it/s, accuracy=0.861, loss=0.369]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39624\n","Train Accuracy: 0.83484\n","Valid Loss: 0.36893\n","Valid Accuracy: 0.86148\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.40it/s, accuracy=0.901, loss=0.266, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.46it/s, accuracy=0.884, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26632\n","Train Accuracy: 0.90085\n","Valid Loss: 0.29943\n","Valid Accuracy: 0.88373\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.41it/s, accuracy=0.941, loss=0.163, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.46it/s, accuracy=0.9, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16299\n","Train Accuracy: 0.94113\n","Valid Loss: 0.29887\n","Valid Accuracy: 0.89964\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.82, loss=0.414, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.45it/s, accuracy=0.87, loss=0.335]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41373\n","Train Accuracy: 0.82038\n","Valid Loss: 0.33518\n","Valid Accuracy: 0.86976\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.896, loss=0.273, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.42it/s, accuracy=0.878, loss=0.313]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27293\n","Train Accuracy: 0.89557\n","Valid Loss: 0.31261\n","Valid Accuracy: 0.87804\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.41it/s, accuracy=0.944, loss=0.165, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.23it/s, accuracy=0.893, loss=0.311]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16510\n","Train Accuracy: 0.94365\n","Valid Loss: 0.31143\n","Valid Accuracy: 0.89282\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.41it/s, accuracy=0.828, loss=0.4, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.09it/s, accuracy=0.86, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39955\n","Train Accuracy: 0.82770\n","Valid Loss: 0.33870\n","Valid Accuracy: 0.86016\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.902, loss=0.261, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.18it/s, accuracy=0.897, loss=0.278]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26119\n","Train Accuracy: 0.90159\n","Valid Loss: 0.27786\n","Valid Accuracy: 0.89654\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 385/385 [01:27<00:00,  4.42it/s, accuracy=0.943, loss=0.154, lr=3e-5]\n","100%|██████████| 193/193 [00:15<00:00, 12.18it/s, accuracy=0.888, loss=0.311]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.15444\n","Train Accuracy: 0.94251\n","Valid Loss: 0.31078\n","Valid Accuracy: 0.88793\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93uwwAE_vbCG","executionInfo":{"status":"ok","timestamp":1684802883780,"user_tz":300,"elapsed":873669,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"157b35d5-bb7a-4abe-e92a-89d43bf67f76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.825, loss=0.408, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.80it/s, accuracy=0.859, loss=0.347]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40761\n","Train Accuracy: 0.82485\n","Valid Loss: 0.34736\n","Valid Accuracy: 0.85905\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.282, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.872, loss=0.318]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28239\n","Train Accuracy: 0.89346\n","Valid Loss: 0.31829\n","Valid Accuracy: 0.87187\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.93, loss=0.191, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.888, loss=0.313]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19137\n","Train Accuracy: 0.93017\n","Valid Loss: 0.31318\n","Valid Accuracy: 0.88828\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.817, loss=0.418, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.86, loss=0.346]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41810\n","Train Accuracy: 0.81697\n","Valid Loss: 0.34594\n","Valid Accuracy: 0.85986\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.283, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.885, loss=0.305]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28280\n","Train Accuracy: 0.89306\n","Valid Loss: 0.30509\n","Valid Accuracy: 0.88503\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.935, loss=0.188, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.892, loss=0.315]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.18823\n","Train Accuracy: 0.93479\n","Valid Loss: 0.31475\n","Valid Accuracy: 0.89185\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.821, loss=0.414, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.66it/s, accuracy=0.859, loss=0.35]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41384\n","Train Accuracy: 0.82113\n","Valid Loss: 0.35003\n","Valid Accuracy: 0.85870\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.891, loss=0.287, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.61it/s, accuracy=0.885, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28655\n","Train Accuracy: 0.89112\n","Valid Loss: 0.30893\n","Valid Accuracy: 0.88485\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.193, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.899, loss=0.279]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19258\n","Train Accuracy: 0.93245\n","Valid Loss: 0.27942\n","Valid Accuracy: 0.89881\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 128\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GIGRP_CvhI0","executionInfo":{"status":"ok","timestamp":1684803748399,"user_tz":300,"elapsed":864651,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"3ac808f5-b0a2-4546-ee89-2519f6bc11fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.807, loss=0.439, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.31it/s, accuracy=0.857, loss=0.359]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43871\n","Train Accuracy: 0.80666\n","Valid Loss: 0.35905\n","Valid Accuracy: 0.85661\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.883, loss=0.307, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.27it/s, accuracy=0.87, loss=0.329]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.30734\n","Train Accuracy: 0.88331\n","Valid Loss: 0.32878\n","Valid Accuracy: 0.87009\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.921, loss=0.223, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.30it/s, accuracy=0.891, loss=0.307]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.22275\n","Train Accuracy: 0.92140\n","Valid Loss: 0.30688\n","Valid Accuracy: 0.89071\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.812, loss=0.432, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.28it/s, accuracy=0.854, loss=0.363]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43164\n","Train Accuracy: 0.81202\n","Valid Loss: 0.36299\n","Valid Accuracy: 0.85450\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:19<00:00,  1.23it/s, accuracy=0.878, loss=0.307, lr=3e-5]\n","100%|██████████| 49/49 [00:15<00:00,  3.26it/s, accuracy=0.872, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.30695\n","Train Accuracy: 0.87795\n","Valid Loss: 0.33933\n","Valid Accuracy: 0.87204\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.92, loss=0.224, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.28it/s, accuracy=0.883, loss=0.333]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.22383\n","Train Accuracy: 0.92018\n","Valid Loss: 0.33326\n","Valid Accuracy: 0.88308\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.806, loss=0.441, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.35it/s, accuracy=0.857, loss=0.351]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44064\n","Train Accuracy: 0.80627\n","Valid Loss: 0.35106\n","Valid Accuracy: 0.85724\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.882, loss=0.311, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.38it/s, accuracy=0.876, loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31060\n","Train Accuracy: 0.88154\n","Valid Loss: 0.31368\n","Valid Accuracy: 0.87559\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [01:18<00:00,  1.23it/s, accuracy=0.917, loss=0.234, lr=3e-5]\n","100%|██████████| 49/49 [00:14<00:00,  3.38it/s, accuracy=0.888, loss=0.297]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.23450\n","Train Accuracy: 0.91702\n","Valid Loss: 0.29747\n","Valid Accuracy: 0.88761\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRSerzeH2vT_","executionInfo":{"status":"ok","timestamp":1684804619388,"user_tz":300,"elapsed":871005,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"78085474-30a2-4e59-fff9-ec48da629685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.826, loss=0.409, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.73it/s, accuracy=0.851, loss=0.357]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40899\n","Train Accuracy: 0.82639\n","Valid Loss: 0.35676\n","Valid Accuracy: 0.85060\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.891, loss=0.285, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.867, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28516\n","Train Accuracy: 0.89143\n","Valid Loss: 0.33968\n","Valid Accuracy: 0.86716\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.189, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.887, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18873\n","Train Accuracy: 0.93179\n","Valid Loss: 0.30920\n","Valid Accuracy: 0.88714\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.819, loss=0.416, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.70it/s, accuracy=0.868, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41588\n","Train Accuracy: 0.81900\n","Valid Loss: 0.34047\n","Valid Accuracy: 0.86765\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.895, loss=0.278, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.887, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27804\n","Train Accuracy: 0.89476\n","Valid Loss: 0.30867\n","Valid Accuracy: 0.88665\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.934, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.904, loss=0.285]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18642\n","Train Accuracy: 0.93366\n","Valid Loss: 0.28461\n","Valid Accuracy: 0.90419\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.819, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.67it/s, accuracy=0.863, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41302\n","Train Accuracy: 0.81926\n","Valid Loss: 0.33852\n","Valid Accuracy: 0.86292\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.281, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.63it/s, accuracy=0.887, loss=0.307]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28063\n","Train Accuracy: 0.89290\n","Valid Loss: 0.30682\n","Valid Accuracy: 0.88696\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.935, loss=0.183, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.67it/s, accuracy=0.901, loss=0.279]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18279\n","Train Accuracy: 0.93513\n","Valid Loss: 0.27861\n","Valid Accuracy: 0.90141\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 4\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBGlFVf824LX","executionInfo":{"status":"ok","timestamp":1684805496067,"user_tz":300,"elapsed":876152,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"603597c5-6416-4aba-c6ab-f703324679cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.817, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.848, loss=0.373]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41296\n","Train Accuracy: 0.81746\n","Valid Loss: 0.37315\n","Valid Accuracy: 0.84784\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.896, loss=0.28, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.73it/s, accuracy=0.873, loss=0.312]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27979\n","Train Accuracy: 0.89557\n","Valid Loss: 0.31200\n","Valid Accuracy: 0.87301\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.933, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.897, loss=0.296]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18627\n","Train Accuracy: 0.93350\n","Valid Loss: 0.29639\n","Valid Accuracy: 0.89704\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.823, loss=0.407, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.867, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40715\n","Train Accuracy: 0.82306\n","Valid Loss: 0.33856\n","Valid Accuracy: 0.86749\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.893, loss=0.282, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.89, loss=0.293]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28229\n","Train Accuracy: 0.89306\n","Valid Loss: 0.29268\n","Valid Accuracy: 0.88990\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.935, loss=0.189, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.74it/s, accuracy=0.898, loss=0.276]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18892\n","Train Accuracy: 0.93471\n","Valid Loss: 0.27601\n","Valid Accuracy: 0.89818\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.822, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.62it/s, accuracy=0.861, loss=0.349]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41310\n","Train Accuracy: 0.82243\n","Valid Loss: 0.34871\n","Valid Accuracy: 0.86097\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.892, loss=0.286, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.68it/s, accuracy=0.879, loss=0.312]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28591\n","Train Accuracy: 0.89217\n","Valid Loss: 0.31213\n","Valid Accuracy: 0.87900\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.193, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.65it/s, accuracy=0.902, loss=0.268]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19294\n","Train Accuracy: 0.93204\n","Valid Loss: 0.26834\n","Valid Accuracy: 0.90239\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 164\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 8\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVANY9xo26LY","executionInfo":{"status":"ok","timestamp":1684806328598,"user_tz":300,"elapsed":832542,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"ce31b4fe-3f70-4bbd-a3e3-55e4d9c73190"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.813, loss=0.436, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.67it/s, accuracy=0.851, loss=0.366]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43580\n","Train Accuracy: 0.81267\n","Valid Loss: 0.36562\n","Valid Accuracy: 0.85125\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.881, loss=0.314, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.65it/s, accuracy=0.865, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31400\n","Train Accuracy: 0.88112\n","Valid Loss: 0.33951\n","Valid Accuracy: 0.86505\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.915, loss=0.238, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.66it/s, accuracy=0.882, loss=0.319]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.23828\n","Train Accuracy: 0.91539\n","Valid Loss: 0.31860\n","Valid Accuracy: 0.88178\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.806, loss=0.443, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.64it/s, accuracy=0.861, loss=0.351]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44344\n","Train Accuracy: 0.80641\n","Valid Loss: 0.35062\n","Valid Accuracy: 0.86148\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.876, loss=0.319, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.64it/s, accuracy=0.879, loss=0.324]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31884\n","Train Accuracy: 0.87568\n","Valid Loss: 0.32432\n","Valid Accuracy: 0.87934\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.909, loss=0.244, lr=3e-5]\n","100%|██████████| 38/38 [00:14<00:00,  2.66it/s, accuracy=0.877, loss=0.328]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.24363\n","Train Accuracy: 0.90905\n","Valid Loss: 0.32769\n","Valid Accuracy: 0.87675\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.811, loss=0.438, lr=3e-5]\n","100%|██████████| 38/38 [00:13<00:00,  2.83it/s, accuracy=0.859, loss=0.352]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.43805\n","Train Accuracy: 0.81098\n","Valid Loss: 0.35230\n","Valid Accuracy: 0.85886\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.879, loss=0.316, lr=3e-5]\n","100%|██████████| 38/38 [00:13<00:00,  2.82it/s, accuracy=0.879, loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.31595\n","Train Accuracy: 0.87886\n","Valid Loss: 0.31393\n","Valid Accuracy: 0.87884\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 76/76 [01:16<00:00,  1.00s/it, accuracy=0.913, loss=0.242, lr=3e-5]\n","100%|██████████| 38/38 [00:13<00:00,  2.79it/s, accuracy=0.89, loss=0.3]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.24200\n","Train Accuracy: 0.91288\n","Valid Loss: 0.30004\n","Valid Accuracy: 0.89037\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-4\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zfnHC7CvuSs","executionInfo":{"status":"ok","timestamp":1684807192842,"user_tz":300,"elapsed":864262,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"b4106a01-d28a-42a2-ab3e-a3d8181d9ae8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.821, loss=0.428, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.841, loss=0.377]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42777\n","Train Accuracy: 0.82063\n","Valid Loss: 0.37685\n","Valid Accuracy: 0.84053\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.899, loss=0.278, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.866, loss=0.384]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.27810\n","Train Accuracy: 0.89866\n","Valid Loss: 0.38411\n","Valid Accuracy: 0.86635\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.857, loss=0.311, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.89it/s, accuracy=0.568, loss=0.685]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.31086\n","Train Accuracy: 0.85708\n","Valid Loss: 0.68475\n","Valid Accuracy: 0.56804\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.808, loss=0.448, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.842, loss=0.387]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44846\n","Train Accuracy: 0.80828\n","Valid Loss: 0.38718\n","Valid Accuracy: 0.84167\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.892, loss=0.304, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.868, loss=0.369]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.30358\n","Train Accuracy: 0.89151\n","Valid Loss: 0.36917\n","Valid Accuracy: 0.86798\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.899, loss=0.289, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.85it/s, accuracy=0.86, loss=0.371]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.28907\n","Train Accuracy: 0.89923\n","Valid Loss: 0.37125\n","Valid Accuracy: 0.85969\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.81, loss=0.443, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.86, loss=0.35]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.44255\n","Train Accuracy: 0.81049\n","Valid Loss: 0.35021\n","Valid Accuracy: 0.85983\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:19<00:00,  2.42it/s, accuracy=0.904, loss=0.265, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.883, loss=0.351]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.26450\n","Train Accuracy: 0.90435\n","Valid Loss: 0.35081\n","Valid Accuracy: 0.88306\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:19<00:00,  2.41it/s, accuracy=0.942, loss=0.183, lr=0.0003]\n","100%|██████████| 97/97 [00:14<00:00,  6.86it/s, accuracy=0.797, loss=0.539]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.18266\n","Train Accuracy: 0.94186\n","Valid Loss: 0.53891\n","Valid Accuracy: 0.79682\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSbf7y5Xh4Da","executionInfo":{"status":"ok","timestamp":1684808066622,"user_tz":300,"elapsed":873806,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"7f9c034b-a235-486b-8be9-9478716b5ba8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.828, loss=0.407, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.74it/s, accuracy=0.855, loss=0.354]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40745\n","Train Accuracy: 0.82818\n","Valid Loss: 0.35389\n","Valid Accuracy: 0.85515\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.894, loss=0.281, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.75it/s, accuracy=0.87, loss=0.33]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28069\n","Train Accuracy: 0.89411\n","Valid Loss: 0.32966\n","Valid Accuracy: 0.87025\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.934, loss=0.184, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.891, loss=0.311]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18392\n","Train Accuracy: 0.93374\n","Valid Loss: 0.31124\n","Valid Accuracy: 0.89136\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.814, loss=0.418, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.72it/s, accuracy=0.869, loss=0.336]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41840\n","Train Accuracy: 0.81445\n","Valid Loss: 0.33602\n","Valid Accuracy: 0.86928\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.893, loss=0.283, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.89, loss=0.302]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28258\n","Train Accuracy: 0.89265\n","Valid Loss: 0.30174\n","Valid Accuracy: 0.89006\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.937, loss=0.184, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.9, loss=0.274]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18427\n","Train Accuracy: 0.93723\n","Valid Loss: 0.27359\n","Valid Accuracy: 0.90045\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.825, loss=0.411, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.61it/s, accuracy=0.862, loss=0.342]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41074\n","Train Accuracy: 0.82462\n","Valid Loss: 0.34211\n","Valid Accuracy: 0.86195\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.897, loss=0.279, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.68it/s, accuracy=0.887, loss=0.296]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27871\n","Train Accuracy: 0.89713\n","Valid Loss: 0.29615\n","Valid Accuracy: 0.88728\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.932, loss=0.19, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.897, loss=0.293]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18972\n","Train Accuracy: 0.93220\n","Valid Loss: 0.29288\n","Valid Accuracy: 0.89703\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-6\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yR7Mjom3v6qo","executionInfo":{"status":"ok","timestamp":1684808939068,"user_tz":300,"elapsed":872472,"user":{"displayName":"Taishi Okano","userId":"12143587453860487735"}},"outputId":"598c612f-798c-4660-b058-7833294e0a5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.709, loss=0.561, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.71it/s, accuracy=0.816, loss=0.429]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.56141\n","Train Accuracy: 0.70905\n","Valid Loss: 0.42886\n","Valid Accuracy: 0.81634\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.836, loss=0.393, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.839, loss=0.392]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39309\n","Train Accuracy: 0.83573\n","Valid Loss: 0.39205\n","Valid Accuracy: 0.83875\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.856, loss=0.359, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.845, loss=0.378]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.35943\n","Train Accuracy: 0.85595\n","Valid Loss: 0.37782\n","Valid Accuracy: 0.84492\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.714, loss=0.571, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.74it/s, accuracy=0.815, loss=0.425]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.57116\n","Train Accuracy: 0.71368\n","Valid Loss: 0.42452\n","Valid Accuracy: 0.81487\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.828, loss=0.406, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.79it/s, accuracy=0.837, loss=0.384]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40560\n","Train Accuracy: 0.82810\n","Valid Loss: 0.38365\n","Valid Accuracy: 0.83696\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.851, loss=0.365, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.78it/s, accuracy=0.856, loss=0.358]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.36466\n","Train Accuracy: 0.85132\n","Valid Loss: 0.35792\n","Valid Accuracy: 0.85612\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.759, loss=0.535, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.62it/s, accuracy=0.829, loss=0.407]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.53493\n","Train Accuracy: 0.75893\n","Valid Loss: 0.40660\n","Valid Accuracy: 0.82930\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.836, loss=0.397, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.847, loss=0.374]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39690\n","Train Accuracy: 0.83647\n","Valid Loss: 0.37408\n","Valid Accuracy: 0.84733\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.854, loss=0.361, lr=3e-6]\n","100%|██████████| 97/97 [00:14<00:00,  6.69it/s, accuracy=0.854, loss=0.359]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.36112\n","Train Accuracy: 0.85442\n","Valid Loss: 0.35892\n","Valid Accuracy: 0.85399\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.3\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-RvtjDCwImw","outputId":"376501ee-a7b1-4b53-992f-0418167132d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.829, loss=0.407, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.73it/s, accuracy=0.859, loss=0.35]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40665\n","Train Accuracy: 0.82875\n","Valid Loss: 0.35020\n","Valid Accuracy: 0.85856\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.896, loss=0.28, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.80it/s, accuracy=0.878, loss=0.322]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27963\n","Train Accuracy: 0.89631\n","Valid Loss: 0.32183\n","Valid Accuracy: 0.87788\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.932, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.76it/s, accuracy=0.888, loss=0.307]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19230\n","Train Accuracy: 0.93220\n","Valid Loss: 0.30682\n","Valid Accuracy: 0.88795\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.82, loss=0.414, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.70it/s, accuracy=0.869, loss=0.335]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41370\n","Train Accuracy: 0.82006\n","Valid Loss: 0.33459\n","Valid Accuracy: 0.86928\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.895, loss=0.277, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.66it/s, accuracy=0.883, loss=0.317]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27708\n","Train Accuracy: 0.89484\n","Valid Loss: 0.31736\n","Valid Accuracy: 0.88259\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.936, loss=0.179, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.77it/s, accuracy=0.886, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.17940\n","Train Accuracy: 0.93593\n","Valid Loss: 0.34012\n","Valid Accuracy: 0.88600\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.41it/s, accuracy=0.824, loss=0.406, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.63it/s, accuracy=0.867, loss=0.336]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40642\n","Train Accuracy: 0.82421\n","Valid Loss: 0.33584\n","Valid Accuracy: 0.86731\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:20<00:00,  2.40it/s, accuracy=0.895, loss=0.279, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.70it/s, accuracy=0.889, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27859\n","Train Accuracy: 0.89510\n","Valid Loss: 0.29923\n","Valid Accuracy: 0.88939\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 111/193 [00:46<00:35,  2.34it/s, accuracy=0.932, loss=0.191, lr=3e-5]"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"id":"_XOAQZF_wIa9","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["05ef74d1e1a54ab49cc6f678edeb1154","0f6e60e5fff043d082739ed556ebf044","8ab1093d700149cba4adc69c77749a97","2d626ac7cc374a7d9b60e771c3a486d7","b10dc8b5149141f79d7f1a4fef8607c4","92f4b27041924242bf1af53b71e0da7d","996a0ad2a27744bbb92abe8de2d58005","10b1dcdbd4d442478cfb33d1fab31576","2460d53532234992ba6e4a7b4c57e114","beaa5399c0d54cb2bb8c271ffba28d4f","14eed485e5c24686b24cc741eaeb002e","0b931b9dd883403d9b1ef37b17b881d2","738671733b9b4d2eb4d8ad6cb810256d","d784315b617946b89e444055494de1d6","a7a66c2610e7450d9bcdd53cbf30cec8","676136a65927411eb68d6cbe38c3aae4","ced61f02a6774341881609d34458b71b","7829436c8f45465eb3b55d1d765d1165","e289a021b2b946b48db64f461c398e85","900a1a0d8eb44c52a5678485407f393c","68c7be8a967e43538f8cd7909317faaa","a321875ca5f54381973efa18fd3f62cb","cc02cc403522413ba1bdbea8e877c48a","91273b5ac793497b816c0f2b9f2b0ad1","20206aa5b3f3425f8ccdc27e7381f8e9","e73fca752bc94121bc99bcc6dd4c2b15","6615e61dfed34a4990c1de16daf289d6","4208dca6401c48139d8a74169b7978c9","769fbd8c81194e639fb08d8ddf8208db","7b3ac426757e44b98f87be1ec767eeac","f96db9a22b224f93bd4acd36797756b8","53823ee214b74d5594fda2b26e738cf3","efacf4050e2f4457a714b4a45807d3a5","9aaa873f53724f989fbc1859d760ed63","1bb5d96cd3844a87b359765af77ec695","850cb826e12347afa6344ac5535a71b3","6c31bccbed4e48308f231698f874c14c","6573e7b66ca24338aeb13ba30d6d5e2a","96677ea8c20c4390ba6e8e6fb48c5a4d","6608aaa7466d4fbf90ec6186d1cbfbe4","045b7e19e7d54757bf9e7a74207a5d0a","c01c4dd103a54506ae881476b571366b","93a107d3092a497796f30fa75b4d67b6","3e50beb22cd84dbd8ca7c64aab173fc3","8c74acd3ae9745dca21a5912769d48f2","f8bf05b262b44865b4119a2c310ba808","e86f35f4fc5a42169a5c6913108cf905","145a958cc7cc4ea6a444ad0ca7ae98c4","b7957ab7653749c78caf142db9ecc47c","7ff6a6c0817d430fad3eba3fb6dcefde","1f04ebc1e44543b19149c639a9c75480","4669592ceb11465cb252a70126ceaba9","87314329550e4e9c900037ced40488d8","9bd1a6098a20479db71e6b1332cf716c","a8122bcc575e40deb579191f5f084692"]},"executionInfo":{"status":"ok","timestamp":1684811050826,"user_tz":300,"elapsed":918798,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"1660fd2b-7290-4676-dc88-7301d9999c69"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ef74d1e1a54ab49cc6f678edeb1154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b931b9dd883403d9b1ef37b17b881d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc02cc403522413ba1bdbea8e877c48a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aaa873f53724f989fbc1859d760ed63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c74acd3ae9745dca21a5912769d48f2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.829, loss=0.404, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.28it/s, accuracy=0.859, loss=0.349]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40448\n","Train Accuracy: 0.82907\n","Valid Loss: 0.34852\n","Valid Accuracy: 0.85872\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.897, loss=0.275, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.56it/s, accuracy=0.882, loss=0.32]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27475\n","Train Accuracy: 0.89712\n","Valid Loss: 0.32010\n","Valid Accuracy: 0.88178\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.932, loss=0.185, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.53it/s, accuracy=0.893, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18475\n","Train Accuracy: 0.93228\n","Valid Loss: 0.30369\n","Valid Accuracy: 0.89282\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.824, loss=0.416, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.57it/s, accuracy=0.864, loss=0.341]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41584\n","Train Accuracy: 0.82420\n","Valid Loss: 0.34128\n","Valid Accuracy: 0.86408\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.889, loss=0.285, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.58it/s, accuracy=0.89, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28511\n","Train Accuracy: 0.88948\n","Valid Loss: 0.29872\n","Valid Accuracy: 0.89022\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.934, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.52it/s, accuracy=0.897, loss=0.298]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.18641\n","Train Accuracy: 0.93447\n","Valid Loss: 0.29832\n","Valid Accuracy: 0.89721\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.822, loss=0.415, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.42it/s, accuracy=0.862, loss=0.342]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41490\n","Train Accuracy: 0.82194\n","Valid Loss: 0.34152\n","Valid Accuracy: 0.86211\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.89, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.44it/s, accuracy=0.884, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28883\n","Train Accuracy: 0.88982\n","Valid Loss: 0.30353\n","Valid Accuracy: 0.88420\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.931, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.43it/s, accuracy=0.897, loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19210\n","Train Accuracy: 0.93090\n","Valid Loss: 0.28713\n","Valid Accuracy: 0.89687\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.7\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"id":"q7aR3nDuwIMx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684811944941,"user_tz":300,"elapsed":894119,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"b6462802-32b2-4ace-e62c-5200a677741a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.82, loss=0.424, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.49it/s, accuracy=0.855, loss=0.36]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42373\n","Train Accuracy: 0.81989\n","Valid Loss: 0.35962\n","Valid Accuracy: 0.85466\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.893, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.57it/s, accuracy=0.874, loss=0.326]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28902\n","Train Accuracy: 0.89265\n","Valid Loss: 0.32593\n","Valid Accuracy: 0.87399\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.925, loss=0.204, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.52it/s, accuracy=0.886, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.20383\n","Train Accuracy: 0.92481\n","Valid Loss: 0.30859\n","Valid Accuracy: 0.88600\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.816, loss=0.42, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.51it/s, accuracy=0.863, loss=0.338]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42016\n","Train Accuracy: 0.81640\n","Valid Loss: 0.33790\n","Valid Accuracy: 0.86310\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.889, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.56it/s, accuracy=0.886, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28857\n","Train Accuracy: 0.88867\n","Valid Loss: 0.30922\n","Valid Accuracy: 0.88600\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.929, loss=0.198, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.48it/s, accuracy=0.893, loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.19808\n","Train Accuracy: 0.92895\n","Valid Loss: 0.31361\n","Valid Accuracy: 0.89282\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.822, loss=0.42, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.42it/s, accuracy=0.867, loss=0.342]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.42011\n","Train Accuracy: 0.82243\n","Valid Loss: 0.34216\n","Valid Accuracy: 0.86682\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.891, loss=0.287, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.36it/s, accuracy=0.882, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28724\n","Train Accuracy: 0.89063\n","Valid Loss: 0.30376\n","Valid Accuracy: 0.88176\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.932, loss=0.195, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.42it/s, accuracy=0.895, loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19470\n","Train Accuracy: 0.93196\n","Valid Loss: 0.28740\n","Valid Accuracy: 0.89524\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 3\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"id":"B2JMQIhVyfTZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684812837627,"user_tz":300,"elapsed":892692,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"874b052d-36cc-49f3-8b68-4390304c4af6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.819, loss=0.416, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.59it/s, accuracy=0.855, loss=0.349]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41570\n","Train Accuracy: 0.81876\n","Valid Loss: 0.34924\n","Valid Accuracy: 0.85466\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.892, loss=0.286, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.55it/s, accuracy=0.876, loss=0.316]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28595\n","Train Accuracy: 0.89249\n","Valid Loss: 0.31641\n","Valid Accuracy: 0.87577\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.932, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.56it/s, accuracy=0.897, loss=0.306]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.19208\n","Train Accuracy: 0.93220\n","Valid Loss: 0.30561\n","Valid Accuracy: 0.89737\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.819, loss=0.418, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.60it/s, accuracy=0.863, loss=0.347]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41766\n","Train Accuracy: 0.81908\n","Valid Loss: 0.34712\n","Valid Accuracy: 0.86262\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.889, loss=0.289, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.50it/s, accuracy=0.887, loss=0.308]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28851\n","Train Accuracy: 0.88883\n","Valid Loss: 0.30789\n","Valid Accuracy: 0.88698\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.93, loss=0.192, lr=3e-5]\n","100%|██████████| 97/97 [00:14<00:00,  6.58it/s, accuracy=0.885, loss=0.338]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.19165\n","Train Accuracy: 0.93025\n","Valid Loss: 0.33782\n","Valid Accuracy: 0.88454\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.821, loss=0.413, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.45it/s, accuracy=0.868, loss=0.344]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41259\n","Train Accuracy: 0.82137\n","Valid Loss: 0.34394\n","Valid Accuracy: 0.86844\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.35it/s, accuracy=0.892, loss=0.282, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.39it/s, accuracy=0.889, loss=0.296]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.28152\n","Train Accuracy: 0.89169\n","Valid Loss: 0.29590\n","Valid Accuracy: 0.88939\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [01:22<00:00,  2.34it/s, accuracy=0.935, loss=0.186, lr=3e-5]\n","100%|██████████| 97/97 [00:15<00:00,  6.44it/s, accuracy=0.901, loss=0.303]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.18581\n","Train Accuracy: 0.93456\n","Valid Loss: 0.30261\n","Valid Accuracy: 0.90109\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 5\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"id":"uZaMpvL_ylZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684814486728,"user_tz":300,"elapsed":1649105,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"0a6d991c-cf30-4439-dd67-bfc71b7f1325"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.826, loss=0.403, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.48it/s, accuracy=0.868, loss=0.339]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40256\n","Train Accuracy: 0.82589\n","Valid Loss: 0.33863\n","Valid Accuracy: 0.86766\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.9, loss=0.267, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.46it/s, accuracy=0.9, loss=0.282]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26724\n","Train Accuracy: 0.90012\n","Valid Loss: 0.28193\n","Valid Accuracy: 0.89959\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.942, loss=0.165, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.42it/s, accuracy=0.908, loss=0.262]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16485\n","Train Accuracy: 0.94194\n","Valid Loss: 0.26226\n","Valid Accuracy: 0.90825\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.825, loss=0.401, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.48it/s, accuracy=0.866, loss=0.333]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40150\n","Train Accuracy: 0.82508\n","Valid Loss: 0.33252\n","Valid Accuracy: 0.86604\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.901, loss=0.27, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.45it/s, accuracy=0.873, loss=0.331]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26999\n","Train Accuracy: 0.90087\n","Valid Loss: 0.33072\n","Valid Accuracy: 0.87280\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.94, loss=0.174, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.44it/s, accuracy=0.901, loss=0.291]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17410\n","Train Accuracy: 0.93950\n","Valid Loss: 0.29100\n","Valid Accuracy: 0.90122\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.829, loss=0.405, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.13it/s, accuracy=0.87, loss=0.333]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40450\n","Train Accuracy: 0.82914\n","Valid Loss: 0.33336\n","Valid Accuracy: 0.87009\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.899, loss=0.274, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.21it/s, accuracy=0.888, loss=0.295]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27392\n","Train Accuracy: 0.89857\n","Valid Loss: 0.29462\n","Valid Accuracy: 0.88823\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.941, loss=0.172, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.15it/s, accuracy=0.904, loss=0.274]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17179\n","Train Accuracy: 0.94079\n","Valid Loss: 0.27446\n","Valid Accuracy: 0.90392\n","******************************\n","Training Fold: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.826, loss=0.409, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.45it/s, accuracy=0.866, loss=0.33]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40889\n","Train Accuracy: 0.82638\n","Valid Loss: 0.32990\n","Valid Accuracy: 0.86573\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.901, loss=0.264, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.39it/s, accuracy=0.897, loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26354\n","Train Accuracy: 0.90060\n","Valid Loss: 0.28656\n","Valid Accuracy: 0.89659\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.943, loss=0.164, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.32it/s, accuracy=0.915, loss=0.255]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16442\n","Train Accuracy: 0.94276\n","Valid Loss: 0.25511\n","Valid Accuracy: 0.91473\n","******************************\n","Training Fold: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.833, loss=0.398, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.34it/s, accuracy=0.868, loss=0.333]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39849\n","Train Accuracy: 0.83328\n","Valid Loss: 0.33278\n","Valid Accuracy: 0.86789\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:39<00:00,  2.33it/s, accuracy=0.9, loss=0.273, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.08it/s, accuracy=0.898, loss=0.28]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27256\n","Train Accuracy: 0.89952\n","Valid Loss: 0.28003\n","Valid Accuracy: 0.89767\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.936, loss=0.176, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.31it/s, accuracy=0.91, loss=0.26]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17622\n","Train Accuracy: 0.93633\n","Valid Loss: 0.25999\n","Valid Accuracy: 0.91012\n","******************************\n"]}]},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 3\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 7\n","\n","parameters = Parameters()\n","train_folds(parameters)\n"],"metadata":{"id":"ZYQAyiu8ymXd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684816873605,"user_tz":300,"elapsed":2386882,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"e1d90108-5c7a-4692-f03a-3700fcef446b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:46<00:00,  2.34it/s, accuracy=0.832, loss=0.399, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.52it/s, accuracy=0.874, loss=0.32]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39925\n","Train Accuracy: 0.83156\n","Valid Loss: 0.32019\n","Valid Accuracy: 0.87382\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.901, loss=0.265, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.59it/s, accuracy=0.901, loss=0.263]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26548\n","Train Accuracy: 0.90078\n","Valid Loss: 0.26278\n","Valid Accuracy: 0.90110\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.941, loss=0.164, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.48it/s, accuracy=0.911, loss=0.28]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.16434\n","Train Accuracy: 0.94070\n","Valid Loss: 0.28043\n","Valid Accuracy: 0.91095\n","******************************\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Training Fold: 1\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.832, loss=0.398, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.50it/s, accuracy=0.862, loss=0.344]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39839\n","Train Accuracy: 0.83201\n","Valid Loss: 0.34357\n","Valid Accuracy: 0.86245\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.903, loss=0.26, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.50it/s, accuracy=0.884, loss=0.304]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.25960\n","Train Accuracy: 0.90350\n","Valid Loss: 0.30408\n","Valid Accuracy: 0.88367\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.943, loss=0.159, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.51it/s, accuracy=0.908, loss=0.274]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.15919\n","Train Accuracy: 0.94278\n","Valid Loss: 0.27437\n","Valid Accuracy: 0.90830\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.829, loss=0.401, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.51it/s, accuracy=0.866, loss=0.328]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40057\n","Train Accuracy: 0.82898\n","Valid Loss: 0.32752\n","Valid Accuracy: 0.86624\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.36it/s, accuracy=0.9, loss=0.264, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.53it/s, accuracy=0.892, loss=0.291]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26361\n","Train Accuracy: 0.89965\n","Valid Loss: 0.29084\n","Valid Accuracy: 0.89200\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.941, loss=0.164, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.51it/s, accuracy=0.906, loss=0.29]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16364\n","Train Accuracy: 0.94146\n","Valid Loss: 0.28975\n","Valid Accuracy: 0.90640\n","******************************\n","Training Fold: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.832, loss=0.398, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.48it/s, accuracy=0.879, loss=0.317]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39835\n","Train Accuracy: 0.83194\n","Valid Loss: 0.31706\n","Valid Accuracy: 0.87912\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.903, loss=0.26, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.42it/s, accuracy=0.908, loss=0.259]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.25982\n","Train Accuracy: 0.90344\n","Valid Loss: 0.25913\n","Valid Accuracy: 0.90830\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.942, loss=0.159, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.57it/s, accuracy=0.915, loss=0.247]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.15947\n","Train Accuracy: 0.94171\n","Valid Loss: 0.24656\n","Valid Accuracy: 0.91550\n","******************************\n","Training Fold: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.828, loss=0.401, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.47it/s, accuracy=0.873, loss=0.328]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40067\n","Train Accuracy: 0.82803\n","Valid Loss: 0.32790\n","Valid Accuracy: 0.87344\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.899, loss=0.268, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.60it/s, accuracy=0.898, loss=0.28]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26769\n","Train Accuracy: 0.89946\n","Valid Loss: 0.28024\n","Valid Accuracy: 0.89845\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.938, loss=0.168, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.47it/s, accuracy=0.915, loss=0.232]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16810\n","Train Accuracy: 0.93830\n","Valid Loss: 0.23204\n","Valid Accuracy: 0.91550\n","******************************\n","Training Fold: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.834, loss=0.395, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.45it/s, accuracy=0.876, loss=0.323]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39487\n","Train Accuracy: 0.83441\n","Valid Loss: 0.32344\n","Valid Accuracy: 0.87609\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.902, loss=0.268, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.41it/s, accuracy=0.901, loss=0.265]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26777\n","Train Accuracy: 0.90211\n","Valid Loss: 0.26477\n","Valid Accuracy: 0.90110\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.937, loss=0.175, lr=3e-5]\n","100%|██████████| 42/42 [00:05<00:00,  7.50it/s, accuracy=0.905, loss=0.26]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17514\n","Train Accuracy: 0.93722\n","Valid Loss: 0.26048\n","Valid Accuracy: 0.90489\n","******************************\n","Training Fold: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.83, loss=0.404, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.34it/s, accuracy=0.858, loss=0.353]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40363\n","Train Accuracy: 0.83011\n","Valid Loss: 0.35326\n","Valid Accuracy: 0.85752\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.899, loss=0.269, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.34it/s, accuracy=0.897, loss=0.28]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26886\n","Train Accuracy: 0.89889\n","Valid Loss: 0.27966\n","Valid Accuracy: 0.89731\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 248/248 [01:45<00:00,  2.35it/s, accuracy=0.938, loss=0.169, lr=3e-5]\n","100%|██████████| 42/42 [00:06<00:00,  6.40it/s, accuracy=0.915, loss=0.238]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16935\n","Train Accuracy: 0.93773\n","Valid Loss: 0.23845\n","Valid Accuracy: 0.91474\n","******************************\n"]}]},{"cell_type":"markdown","source":["## Run with the best setting"],"metadata":{"id":"VdZonxywX33B"}},{"cell_type":"code","source":["class Parameters:\n","    model_name = 'distilbert-base-uncased'\n","    batch_size = 64\n","    num_labels = 2\n","    epochs = 5\n","    num_workers = 2\n","    learning_rate = 3e-5\n","    scheduler = \"ReduceLROnPlateau\"\n","    patience = 2\n","    dropout = 0.5\n","    model_path = path + \"/models/\"\n","    max_length = 140\n","    model_save_name = \"model.pt\"\n","    n_folds = 5\n","\n","parameters = Parameters()\n","train_folds(parameters)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-15T02:37:21.624974Z","iopub.execute_input":"2023-05-15T02:37:21.625331Z","iopub.status.idle":"2023-05-15T02:37:21.633119Z","shell.execute_reply.started":"2023-05-15T02:37:21.625294Z","shell.execute_reply":"2023-05-15T02:37:21.632176Z"},"trusted":true,"id":"2Cr9kRKlSWNL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684819591595,"user_tz":300,"elapsed":2717997,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"a9d6d472-2900-49c2-f723-1ef0f5bf7f4b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Fold: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.826, loss=0.406, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.46it/s, accuracy=0.868, loss=0.341]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40598\n","Train Accuracy: 0.82623\n","Valid Loss: 0.34095\n","Valid Accuracy: 0.86766\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.9, loss=0.268, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.46it/s, accuracy=0.888, loss=0.294]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26797\n","Train Accuracy: 0.90046\n","Valid Loss: 0.29449\n","Valid Accuracy: 0.88769\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.938, loss=0.174, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.52it/s, accuracy=0.901, loss=0.27]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17398\n","Train Accuracy: 0.93781\n","Valid Loss: 0.26964\n","Valid Accuracy: 0.90122\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.96, loss=0.111, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.44it/s, accuracy=0.913, loss=0.302]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.11135\n","Train Accuracy: 0.96014\n","Valid Loss: 0.30197\n","Valid Accuracy: 0.91313\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.972, loss=0.0777, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.44it/s, accuracy=0.918, loss=0.309]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.07773\n","Train Accuracy: 0.97232\n","Valid Loss: 0.30932\n","Valid Accuracy: 0.91800\n","******************************\n","Training Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.823, loss=0.413, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.36it/s, accuracy=0.866, loss=0.332]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.41295\n","Train Accuracy: 0.82298\n","Valid Loss: 0.33228\n","Valid Accuracy: 0.86604\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.897, loss=0.274, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.42it/s, accuracy=0.893, loss=0.286]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27436\n","Train Accuracy: 0.89667\n","Valid Loss: 0.28573\n","Valid Accuracy: 0.89256\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.94, loss=0.173, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  6.45it/s, accuracy=0.905, loss=0.275]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17277\n","Train Accuracy: 0.94011\n","Valid Loss: 0.27516\n","Valid Accuracy: 0.90501\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.96, loss=0.11, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.38it/s, accuracy=0.913, loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.11041\n","Train Accuracy: 0.96008\n","Valid Loss: 0.28688\n","Valid Accuracy: 0.91286\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.969, loss=0.0777, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.42it/s, accuracy=0.928, loss=0.276]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.07769\n","Train Accuracy: 0.96941\n","Valid Loss: 0.27649\n","Valid Accuracy: 0.92801\n","******************************\n","Training Fold: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.827, loss=0.402, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.12it/s, accuracy=0.871, loss=0.332]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40216\n","Train Accuracy: 0.82677\n","Valid Loss: 0.33243\n","Valid Accuracy: 0.87091\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.901, loss=0.264, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.21it/s, accuracy=0.89, loss=0.295]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26370\n","Train Accuracy: 0.90073\n","Valid Loss: 0.29524\n","Valid Accuracy: 0.88958\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.943, loss=0.163, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.09it/s, accuracy=0.909, loss=0.273]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.16268\n","Train Accuracy: 0.94262\n","Valid Loss: 0.27291\n","Valid Accuracy: 0.90907\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.964, loss=0.104, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.10it/s, accuracy=0.916, loss=0.267]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.10406\n","Train Accuracy: 0.96393\n","Valid Loss: 0.26664\n","Valid Accuracy: 0.91637\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.974, loss=0.0724, lr=3e-5]\n","100%|██████████| 58/58 [00:08<00:00,  7.12it/s, accuracy=0.922, loss=0.3]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.07241\n","Train Accuracy: 0.97381\n","Valid Loss: 0.30009\n","Valid Accuracy: 0.92152\n","******************************\n","Training Fold: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.828, loss=0.407, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.36it/s, accuracy=0.867, loss=0.34]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.40700\n","Train Accuracy: 0.82786\n","Valid Loss: 0.34048\n","Valid Accuracy: 0.86708\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.898, loss=0.274, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.39it/s, accuracy=0.896, loss=0.275]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.27365\n","Train Accuracy: 0.89844\n","Valid Loss: 0.27533\n","Valid Accuracy: 0.89632\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.94, loss=0.17, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.39it/s, accuracy=0.91, loss=0.266]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17016\n","Train Accuracy: 0.93991\n","Valid Loss: 0.26610\n","Valid Accuracy: 0.91040\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.96, loss=0.112, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.35it/s, accuracy=0.919, loss=0.26]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.11205\n","Train Accuracy: 0.96015\n","Valid Loss: 0.25960\n","Valid Accuracy: 0.91852\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.35it/s, accuracy=0.973, loss=0.0755, lr=3e-5]\n","100%|██████████| 58/58 [00:07<00:00,  7.35it/s, accuracy=0.913, loss=0.277]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.07550\n","Train Accuracy: 0.97253\n","Valid Loss: 0.27707\n","Valid Accuracy: 0.91337\n","******************************\n","Training Fold: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.831, loss=0.399, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.39it/s, accuracy=0.864, loss=0.343]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.39910\n","Train Accuracy: 0.83104\n","Valid Loss: 0.34264\n","Valid Accuracy: 0.86437\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:38<00:00,  2.34it/s, accuracy=0.899, loss=0.269, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.28it/s, accuracy=0.896, loss=0.281]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.26913\n","Train Accuracy: 0.89850\n","Valid Loss: 0.28147\n","Valid Accuracy: 0.89605\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:39<00:00,  2.33it/s, accuracy=0.938, loss=0.173, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.32it/s, accuracy=0.909, loss=0.271]\n"]},{"output_type":"stream","name":"stdout","text":["Saved best model!\n","Train Loss: 0.17274\n","Train Accuracy: 0.93795\n","Valid Loss: 0.27094\n","Valid Accuracy: 0.90877\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:39<00:00,  2.32it/s, accuracy=0.963, loss=0.105, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.31it/s, accuracy=0.919, loss=0.276]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.10543\n","Train Accuracy: 0.96258\n","Valid Loss: 0.27603\n","Valid Accuracy: 0.91933\n","******************************\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","Epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [01:39<00:00,  2.31it/s, accuracy=0.97, loss=0.0759, lr=3e-5]\n","100%|██████████| 58/58 [00:09<00:00,  6.29it/s, accuracy=0.918, loss=0.306]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.07586\n","Train Accuracy: 0.97036\n","Valid Loss: 0.30582\n","Valid Accuracy: 0.91825\n","******************************\n"]}]},{"cell_type":"code","source":["accuracies = [0.8657645459910691, 0.8960757774493691, 0.9096075771464708, 0.9098782130765334, 0.9234100128058974, 0.9142083890221923, 0.9174560208927149, 0.9139377529953426, 0.9209742888546119, 0.9179972929141518, 0.9220568328006987, 0.9198917448762628, 0.9169147489358027, 0.9182679289087391, 0.9161028409520409, 0.9155615689628663, 0.9179972929141518, 0.9188092008979136, 0.9147496609791045, 0.9150202969736917]\n","import matplotlib.pyplot as plt\n","epochs = 20\n","plt.plot(range(1, epochs + 1), accuracies)"],"metadata":{"id":"oVDHc4s3hwwg","colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"status":"ok","timestamp":1684819592359,"user_tz":300,"elapsed":777,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"dc67ff5c-a2fe-42c2-f294-2164ea7842ea"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7fa2dd8cfd00>]"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def test_one_model(parameters):\n","    \"\"\"\n","    Perform testing for a single trained model.\n","\n","    Args:\n","        parameters: An object containing various parameters and configurations.\n","\n","    Returns:\n","        all_preds: Tensor containing the predictions for the test dataset.\n","    \"\"\"\n","    test_dataframe = pd.read_csv(path+'/data/tweet_samples_100.csv', sep=\",\")\n","\n","    bert_model = transformers.DistilBertModel.from_pretrained(parameters.model_name)\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(parameters.model_name,\n","                                                           use_fast=True)\n","\n","    # Create a test data loader using the test dataset and tokenizer\n","    test_loader = make_loaders(test_dataframe, tokenizer, mode=\"test\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Initialize the model with the BERT model, number of labels, and dropout rate specified in the `parameters` object\n","    model = CustomModel(bert_model,\n","                        parameters.num_labels,\n","                        dropout=parameters.dropout).to(device)\n","\n","    model.load_state_dict(torch.load(f\"{parameters.model_path}/{parameters.model_save_name}\", \n","                                     map_location=device))\n","\n","    model.eval()\n","\n","    all_preds = None\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader):\n","            # Move the inputs to the device\n","            batch = {}\n","            for key, value in batch.items():\n","                batch[key] = value.to(device)\n","            \n","            # Generate predictions using the model\n","            preds = model(batch)\n","            \n","            if all_preds is None:\n","                all_preds = preds\n","            else:\n","                # Concatenate the predictions with the `all_preds` tensor\n","                all_preds = torch.cat([all_preds, preds], dim=0)\n","\n","    return all_preds\n"],"metadata":{"trusted":true,"id":"2wPQkR2oSWNM","executionInfo":{"status":"ok","timestamp":1684819592359,"user_tz":300,"elapsed":17,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def test_all_models(parameters):\n","    \"\"\"\n","    Test all models trained on different folds and calculate the mean predictions.\n","\n","    Args:\n","        parameters: An object containing the necessary parameters for testing.\n","\n","    Returns:\n","        torch.Tensor: The mean predictions of all models.\n","    \"\"\"\n","    # Get the number of folds from the parameters\n","    num_folds = parameters.n_folds\n","\n","    all_model_preds = []\n","\n","    for fold in range(num_folds):\n","        parameters.model_save_name = f\"model_fold_{fold}.pt\"\n","        fold_preds = test_one_model(parameters)\n","        all_model_preds.append(fold_preds)\n","\n","    # Stack the predictions along the first dimension to create a tensor of shape (num_folds, ...)\n","    all_model_preds = torch.stack(all_model_preds, dim=0)\n","\n","    print(all_model_preds.shape)\n","\n","    # Calculate the mean predictions along the first dimension\n","    mean_preds = all_model_preds.mean(0)\n","\n","    return mean_preds\n"],"metadata":{"trusted":true,"id":"ExIew2paSWNM","executionInfo":{"status":"ok","timestamp":1684819592360,"user_tz":300,"elapsed":17,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["test_dataframe = pd.read_csv(path+'/data/tweet_samples_100.csv', sep=\",\")\n","all_preds = test_all_models(parameters)\n","predictions = all_preds.argmax(dim=1).cpu().numpy()\n","true_labels = np.array(test_dataframe[\"target\"].tolist())\n"],"metadata":{"trusted":true,"id":"u0ldye1tSWNN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684819601119,"user_tz":300,"elapsed":8776,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"7bac7391-799b-46c7-f042-c049059abb48"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2/2 [00:00<00:00,  4.81it/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2/2 [00:00<00:00,  5.53it/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2/2 [00:00<00:00,  5.79it/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2/2 [00:00<00:00,  5.78it/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2/2 [00:00<00:00,  5.83it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 100, 2])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["np.sum(predictions == true_labels)"],"metadata":{"id":"yOovrTfP0sHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684819601120,"user_tz":300,"elapsed":16,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"6baaac7a-a317-4d64-b847-e120d6f221ac"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["mismatched_indices = []\n","for i in range(len(predictions)):\n","    if predictions[i] != true_labels[i]:\n","        mismatched_indices.append(i)\n","mismatched_indices"],"metadata":{"id":"sRLIv1SK0yEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684819601120,"user_tz":300,"elapsed":14,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}},"outputId":"ad6159d2-e2ca-4926-f086-b70bb9c9af3e"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 55, 90]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"pa7D1IJB-lLS","executionInfo":{"status":"ok","timestamp":1684819601120,"user_tz":300,"elapsed":13,"user":{"displayName":"Taishi Okano","userId":"06239394428793284090"}}},"execution_count":24,"outputs":[]}]}