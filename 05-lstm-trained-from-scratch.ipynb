{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Training Embedding Vector from Scratch\n",
    "In this module, rather than using pre-trained embedding vector, we allow an embedding vector changed as same as other parameters in model. In other words, An embedding vector can be trained along with the rest of the parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialized Data Set\n",
    "As usual, import our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/cleaned-train-tweets.csv\", sep=\"|\")\n",
    "\n",
    "# create PyTorch data set\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "class DisasterTweetsDataset(Dataset):\n",
    "    def __init__(self, df, max_vocab_size, vocabulary = None):\n",
    "        \n",
    "        # load dataframe\n",
    "        self.x = df[\"clean_text\"]\n",
    "        self.y = df[\"target\"]\n",
    "        \n",
    "\n",
    "        # create vocabulary\n",
    "        if not vocabulary:\n",
    "            self.vocab = build_vocab_from_iterator(\n",
    "                [\" \".join([str(text) for text in df[\"clean_text\"]]).split()],\n",
    "                specials=['<unk>'],\n",
    "                max_tokens = max_vocab_size)\n",
    "            self.vocab.set_default_index(self.vocab['<unk>'])\n",
    "        else:\n",
    "            self.vocab = vocabulary\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        # add one more for out of vocab words\n",
    "        return len(self.vocab) + 1\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = self.x[i]\n",
    "        y = self.y[i]\n",
    "        return (y, x)\n",
    "\n",
    "# initiate dataset and vocabulary\n",
    "dataset = DisasterTweetsDataset(df, 10000)\n",
    "vocab = dataset.get_vocab()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation Function\n",
    "Letting the embedding matrix be changed is a complicated task. We has to create a new collation function that map each token to its corresponding index in the vocabulary. Since each tweet has different length. We need to pad each tweet that make the number of tokens of each tweet match the highest length of tweet in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    collate the dataset into bag of words representation\n",
    "    \n",
    "    input:\n",
    "        - batch (list(str, int)): a list of dataset in forms of label, text\n",
    "    return:\n",
    "        - (tensor): a tensor of labels\n",
    "        - (tensor): a tensor of bag of words\n",
    "    \"\"\"\n",
    "\n",
    "    max_tweet_indexes_size = -float(\"inf\")\n",
    "    labels, tweet_indexes = [], []\n",
    "    for label, tweet in batch:\n",
    "        labels.append(int(label))\n",
    "        tweets = str(tweet).split()\n",
    "        max_tweet_indexes_size = max(max_tweet_indexes_size, len(tweets))\n",
    "        tweet_indexes.append(vocab(tweets))\n",
    "    # pad tweet_indexes\n",
    "    temp = [tweet_index + [0] * max_tweet_indexes_size for tweet_index in tweet_indexes]\n",
    "    tweet_indexes = [x[0: max_tweet_indexes_size] for x in temp]\n",
    "\n",
    "    return (\n",
    "        torch.tensor(labels, dtype=torch.int64), \n",
    "        torch.tensor(tweet_indexes)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "We previously knew that the best model so far is bidirectional LSTM. We continue the experiment with BiLSTM model, but rather keep the embedding matrix freezing, we train the embedding matrix along with other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a dataloader and split the data into train and validation dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def new_dataloader(dataset, collate_fn, batch_size=64, split_train_ratio=0.7):\n",
    "    num_train = int(len(dataset) * split_train_ratio)\n",
    "    num_valid = len(dataset) - num_train\n",
    "    train_data, valid_data = random_split(\n",
    "        dataset,\n",
    "        [num_train, num_valid]\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn)\n",
    "    return (train_dataloader, valid_dataloader)\n",
    "\n",
    "# helper function: repackage hidden\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"\n",
    "    Wraps hidden states in new Tensors, to detach them from their history.\n",
    "    \"\"\"\n",
    "    if h is None:\n",
    "        return None\n",
    "    elif isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "\n",
    "# function for training an epoch\n",
    "def train_an_epoch(dataloader, model, hidden, loss_function, optimizer, \n",
    "                   clip_grad, max_norm):\n",
    "    model.train() # Sets the module in training mode.\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(text, hidden)\n",
    "        loss = loss_function(output.view(-1, output.size(-1)), label.view(-1))\n",
    "        loss.backward()\n",
    "        if clip_grad:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                parameters=model.parameters(), \n",
    "                max_norm=max_norm # default GRAD_CLIP = 1\n",
    "            )\n",
    "        optimizer.step()\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')\n",
    "\n",
    "# function for calculate the accuracy for a given dataloader\n",
    "def get_accuracy(dataloader, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = None\n",
    "        total_acc, total_count = 0, 0\n",
    "        for _, (label, text) in enumerate(dataloader):\n",
    "            log_probs, hidden = model(text, hidden)\n",
    "            predicted_label = torch.argmax(log_probs, dim=1)\n",
    "            total_acc += (predicted_label == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count\n",
    "\n",
    "# putting all together, create function for training\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def training(dataset, collate_fn, batch_size, split_train_ratio, \n",
    "             model, epochs, loss_function, optimizer, clip_grad, max_norm):\n",
    "    \n",
    "    # create dataloader from dataset\n",
    "    train_dataloader, valid_dataloader = new_dataloader(\n",
    "        dataset, collate_fn, batch_size, split_train_ratio)\n",
    "\n",
    "    # training\n",
    "    accuracies = []\n",
    "    max_val_acc = -float(\"inf\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        hidden = None\n",
    "        train_an_epoch(train_dataloader, model, hidden, loss_function, optimizer,\n",
    "                       clip_grad, max_norm)\n",
    "        accuracy = get_accuracy(valid_dataloader, model)\n",
    "        accuracies.append(accuracy)\n",
    "        time_taken = time.time() - epoch_start_time\n",
    "        print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
    "        # persist the best model\n",
    "        if accuracy > max_val_acc:\n",
    "            print(\"the best model has validation accuracy at {}\".format(accuracy))\n",
    "            best_model = type(model)( \n",
    "                model.num_embeddings,\n",
    "                model.embedding_dim,\n",
    "                model.hidden_size, \n",
    "                model.out_features,\n",
    "                model.num_layers, \n",
    "                model.dropout\n",
    "            )\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            max_val_acc = accuracy\n",
    "    \n",
    "    plt.plot(range(1, epochs + 1), accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an BiLSTM classifier\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Initialize RNN classifier\n",
    "\n",
    "    Args:\n",
    "        - input_size (int): size of embedding vector (number of features) \n",
    "            for each word (default: 300)\n",
    "        - hidden_size (int): the number of features in the hidden state (def: 300)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, out_features,\n",
    "                 num_layers, dropout=0.5):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_features = out_features\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = self.encoder = nn.Embedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Linear(in_features=hidden_size * 2, \n",
    "                                 out_features=out_features)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden0):\n",
    "        embedding = self.drop(self.encoder(input))\n",
    "        x = torch.mean(embedding, 1)\n",
    "        output, hidden = self.rnn(x, hidden0)\n",
    "        output = self.drop(output)\n",
    "        decoded_output = self.decoder(output)\n",
    "        decoded_output = F.log_softmax(self.decoder(output), dim=1)\n",
    "        return decoded_output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1 the validation accuracy is 0.733.\n",
      "the best model has validation accuracy at 0.7333092746300974\n",
      "After epoch 2 the validation accuracy is 0.774.\n",
      "the best model has validation accuracy at 0.7740887766149405\n",
      "After epoch 3 the validation accuracy is 0.810.\n",
      "the best model has validation accuracy at 0.810357271743053\n",
      "After epoch 4 the validation accuracy is 0.823.\n",
      "the best model has validation accuracy at 0.8231685312161674\n",
      "After epoch 5 the validation accuracy is 0.840.\n",
      "the best model has validation accuracy at 0.8395885961746662\n",
      "After epoch 6 the validation accuracy is 0.844.\n",
      "the best model has validation accuracy at 0.843558282208589\n",
      "After epoch 7 the validation accuracy is 0.844.\n",
      "After epoch 8 the validation accuracy is 0.854.\n",
      "the best model has validation accuracy at 0.854384698664742\n",
      "After epoch 9 the validation accuracy is 0.856.\n",
      "the best model has validation accuracy at 0.8563695416817033\n",
      "After epoch 10 the validation accuracy is 0.858.\n",
      "the best model has validation accuracy at 0.8581739444243955\n",
      "After epoch 11 the validation accuracy is 0.861.\n",
      "the best model has validation accuracy at 0.8608805485384338\n",
      "After epoch 12 the validation accuracy is 0.855.\n",
      "After epoch 13 the validation accuracy is 0.864.\n",
      "the best model has validation accuracy at 0.8641284734752797\n",
      "After epoch 14 the validation accuracy is 0.863.\n",
      "After epoch 15 the validation accuracy is 0.867.\n",
      "the best model has validation accuracy at 0.8673763984121255\n",
      "After epoch 16 the validation accuracy is 0.871.\n",
      "the best model has validation accuracy at 0.8711656441717791\n",
      "After epoch 17 the validation accuracy is 0.870.\n",
      "After epoch 18 the validation accuracy is 0.875.\n",
      "the best model has validation accuracy at 0.8747744496571634\n",
      "After epoch 19 the validation accuracy is 0.874.\n",
      "After epoch 20 the validation accuracy is 0.875.\n",
      "the best model has validation accuracy at 0.8753157704799711\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm20lEQVR4nO3deXxU9b3/8dcnCQlkgZCFRbawI+CCxH1BqyjSVrtesbWtt1btbfX+2urv1t62Xq+/R3d77XJtb61tXdorUrtRi4JWpa0rAQENmBAWIUCSIUBIAtk/vz/moGPIMpBJJpm8n4/HPHKW75n5ZBjeOfM933OOuTsiIpK4kuJdgIiI9C4FvYhIglPQi4gkOAW9iEiCU9CLiCQ4Bb2ISIJLiaaRmS0CfggkAw+4+7fbrZ8IPARkB23ucPcVZjYEeAA4I3ith939W129Vl5enhcUFBznryEiMritXbt2n7vnd7Su26A3s2TgPmAhUA6sMbPl7r4potnXgGXu/lMzmw2sAAqAjwJp7n6KmaUDm8zsUXff0dnrFRQUUFRUFOWvJiIiAGb2Vmfroum6OQsoc/dt7t4ELAWubtfGgeHB9AhgT8TyDDNLAYYBTcCh46hdRER6KJqgHwfsipgvD5ZFugu4zszKCe/N3xosfxyoB/YCO4F73H1/TwoWEZHjE6uDsdcCD7r7eGAx8IiZJRH+NtAKnARMBm4zsyntNzazm8ysyMyKQqFQjEoSERGILuh3AxMi5scHyyLdACwDcPeXgKFAHvAx4Cl3b3b3KuAFoLD9C7j7/e5e6O6F+fkdHksQEZETFE3QrwGmm9lkM0sFlgDL27XZCVwKYGYnEw76ULD8PcHyDOAc4M3YlC4iItHoNujdvQW4BVgJbCY8uqbYzO42s6uCZrcBN5rZBuBR4HoPXxbzPiDTzIoJ/8H4lbtv7I1fREREOmb97TLFhYWFruGVIiLHx8zWuvsxXeMQ5QlTIiISew3NrZQfOMyOfYfZUV1PemoKHzt7YsxfR0EvIoOau7Nu50F+W7SLikMN5GemkZ/1zmNU1tC3pzNSkzGz43r+I02t7NwfDvK3quvZUX2YHfvqeav6MHtqjhDZqXLGxGwFvYhIrOyvb+L368p5bM0utlTVkZ6azJT8DN7cW8u+ukZa2o7t1h42JPmdPwLH/EFIo6mljR3Vh4NAr2fHvsNUHGp413OMTB/CpNwMziwYyaTc8UzOy2BSbjoFuRlkpw/pld9VQS8ig0Zbm/Pi1mqWrtnJquJKmlrbOH1CNt/58Cm899STyExLebvdwSPNhGobw4+6BqoOHZ0O/9waquPl7dUcPNx8zOvkZaZRkJvO+dPyKMhNZ1JeRvhnTgYjeinMu6KgF5GEV1HTwONrd/FY0S527T/CiGFD+Pg5E7nmzAnMGjP8mPZJSUZORio5GanMHJPV5XM3trRSXddEVW0jKUnGpNx0sob2fZh3RUEvIgmppbWN50pCLH11J8+VVNHmcN7UXG6/fCZXzBnD0CHJMXmdtJRkTsoexknZw2LyfL1BQS8icdXY0soLZft46o0K9tc3k5MxhJEZqeSkpzIyI5XcjNR3zQ8fmtLlAdG3qut5bM0uHl9bTlVtI/lZaXx2wVT+qXACBXkZffib9R8KehHpcw3Nrfx9yz5WvL6XZzZVUtvYQtbQFMZlD+P13U0cqG+mqbWtw21Tkozs9NTwH4T0cPfKyIxURqYP4bWdB3lxazVJBpfMHMU1Z07gklmjGJI8uO+xpKAXkT7R0NzK8yVVrHi9gr9urqS+qZURw4awaO4YFp8ylvOn5ZGaEg5kd6e+qZUD9U3sr29i/+Gmt6cPHG5if31zeP5wE2VVdcGyJk7KHsZtC2fwkcLxjB3Rf7tS+pqCXkR6zeGmFp57M8SKN/by3JtVHG5qZWT6EN5/2klcecpYzpua2+HetpmRmZZCZloKE3LSo3qttjbHjOMe5z4YKOhFJKbqGlt49s0qnnx9L8+VVNHQ3EZuRiofmDeOxXPHcs6UHFJ6oSslKUkB3xkFvYj0WENzK6s2VfLEhj2sLg3R2NJGXmYaH50/gStPGcPZk3NJVhDHjYJeRE6Iu/ParoM8vracP2/YQ21DC6OHp3HtWRO5cu4YCgtyFO79hIJeRI5L5aEGfr9uN4+v3cXWUD1DhyRx5dyxfGT+eM6dkqsulH5IQS8i3WpobuWZzZX8tqicv28J0eZQOGkk3/nwFBafMrbfnQkq76agF5EOuTsby2t4fG05yzfsoeZIM2NHDOVzF0/jw/PDF+OSgUFBL5IA9tYc4UuPbeCt6vp3XVHxnSssDn37Cot5mWkMS+389P+q2gb++NpuHl9bTmllHWkpSSyaO4aPzB/PeVPz1O8+ACnoRQa4tW/t5+ZH1tHQ3MrC2aOprm+i/MAR1u86SHV9Ex3dRC4rLYX8rDTyIv4g5GWmsm7nQVaXhmhtc86YmM23PnQK7z11LMPVNTOgKehFBrDH1uzka398g5Oyh/HojWczffS7r7TY0trG/vrwlRWPXl73nUvvhn9u3nOIv9U2UtvYwpjhQ7n5oil8eP54puZnxum3kliLKujNbBHwQyAZeMDdv91u/UTgISA7aHOHu68I1p0K/AwYDrQBZ7r7u6/ELyLHpbm1jW/8ZTMPvriDC6fn8eNr55GdnnpMu5TkJEYNH8qo4UO7fc4jTa2kpSRp1EwC6jbozSwZuA9YCJQDa8xsubtvimj2NWCZu//UzGYDK4ACM0sBfg18wt03mFkucOxV+kUGuN0Hj/DazgNMH5XV7fXLe+pAfROf/991vLi1mhsumMxXrpwVkzNNu+q3l4Etmj36s4Ayd98GYGZLgauByKB3wnvsACOAPcH05cBGd98A4O7VsShaJJ7a2pzSqlrWbN/Pmh0HKNqxnz014S+pZvCB08fxxctmMDE3umu0HI83Kw5x48NFVNY0cs9HT+Mj88fH/DUk8UQT9OOAXRHz5cDZ7drcBawys1uBDOCyYPkMwM1sJZAPLHX37/aoYpE+1tDcysbyGtbs2E/Rjv2sfesAhxpaABiVlcaZk3O4adJITp2QzdObKvnVC9t5YuMePnbWRG55z3Tys9JiUsdTb1TwpWXryUxL4bGbz2HexJExeV5JfLE6GHst8KC7f9/MzgUeMbO5wfNfAJwJHAb+amZr3f2vkRub2U3ATQATJ8b+Dugix6PmcDNFb72zt76xvObta6NPG5XJe08dS+GkHM4syGFCzrB3XS3xjIkjuf68An741y38+pWd/HZtOZ+5YDI3XjTlhE8qamtzfvxsGfc+U8ppE7K5/xPzGR1Fn7vIUeYdjb2KbBAO7rvc/Ypg/isA7v6tiDbFwCJ33xXMbwPOAd4DXOnunwqWfx1ocPfvdfZ6hYWFXlRU1KNfSiQarW3O7gNHKAvVsrWqnrKqOtbvOkhJZS0AQ5KNueNGcGZBONTnTxpJTsaxBzw7sy1Ux/efLuUvG/cyMn0In79kGtedM+m4bmFX39jC7b/dwJNvVPChM8bxzQ+eErNb4EliCXaiCztcF0XQpwClwKXAbmAN8DF3L45o8yTwmLs/aGYnA38l3OWTHUxfADQBTwH3uvtfOns9Bb3E2uGmFraF6tkaqmNrVR1bg+lt++ppannnLkY5GanMHTeCswpGUliQw2njs2NygHJj+UG+t7KEv2/Zx7jsYXzhsul86Izx3Z54tGv/YW58uIjSylr+ffHJ3HDBZF1rXTrVo6APnmAx8APCQyd/6e7fMLO7gSJ3Xx6MtPk5kEn4wOy/ufuqYNvrgK8Ey1e4+7919VoKejkR7k6orpGyo0FeVRcO81A9uw8eebtdksHEnHSm5mcybVQmU/MzmToqgyl5mYw8jr31E/FC2T6++9SbbCivYfqoTP7vFTNZOHt0h+H94tZ9fP4362htc/77Y2dw0Yz8Xq1NBr4eB31fUtBLd2qONLOlspaSylpKK2p5s6KW0spaDhx+Z+RuempyOMTzMyICPZNJuemkpcSv68PdefKNCu5ZWcK2ffWcMTGbLy+axdlTct9e/8jLb/Gff97E5LwMfv7JQl1TRqKioJcBqaG5lbKqOkqCIC+prKWkopa9Ne+cb5eZlsKM0ZnMHJPF9FFZzBidxdRRGYwZPrRfd3O0tLbx27Xl/OCZUioPNXLxzHy+eNkMlq7ZyaOv7uKyk0dx7zWn66qQEjUFvQwIL2+r5sWt1ZQGwb6jup624OOZmpzE1FGZzBydycwxw5k5JpMZo7MYlz2sXwd6dxqaW3noxR385Pmt1BwJfyP5/CVTuW3hTJ2hKsdFQS/93q9e2M5//nkTSQYFuRnMGJ3FjDFZzBoT3ksvyE3vlfuM9hc1R5p56MUdzBidxaK5Y+JdjgxAXQW9LmomceUeHiP+X0+XcsWc0dx7zemkpw6+j+WIYUP410unx7sMSVCD73+U9BvuzjdXbObnf9/Oh+aN47sfOTWh99pF4kVBL3HR2uZ89Q+vs3TNLj517iT+4/1z1Cct0ksU9NLnmlra+NKy9TyxcS+3XDKN2y6fMaAPqIr0dwp66VMNza38y6/X8lxJiK9cOYubF0yNd0kiCU9BL32mtqGZzzxUxKs79vOND87l42dPindJIoOCgl76xIH6Jj71q1cp3nOIH1xzOlefPi7eJYkMGgp66XWVhxq47oFXeGv/YX523Xwumz063iWJDCoKeulVu/Yf5uMPvEJ1XSMP/vOZnDc1L94liQw6CnrpNVsqa7nuF6/Q0NzGb248h9MnZMe7JJFBSUEvveL18ho++ctXSElOYtnN5/b6DbNFpHMKeom5V7ZVc8NDRYwYNoTffOZsCnSZXZG4UtBLTD1XUsVnH1nL+JHD+PVnzmbsiGHxLklk0FPQCxC+JMFrOw9wMOLmHcdr14HDfHPFZmaMzuLhT59FbmZaDCsUkROloB/E3J3Xdh1k+fo9/OX1vYRqG3v8nIWTRvKL689kxDDdMEOkv1DQDzLuzua9tSzfsIcnNu6h/MARUlOSeM/MUbzvtLFMyjnx/nQzmDUmS1egFOlnogp6M1sE/JDwzcEfcPdvt1s/EXgIyA7a3OHuK9qt3wTc5e73xKZ0OR5bQ3X8ecMe/rxhD1tD9SQnGRdOz+OLl81g4ZzRDNct60QSVrdBb2bJwH3AQqAcWGNmy919U0SzrwHL3P2nZjYbWAEURKz/L+DJmFUtUSk/cJgnNu7lzxv2ULznEGZw9uQcPn3BZK6cO5acjNR4lygifSCaPfqzgDJ33wZgZkuBqwnvoR/lwPBgegSw5+gKM/sAsB2oj0G90o2q2gZWbNzL8g17WLfzIACnT8jm6++bzftOHcvo4UPjW6CI9Llogn4csCtivhw4u12bu4BVZnYrkAFcBmBmmcCXCX8buL2zFzCzm4CbACZOnBhl6RKpsaWVf330NZ7eVEmbh/vK/+8VM3n/qScxMTc93uWJSBzF6mDstcCD7v59MzsXeMTM5hL+A3Cvu9d1dWMJd78fuB/CNwePUU2DyvdXlbKyuJKbF0zhI2eMZ/ponYkqImHRBP1uYELE/PhgWaQbgEUA7v6SmQ0F8gjv+X/EzL5L+EBtm5k1uPt/97RweceLW/fx879v4+NnT+QrV54c73JEpJ+JJujXANPNbDLhgF8CfKxdm53ApcCDZnYyMBQIufuFRxuY2V1AnUI+tmqONHP7sg0U5Gbw1fcq5EXkWN0OeHb3FuAWYCWwmfDommIzu9vMrgqa3QbcaGYbgEeB691dXTB94M4/vUFlbSM/uOZ00lN1WoSIHCuqZAjGxK9ot+zOiOlNwPndPMddJ1CfdOFP63fzp/V7+NLCGZymSwCLSCd0CuMAtefgEb72xzeYNzGbz12sG2yLSOcU9ANQW5tz27INtLY5P7jmdF1yQES6pIQYgH7xj+28tK2a/3j/bCbl6lrvItI1Bf0As3nvIb63soTLZ4/mnwondL+BiAx6CvoBpKG5lS8sXc/wYUP41odOoauT0EREjtJ4vAHknpUllFTW8qvrz9RNPUQkatqjHyBeKNvHA//YzifOmcQls0bFuxwRGUAU9ANAzeFmblu2gSn5Gfz7Yp39KiLHR103/Zy789U/vs6+ukZ+/8nzGJaaHO+SRGSA0R59P/en9Xt4YuNevnDZdE4dnx3vckRkAFLQ92PlBw7z9T+9QeGkkfzLxdPiXY6IDFAK+n6qNTj7ta3Nufea00lO0lBKETkxCvp+6oG/b+OV7fv5j6vmMCFHd4gSkROnoO+HivfUcM+qEhbNGcNH54+PdzkiMsAp6PuZhuZWvvjYerLTU/mmzn4VkRjQ8Mp+5rtPlVBaWcdDnz6LnIzUeJcjIglAe/T9yN+3hPjlC9v51LmTWDAjP97liEiCUND3E3trjnD7bzcwbVQmd+gG3yISQwr6fqDmcDPX/3IN9Y2t/PjaeTr7VURiKqqgN7NFZlZiZmVmdkcH6yea2XNm9pqZbTSzxcHyhWa21sxeD36+J9a/wEDX0NzKjQ8XsW1fHT/7xHxOHjs83iWJSILp9mCsmSUD9wELgXJgjZktD24IftTXgGXu/lMzm034RuIFwD7g/e6+x8zmAiuBcTH+HQas1jbnC0vX8+qO/fzo2nmcPy0v3iWJSAKKZo/+LKDM3be5exOwFLi6XRsHju6KjgD2ALj7a+6+J1heDAwzM11InfDFyu5aXsxTxRV8/X2zueq0k+JdkogkqGiCfhywK2K+nGP3yu8CrjOzcsJ787d28DwfBta5e2P7FWZ2k5kVmVlRKBSKqvCB7r7nynjk5be4+aIp3HDB5HiXIyIJLFYHY68FHnT38cBi4BEze/u5zWwO8B3g5o42dvf73b3Q3Qvz8xN/WOGyNbu4Z1UpH5w3ji8vmhXvckQkwUUT9LuByLtQjw+WRboBWAbg7i8BQ4E8ADMbD/wB+KS7b+1pwQPds29W8pU/vM6F0/P4zodPJUkXKxORXhZN0K8BppvZZDNLBZYAy9u12QlcCmBmJxMO+pCZZQN/Ae5w9xdiVvUA9drOA3zuN+uYPXY4P71uPqkpGt0qIr2v26Rx9xbgFsIjZjYTHl1TbGZ3m9lVQbPbgBvNbAPwKHC9u3uw3TTgTjNbHzwG5Q1Pt4bq+PSDaxg9fCi/vP5MMtN09QkR6RsWzuP+o7Cw0IuKiuJdRkxVHmrgQz95kcaWVn73L+cxKTcj3iWJSIIxs7XuXtjROu1W9rJDDc1c/6s1HDjcxGM3nauQF5E+p07iXtTY0srND69lS2Ut/3PdfE4ZPyLeJYnIIKQ9+l7S1uZ8adkGXtpWzb3XnMZFuhqliMSJ9uh7gbtz9xOb+MvGvfz74ll8cJ7uEiUi8aOg7wU/+9s2HnxxBzdcMJkbL5wS73JEZJBT0MfY79aW8+0n3+T9p53EVxefrFsBikjcKehj6PmSKr78u42cPy2Xez6qs15FpH9Q0MfIoYZmbvnf15gxOov/uW4+aSm6eYiI9A8K+hh57s0q6hpbuPvqOWQNHRLvckRE3qagj5FVxZXkZ6VxxsSR8S5FRORdFPQx0NDcynMlVSycPVr98iLS7yjoY+AfW/ZxuKmVRXPGxLsUEZFjKOhjYGVxBVlDUzhnSm68SxEROYaCvodaWtt4ZnMll84apevLi0i/pGTqoVd37OfA4WauULeNiPRTCvoeWlVcSVpKEgtm6qJlItI/Keh7wN1ZVVzBRTPySU/VhUBFpH9S0PfA67tr2FPToG4bEenXFPQ9sLK4guQk47KTB+VtcEVkgIgq6M1skZmVmFmZmd3RwfqJZvacmb1mZhvNbHHEuq8E25WY2RWxLD7ennqjgrMn55CdnhrvUkREOtVt0JtZMnAfcCUwG7jWzGa3a/Y1YJm7zwOWAD8Jtp0dzM8BFgE/CZ5vwCurqmNrqJ5Fc9VtIyL9WzR79GcBZe6+zd2bgKXA1e3aODA8mB4B7AmmrwaWunuju28HyoLnG/BWFlcAcPlsBb2I9G/RBP04YFfEfHmwLNJdwHVmVg6sAG49jm0xs5vMrMjMikKhUJSlx9eq4gpOm5DNmBFD412KiEiXYnUw9lrgQXcfDywGHjGzqJ/b3e9390J3L8zP7//j0fccPMKG8hqumDM63qWIiHQrmsHfu4EJEfPjg2WRbiDcB4+7v2RmQ4G8KLcdcFYF3TYaVikiA0E0e91rgOlmNtnMUgkfXF3ers1O4FIAMzsZGAqEgnZLzCzNzCYD04FXY1V8vKwsrmT6qEym5mfGuxQRkW51G/Tu3gLcAqwENhMeXVNsZneb2VVBs9uAG81sA/AocL2HFQPLgE3AU8Dn3b21N36RvrK/volXd+zX3ryIDBhRnbfv7isIH2SNXHZnxPQm4PxOtv0G8I0e1NivPLO5ktY2V9CLyIChM2OP06riCsZlD2PuuOHdNxYR6QcU9MehvrGFv23Zx+VzRmOmWwaKyMCgoD8Oq0tDNLW0qdtGRAYUBf1xWFlcQU5GKmcW5MS7FBGRqCnoo9TU0sazm6u47ORRJCep20ZEBg4FfZRe3LqP2sYWdduIyICjoI/SyuJKMlKTOX9aXrxLERE5Lgr6KLS2OU9vquTiWaMYOiQhrrIsIoOIgj4K63YeYF9do7ptRGRAUtBHYeUbFaQmJ3HJzP5/ZU0RkfYU9N1wd1ZuquD8ablkDR0S73JERI6bgr4bm/fWsmv/EXXbiMiApaDvxsriCpIMLputm4yIyMCkoO/GyuIKCiflkJeZFu9SREROiIK+C29V1/NmRS2X65aBIjKAKei7sFK3DBSRBKCg78LK4krmnDScCTnp8S5FROSEKeg7UXWogbVvHdDevIgMeFEFvZktMrMSMyszszs6WH+vma0PHqVmdjBi3XfNrNjMNpvZj2yA3LFj1aZKQN02IjLwdXvPWDNLBu4DFgLlwBozWx7cJxYAd/9iRPtbgXnB9HmE7yV7arD6H8AC4PkY1d9rVhZXUJCbzozRmfEuRUSkR6LZoz8LKHP3be7eBCwFru6i/bXAo8G0A0OBVCANGAJUnni5faPmSDMvba3mirljdMtAERnwogn6ccCuiPnyYNkxzGwSMBl4FsDdXwKeA/YGj5XuvrknBfeFZ9+spKXN1W0jIgkh1gdjlwCPu3srgJlNA04GxhP+4/AeM7uw/UZmdpOZFZlZUSgUinFJx2/lG5WMykrj9PHZ8S5FRKTHogn63cCEiPnxwbKOLOGdbhuADwIvu3udu9cBTwLntt/I3e9390J3L8zPj+8VIhuaW1ldGuLyOaNJ0i0DRSQBRBP0a4DpZjbZzFIJh/ny9o3MbBYwEngpYvFOYIGZpZjZEMIHYvt1183fSkMcaW5l0Zyx8S5FRCQmug16d28BbgFWEg7pZe5ebGZ3m9lVEU2XAEvd3SOWPQ5sBV4HNgAb3P3PMau+F6wsrmTEsCGcPSUn3qWIiMREt8MrAdx9BbCi3bI7283f1cF2rcDNPaivTzW3tvHM5kounTWKIck6l0xEEoPSLMKr2/dTc6SZyzXaRkQSiII+wsriCoYOSWLBDN0yUEQSh4I+0NbmrCquZMGMfIalJse7HBGRmFHQBzbtPUTFoQYWzla3jYgkFgV9YHVp+ESti2bkxbkSEZHYUtAHVpeEmHPScEZlDY13KSIiMaWgBw41NLN25wEunqmDsCKSeBT0wItl+2htcxbMGBXvUkREYk5BDzxfEiIrLYV5E7PjXYqISMwN+qB3d1aXhjh/Wp7OhhWRhDTok21LVR17axrUPy8iCWvQB/3qkqPDKhX0IpKYFPSlIWaMzuSk7GHxLkVEpFcM6qCvb2zh1e37dW0bEUlogzroX95WTVNrGxfP1LBKEUlcgzroV5eGGDYkmcKCkfEuRUSk1wz6oD9vai5pKbpapYgkrkEb9Nv31fNW9WEWaFiliCS4QRv0q0uqALhYlz0QkQQXVdCb2SIzKzGzMjO7o4P195rZ+uBRamYHI9ZNNLNVZrbZzDaZWUHsyj9xq0tDTM7LYGJuerxLERHpVd3eHNzMkoH7gIVAObDGzJa7+6ajbdz9ixHtbwXmRTzFw8A33P1pM8sE2mJV/IlqaG7lpW3VLDlzYrxLERHpddHs0Z8FlLn7NndvApYCV3fR/lrgUQAzmw2kuPvTAO5e5+6He1hzj726fT8NzW0aPy8ig0I0QT8O2BUxXx4sO4aZTQImA88Gi2YAB83s92b2mpl9L/iGEFerS0OkpiRxzpTceJciItLrYn0wdgnwuLu3BvMpwIXA7cCZwBTg+vYbmdlNZlZkZkWhUCjGJR1rdWmIsyfn6CbgIjIoRBP0u4EJEfPjg2UdWULQbRMoB9YH3T4twB+BM9pv5O73u3uhuxfm5/dud0r5gcOUVdWp20ZEBo1ogn4NMN3MJptZKuEwX96+kZnNAkYCL7XbNtvMjqbqe4BN7bftS0dvAq7LEovIYNFt0Ad74rcAK4HNwDJ3Lzazu83sqoimS4Cl7u4R27YS7rb5q5m9Dhjw81j+AsdrdUmIcdnDmJqfGc8yRET6TLfDKwHcfQWwot2yO9vN39XJtk8Dp55gfTHV1NLGi1uruer0kzCzeJcjItInBtWZset2HqCusUX98yIyqAyqoH++JERKknHeVA2rFJHBY1AF/erSEPMnjSRr6JB4lyIi0mcGTdBXHmpg895DusmIiAw6gybo/xYMq1T/vIgMNoMm6J8vDZGflcbJY7PiXYqISJ8aFEHf0trGP7bsY8GMfA2rFJFBZ1AE/YbyGmqONOtsWBEZlAZF0K8uDZFkcMG0vHiXIiLS5wZH0JdUcfqEbLLTU+NdiohIn0v4oK+ua2Tj7hoW6N6wIjJIJXzQ/6NsH+66WqWIDF4JH/SrS0LkZKRyyrgR8S5FRCQuEjro29qc1aUhLpyeR1KShlWKyOCU0EFfvOcQ1fVNOhtWRAa1hA761aVVAFykoBeRQSzBgz7EKeNGkJeZFu9SRETiJmGDvuZIM+t2HlS3jYgMegkb9C+U7aO1zVmgYZUiMshFFfRmtsjMSsyszMzu6GD9vWa2PniUmtnBduuHm1m5mf13jOru1uqSEFlDU5g3IbuvXlJEpF/q9ubgZpYM3AcsBMqBNWa23N03HW3j7l+MaH8rMK/d0/w/4G8xqTgK7u8Mq0xJTtgvLSIiUYkmBc8Cytx9m7s3AUuBq7tofy3w6NEZM5sPjAZW9aTQ41FSWUvFoQb1z4uIEF3QjwN2RcyXB8uOYWaTgMnAs8F8EvB94PaelXl8VpeE7yalYZUiIrE/GLsEeNzdW4P5zwEr3L28q43M7CYzKzKzolAo1OMiVpeGmDk6i7EjhvX4uUREBrpogn43MCFifnywrCNLiOi2Ac4FbjGzHcA9wCfN7NvtN3L3+9290N0L8/N7thde39jCmh37dREzEZFAtwdjgTXAdDObTDjglwAfa9/IzGYBI4GXji5z949HrL8eKHT3Y0btxNKLW6tpbnX1z4uIBLrdo3f3FuAWYCWwGVjm7sVmdreZXRXRdAmw1N29d0qNzurSKtJTk5lfMDKeZYiI9BvR7NHj7iuAFe2W3dlu/q5unuNB4MHjqu44uTvPl4Q4b2ouaSnJvflSIiIDRkINMt++r57yA0dYMFN3kxIROSqhgv75YFjlgunqnxcROSqhgn51aYgpeRlMzE2PdykiIv1GwgR9Q3MrL2+r1klSIiLtJEzQHzrSzBVzxnD5nNHxLkVEpF+JatTNQDBq+FB+dG37a6mJiEjC7NGLiEjHFPQiIglOQS8ikuAU9CIiCU5BLyKS4BT0IiIJTkEvIpLgFPQiIgnO4nz5+GOYWQh4K951dCEP2BfvIrqg+npG9fWM6uuZntQ3yd07vAZMvwv6/s7Mity9MN51dEb19Yzq6xnV1zO9VZ+6bkREEpyCXkQkwSnoj9/98S6gG6qvZ1Rfz6i+numV+tRHLyKS4LRHLyKS4BT07ZjZBDN7zsw2mVmxmf2fDtpcbGY1ZrY+eNwZhzp3mNnrwesXdbDezOxHZlZmZhvN7Iw+rG1mxHuz3swOmdkX2rXp0/fQzH5pZlVm9kbEshwze9rMtgQ/R3ay7aeCNlvM7FN9WN/3zOzN4N/vD2aW3cm2XX4WerG+u8xsd8S/4eJOtl1kZiXBZ/GOPqzvsYjadpjZ+k627Yv3r8Nc6bPPoLvrEfEAxgJnBNNZQCkwu12bi4En4lznDiCvi/WLgScBA84BXolTnclABeExvnF7D4GLgDOANyKWfRe4I5i+A/hOB9vlANuCnyOD6ZF9VN/lQEow/Z2O6ovms9CL9d0F3B7Fv/9WYAqQCmxo//+pt+prt/77wJ1xfP86zJW++gxqj74dd9/r7uuC6VpgMzAuvlWdkKuBhz3sZSDbzMbGoY5Lga3uHteT4Nz9b8D+douvBh4Kph8CPtDBplcAT7v7fnc/ADwNLOqL+tx9lbu3BLMvA+Nj/brR6uT9i8ZZQJm7b3P3JmAp4fc9prqqz8wM+Cfg0Vi/brS6yJU++Qwq6LtgZgXAPOCVDlafa2YbzOxJM5vTt5UB4MAqM1trZjd1sH4csCtivpz4/MFaQuf/weL9Ho52973BdAXQ0Q2H+8v7+GnC39A60t1noTfdEnQt/bKTbof+8P5dCFS6+5ZO1vfp+9cuV/rkM6ig74SZZQK/A77g7ofarV5HuCviNODHwB/7uDyAC9z9DOBK4PNmdlEcauiSmaUCVwG/7WB1f3gP3+bh78j9cgiamX0VaAF+00mTeH0WfgpMBU4H9hLuHumPrqXrvfk+e/+6ypXe/Awq6DtgZkMI/2P8xt1/3369ux9y97pgegUwxMzy+rJGd98d/KwC/kD4K3Kk3cCEiPnxwbK+dCWwzt0r26/oD+8hUHm0Oyv4WdVBm7i+j2Z2PfA+4ONBEBwjis9Cr3D3Sndvdfc24OedvG68378U4EPAY5216av3r5Nc6ZPPoIK+naA/7xfAZnf/r07ajAnaYWZnEX4fq/uwxgwzyzo6Tfig3Rvtmi0HPmlh5wA1EV8R+0qne1Lxfg8Dy4GjIxg+BfypgzYrgcvNbGTQNXF5sKzXmdki4N+Aq9z9cCdtovks9FZ9kcd8PtjJ664BppvZ5OAb3hLC73tfuQx4093LO1rZV+9fF7nSN5/B3jzSPBAfwAWEvz5tBNYHj8XAZ4HPBm1uAYoJjyB4GTivj2ucErz2hqCOrwbLI2s04D7CIx5eBwr7uMYMwsE9ImJZ3N5Dwn9w9gLNhPs4bwBygb8CW4BngJygbSHwQMS2nwbKgsc/92F9ZYT7Zo9+Dv8naHsSsKKrz0If1fdI8NnaSDiwxravL5hfTHiUyda+rC9Y/uDRz1xE23i8f53lSp98BnVmrIhIglPXjYhIglPQi4gkOAW9iEiCU9CLiCQ4Bb2ISIJT0IuIJDgFvYhIglPQi4gkuP8PFTNmmB/Zr3YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BiLSTM Model\n",
    "embedding_model = BiLSTMClassifier(\n",
    "    num_embeddings=10000,\n",
    "    embedding_dim=300,\n",
    "    hidden_size=300,\n",
    "    out_features=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "# initialize parameters\n",
    "DATASET = dataset\n",
    "COLLATE_FN = collate_fn\n",
    "BATCH_SIZE = 64\n",
    "SPLIT_TRAIN_RATIO = 0.7\n",
    "MODEL = embedding_model\n",
    "EPOCHS = 20\n",
    "LOSS_FUNCTION = torch.nn.NLLLoss()\n",
    "OPTIMIZER = torch.optim.Adam(MODEL.parameters())\n",
    "CLIP_GRAD = True\n",
    "MAX_NORM = 1\n",
    "\n",
    "training(DATASET, COLLATE_FN, BATCH_SIZE, SPLIT_TRAIN_RATIO, MODEL, EPOCHS, \n",
    "         LOSS_FUNCTION, OPTIMIZER, CLIP_GRAD, MAX_NORM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
